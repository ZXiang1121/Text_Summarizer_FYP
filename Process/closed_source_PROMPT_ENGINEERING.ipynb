{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Closed-Source Prompt Engineering\n",
    "\n",
    "1. **Install & Import Necessary Libraries**\n",
    "\n",
    "2. **Helper Function**\n",
    "\n",
    "3. **Multi-Speaker Conversation Summarizer Prompt Engineering (OpenAI)**\n",
    "\n",
    "    3.1. Prompt Template Testing\n",
    "\n",
    "    3.2 Few-Shot Prompting (Did 5 Shots)\n",
    "\n",
    "    3.3. Map & Combine load_summarize_chain(): Best Method over testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install & Import Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Zhang\n",
      "[nltk_data]     Xiang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Zhang\n",
      "[nltk_data]     Xiang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "c:\\Users\\Zhang Xiang\\Desktop\\Year 3\\Sem 2\\FYPJ\\Project\\RD_TextSummarizerForWebinar\\Development\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import platform\n",
    "import subprocess\n",
    "import time\n",
    "import sys\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "sys.path.append('../')\n",
    "from helper.SummarizationMetrics import SummarizationMetrics\n",
    "from helper.chatgpt_automation import ChatGPTAutomation, split_text_into_chunks\n",
    "from helper.bard_automation import BardAutomation, split_text_into_chunks\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from langchain import LLMChain, HuggingFacePipeline\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from scipy.signal import argrelextrema\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summ_pipeline(model, tokenizer, chain_type, max_length, prompt=False):\n",
    "  pipeline = transformers.pipeline(\n",
    "      \"summarization\",\n",
    "      model=model,\n",
    "      tokenizer=tokenizer,\n",
    "      torch_dtype=torch.bfloat16,\n",
    "      trust_remote_code=True,\n",
    "      device_map=\"auto\",\n",
    "      max_length=max_length,\n",
    "      do_sample=True,\n",
    "      top_k=10,\n",
    "      num_return_sequences=1,\n",
    "      eos_token_id=tokenizer.eos_token_id,\n",
    "  )\n",
    "  \n",
    "  llm = HuggingFacePipeline(pipeline = pipeline)\n",
    "\n",
    "  if chain_type == \"map_reduce\":\n",
    "    if prompt:\n",
    "      prompt_template = \"\"\"Summarize this: ```{text}```\"\"\"\n",
    "      prompt_message = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "      \n",
    "      summary_chain = load_summarize_chain(llm=llm, chain_type=chain_type, token_max=max_length, prompt=prompt_message)\n",
    "    else:\n",
    "      summary_chain = load_summarize_chain(llm=llm, chain_type=chain_type, token_max=max_length)\n",
    "  else:\n",
    "    # can't get it to work with refine and stuff, think they updated the library but no documentation\n",
    "    # on how to set token_max\n",
    "    summary_chain = load_summarize_chain(llm=llm, chain_type=chain_type)\n",
    "  return summary_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from helper.SummarizationMetrics import SummarizationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A firsthand look at efforts to improve diversi...</td>\n",
       "      <td>All right. So our next talk is called Hacking...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It is certainly a time of discovery- though th...</td>\n",
       "      <td>Welcome, DEF CON 28, the Do No Harm panel. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Roman Architecture (HSAR 252) Professor Kleine...</td>\n",
       "      <td>Good morning. As you can see from the title o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stochastic rewriting systems evolving over gra...</td>\n",
       "      <td>Thank you very much, first important question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In typical military operations, the advantage ...</td>\n",
       "      <td>I was great to be with all of you today. I sa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             summary  \\\n",
       "0  A firsthand look at efforts to improve diversi...   \n",
       "1  It is certainly a time of discovery- though th...   \n",
       "2  Roman Architecture (HSAR 252) Professor Kleine...   \n",
       "3  Stochastic rewriting systems evolving over gra...   \n",
       "4  In typical military operations, the advantage ...   \n",
       "\n",
       "                                          transcript  \n",
       "0   All right. So our next talk is called Hacking...  \n",
       "1   Welcome, DEF CON 28, the Do No Harm panel. Th...  \n",
       "2   Good morning. As you can see from the title o...  \n",
       "3   Thank you very much, first important question...  \n",
       "4   I was great to be with all of you today. I sa...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_excel(\"../Data/tib_test.xlsx\")\n",
    "\n",
    "# df_test = df.head(5)\n",
    "\n",
    "# df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\".env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve api key\n",
    "openai_api_key = environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>max_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>16385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>8192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>128000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               models  max_tokens\n",
       "0  gpt-3.5-turbo-1106       16385\n",
       "1               gpt-4        8192\n",
       "2  gpt-4-1106-preview      128000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize OpenAI Model\n",
    "openai_models = {\n",
    "    \"models\": [\n",
    "        \"gpt-3.5-turbo-1106\",\n",
    "        \"gpt-4\",\n",
    "        \"gpt-4-1106-preview\"\n",
    "    ],\n",
    "    \"max_tokens\": [\n",
    "        16385,\n",
    "        8192,\n",
    "        128000,\n",
    "\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_openai_models = pd.DataFrame(openai_models)\n",
    "df_openai_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>method</th>\n",
       "      <th>max_tokens</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>transcript</th>\n",
       "      <th>original summary</th>\n",
       "      <th>summary</th>\n",
       "      <th>rouge</th>\n",
       "      <th>bert_score</th>\n",
       "      <th>bleu</th>\n",
       "      <th>time_taken</th>\n",
       "      <th>grammar</th>\n",
       "      <th>readability</th>\n",
       "      <th>prompt</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, method, max_tokens, num_tokens, transcript, original summary, summary, rouge, bert_score, bleu, time_taken, grammar, readability, prompt, temperature]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute when want to continue\n",
    "df_scores = pd.read_excel(\"./result/closed_source_model_openai_api.xlsx\")\n",
    "df_scores.head(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo-1106\n",
      "Number of tokens: 6827\n",
      "Number of chunks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 52.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2.25 seconds, 0.44 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zhang Xiang\\Desktop\\Year 3\\Sem 2\\FYPJ\\Project\\RD_TextSummarizerForWebinar\\Development\\.venv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 6969\n",
      "Number of chunks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 73.16it/s]\n",
      "c:\\Users\\Zhang Xiang\\Desktop\\Year 3\\Sem 2\\FYPJ\\Project\\RD_TextSummarizerForWebinar\\Development\\.venv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2.08 seconds, 0.48 sentences/sec\n",
      "Number of tokens: 7628\n",
      "Number of chunks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 142.88it/s]\n",
      "c:\\Users\\Zhang Xiang\\Desktop\\Year 3\\Sem 2\\FYPJ\\Project\\RD_TextSummarizerForWebinar\\Development\\.venv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2.14 seconds, 0.47 sentences/sec\n",
      "Number of tokens: 6855\n",
      "Number of chunks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 125.00it/s]\n",
      "c:\\Users\\Zhang Xiang\\Desktop\\Year 3\\Sem 2\\FYPJ\\Project\\RD_TextSummarizerForWebinar\\Development\\.venv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\Zhang Xiang\\Desktop\\Year 3\\Sem 2\\FYPJ\\Project\\RD_TextSummarizerForWebinar\\Development\\.venv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2.45 seconds, 0.41 sentences/sec\n",
      "Number of tokens: 7058\n",
      "Number of chunks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 499.26it/s]\n",
      "c:\\Users\\Zhang Xiang\\Desktop\\Year 3\\Sem 2\\FYPJ\\Project\\RD_TextSummarizerForWebinar\\Development\\.venv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.41 seconds, 0.71 sentences/sec\n",
      "gpt-4\n",
      "Number of tokens: 6827\n",
      "Number of chunks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 25.97it/s]\n",
      "c:\\Users\\Zhang Xiang\\Desktop\\Year 3\\Sem 2\\FYPJ\\Project\\RD_TextSummarizerForWebinar\\Development\\.venv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\Zhang Xiang\\Desktop\\Year 3\\Sem 2\\FYPJ\\Project\\RD_TextSummarizerForWebinar\\Development\\.venv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2.55 seconds, 0.39 sentences/sec\n",
      "Number of tokens: 6969\n",
      "Number of chunks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 664.60it/s]\n",
      "c:\\Users\\Zhang Xiang\\Desktop\\Year 3\\Sem 2\\FYPJ\\Project\\RD_TextSummarizerForWebinar\\Development\\.venv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.31 seconds, 0.76 sentences/sec\n",
      "Number of tokens: 7628\n",
      "Number of chunks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.67it/s]\n",
      "c:\\Users\\Zhang Xiang\\Desktop\\Year 3\\Sem 2\\FYPJ\\Project\\RD_TextSummarizerForWebinar\\Development\\.venv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2.30 seconds, 0.44 sentences/sec\n",
      "Number of tokens: 6855\n",
      "Number of chunks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 499.44it/s]\n",
      "c:\\Users\\Zhang Xiang\\Desktop\\Year 3\\Sem 2\\FYPJ\\Project\\RD_TextSummarizerForWebinar\\Development\\.venv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\Zhang Xiang\\Desktop\\Year 3\\Sem 2\\FYPJ\\Project\\RD_TextSummarizerForWebinar\\Development\\.venv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2.31 seconds, 0.43 sentences/sec\n",
      "Number of tokens: 7058\n",
      "Number of chunks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 29.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.55 seconds, 0.65 sentences/sec\n",
      "gpt-4-1106-preview\n",
      "Number of tokens: 6827\n",
      "Number of chunks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 83.91it/s]\n",
      "c:\\Users\\Zhang Xiang\\Desktop\\Year 3\\Sem 2\\FYPJ\\Project\\RD_TextSummarizerForWebinar\\Development\\.venv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\Zhang Xiang\\Desktop\\Year 3\\Sem 2\\FYPJ\\Project\\RD_TextSummarizerForWebinar\\Development\\.venv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2.34 seconds, 0.43 sentences/sec\n",
      "Number of tokens: 6969\n",
      "Number of chunks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 71.43it/s]\n",
      "c:\\Users\\Zhang Xiang\\Desktop\\Year 3\\Sem 2\\FYPJ\\Project\\RD_TextSummarizerForWebinar\\Development\\.venv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.99 seconds, 0.50 sentences/sec\n",
      "Number of tokens: 7628\n",
      "Number of chunks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2.65 seconds, 0.38 sentences/sec\n",
      "Number of tokens: 6855\n",
      "Number of chunks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 29.41it/s]\n",
      "c:\\Users\\Zhang Xiang\\Desktop\\Year 3\\Sem 2\\FYPJ\\Project\\RD_TextSummarizerForWebinar\\Development\\.venv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\Zhang Xiang\\Desktop\\Year 3\\Sem 2\\FYPJ\\Project\\RD_TextSummarizerForWebinar\\Development\\.venv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2.29 seconds, 0.44 sentences/sec\n",
      "Number of tokens: 7058\n",
      "Number of chunks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 333.30it/s]\n",
      "c:\\Users\\Zhang Xiang\\Desktop\\Year 3\\Sem 2\\FYPJ\\Project\\RD_TextSummarizerForWebinar\\Development\\.venv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2.22 seconds, 0.45 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "for model_index, model_row in df_openai_models.iterrows():\n",
    "    model_name = model_row[\"models\"]\n",
    "    print(model_name)\n",
    "\n",
    "    temperature = 0\n",
    "    llm = ChatOpenAI(temperature=temperature, model_name=model_name, openai_api_key=openai_api_key)\n",
    "    \n",
    "    prompt_template = \"\"\"Write a concise yet comprehensive summary\n",
    "        that highlights key topics and discussions from the webinar transcripts. Purpose of the summary is for users seek overviews before committing to the full video, and the summary should capture\n",
    "          essential threads, providing a gist of the discussion. The intended purpose is to assist users in quickly grasping main points \n",
    "          and reinforcing learning post-viewing. \n",
    "          \n",
    "          Keep the generated summary around 200 words for following context: \n",
    "          {text}\"\"\"\n",
    "    PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "    for index, row in df_test.iterrows():\n",
    "        method = \"MapReduce\"\n",
    "\n",
    "        # get the summary\n",
    "        start_time = time.time()\n",
    "        num_tokens = llm.get_num_tokens(row['transcript'])\n",
    "        print(\"Number of tokens:\", num_tokens)\n",
    "\n",
    "        max_tokens = model_row[\"max_tokens\"]\n",
    "\n",
    "        text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=max_tokens-100, chunk_overlap=100)\n",
    "        docs = text_splitter.create_documents([row['transcript']])\n",
    "        print(\"Number of chunks:\", len(docs))\n",
    "\n",
    "        # break\n",
    "        summary_chain = load_summarize_chain(llm=llm, chain_type='map_reduce', token_max=max_tokens , map_prompt=PROMPT)\n",
    "        summary = summary_chain.run(docs)\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        metrics = SummarizationMetrics(row['summary'], summary)\n",
    "\n",
    "        new_result = {\n",
    "            'model': model_name,\n",
    "            'method': method,\n",
    "            'max_tokens': max_tokens,\n",
    "            'transcript': row['transcript'],\n",
    "            'original summary': row['summary'],\n",
    "            'summary': summary,\n",
    "            'rouge': metrics.rouge_scores(),\n",
    "            'bert_score': metrics.bert_score(),\n",
    "            'bleu': metrics.bleu_score(),\n",
    "            'time_taken': elapsed_time,\n",
    "            'grammar': metrics.grammar_check(),\n",
    "            'readability': metrics.readability_index(),\n",
    "            'num_tokens': num_tokens,\n",
    "            'prompt': prompt_template,\n",
    "            'temperature': temperature\n",
    "        }\n",
    "\n",
    "\n",
    "        new_row = pd.DataFrame([new_result])\n",
    "\n",
    "        df_scores = pd.concat([df_scores, new_row], ignore_index=True)\n",
    "        time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>method</th>\n",
       "      <th>max_tokens</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>transcript</th>\n",
       "      <th>original summary</th>\n",
       "      <th>summary</th>\n",
       "      <th>rouge</th>\n",
       "      <th>bert_score</th>\n",
       "      <th>bleu</th>\n",
       "      <th>time_taken</th>\n",
       "      <th>grammar</th>\n",
       "      <th>readability</th>\n",
       "      <th>prompt</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>6827</td>\n",
       "      <td>All right. So our next talk is called Hacking...</td>\n",
       "      <td>A firsthand look at efforts to improve diversi...</td>\n",
       "      <td>Professor Christina Tamba-Hester's talk on Hac...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.13690476190476192, 'p': 0...</td>\n",
       "      <td>(tensor([0.8656]), tensor([0.8255]), tensor([0...</td>\n",
       "      <td>8.954086e-156</td>\n",
       "      <td>21.383893</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>7628</td>\n",
       "      <td>Good morning. As you can see from the title o...</td>\n",
       "      <td>Roman Architecture (HSAR 252) Professor Kleine...</td>\n",
       "      <td>The speaker discusses important developments i...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.11428571428571428, 'p': 0...</td>\n",
       "      <td>(tensor([0.8856]), tensor([0.8039]), tensor([0...</td>\n",
       "      <td>6.397942e-157</td>\n",
       "      <td>11.230562</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>6855</td>\n",
       "      <td>Thank you very much, first important question...</td>\n",
       "      <td>Stochastic rewriting systems evolving over gra...</td>\n",
       "      <td>The main goal of the research is to analyze th...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.08888888888888889, 'p': 0...</td>\n",
       "      <td>(tensor([0.8576]), tensor([0.7937]), tensor([0...</td>\n",
       "      <td>1.749485e-156</td>\n",
       "      <td>115.299044</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>7058</td>\n",
       "      <td>I was great to be with all of you today. I sa...</td>\n",
       "      <td>In typical military operations, the advantage ...</td>\n",
       "      <td>The presentation challenged traditional approa...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.1037037037037037, 'p': 0....</td>\n",
       "      <td>(tensor([0.8622]), tensor([0.8058]), tensor([0...</td>\n",
       "      <td>1.587501e-79</td>\n",
       "      <td>14.139802</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>6969</td>\n",
       "      <td>Welcome, DEF CON 28, the Do No Harm panel. Th...</td>\n",
       "      <td>It is certainly a time of discovery- though th...</td>\n",
       "      <td>The speaker emphasizes the need to take respon...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.06299212598425197, 'p': 0...</td>\n",
       "      <td>(tensor([0.8376]), tensor([0.7977]), tensor([0...</td>\n",
       "      <td>1.465172e-156</td>\n",
       "      <td>93.767647</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>6969</td>\n",
       "      <td>Welcome, DEF CON 28, the Do No Harm panel. Th...</td>\n",
       "      <td>It is certainly a time of discovery- though th...</td>\n",
       "      <td>The DEF CON 28 Do No Harm panel discussed the ...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.14173228346456693, 'p': 0...</td>\n",
       "      <td>(tensor([0.8701]), tensor([0.8204]), tensor([0...</td>\n",
       "      <td>2.587246e-79</td>\n",
       "      <td>11.267398</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>6969</td>\n",
       "      <td>Welcome, DEF CON 28, the Do No Harm panel. Th...</td>\n",
       "      <td>It is certainly a time of discovery- though th...</td>\n",
       "      <td>At DEF CON 28, the \"Do No Harm\" panel brought ...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.1968503937007874, 'p': 0....</td>\n",
       "      <td>(tensor([0.8469]), tensor([0.8214]), tensor([0...</td>\n",
       "      <td>5.467525e-79</td>\n",
       "      <td>16.473476</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>6827</td>\n",
       "      <td>All right. So our next talk is called Hacking...</td>\n",
       "      <td>A firsthand look at efforts to improve diversi...</td>\n",
       "      <td>In her talk \"Hacking Diversity\", Professor Chr...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.11904761904761904, 'p': 0...</td>\n",
       "      <td>(tensor([0.8734]), tensor([0.8299]), tensor([0...</td>\n",
       "      <td>2.314046e-79</td>\n",
       "      <td>13.086216</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>7628</td>\n",
       "      <td>Good morning. As you can see from the title o...</td>\n",
       "      <td>Roman Architecture (HSAR 252) Professor Kleine...</td>\n",
       "      <td>The lecture explores the architecture of Hercu...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.15, 'p': 0.34426229508196...</td>\n",
       "      <td>(tensor([0.8820]), tensor([0.8144]), tensor([0...</td>\n",
       "      <td>2.455021e-02</td>\n",
       "      <td>14.684876</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>6855</td>\n",
       "      <td>Thank you very much, first important question...</td>\n",
       "      <td>Stochastic rewriting systems evolving over gra...</td>\n",
       "      <td>The speaker explores the application of combin...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.09444444444444444, 'p': 0...</td>\n",
       "      <td>(tensor([0.8588]), tensor([0.7954]), tensor([0...</td>\n",
       "      <td>5.637758e-80</td>\n",
       "      <td>8.984848</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>7058</td>\n",
       "      <td>I was great to be with all of you today. I sa...</td>\n",
       "      <td>In typical military operations, the advantage ...</td>\n",
       "      <td>The speaker emphasizes the significance of cyb...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.08148148148148149, 'p': 0...</td>\n",
       "      <td>(tensor([0.8542]), tensor([0.8088]), tensor([0...</td>\n",
       "      <td>2.474221e-79</td>\n",
       "      <td>12.236066</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>6827</td>\n",
       "      <td>All right. So our next talk is called Hacking...</td>\n",
       "      <td>A firsthand look at efforts to improve diversi...</td>\n",
       "      <td>Professor Christina Tamba-Hester's talk \"Hacki...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.14285714285714285, 'p': 0...</td>\n",
       "      <td>(tensor([0.8674]), tensor([0.8356]), tensor([0...</td>\n",
       "      <td>4.088394e-79</td>\n",
       "      <td>29.100684</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>7628</td>\n",
       "      <td>Good morning. As you can see from the title o...</td>\n",
       "      <td>Roman Architecture (HSAR 252) Professor Kleine...</td>\n",
       "      <td>Today's lecture explored domestic architecture...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.17142857142857143, 'p': 0...</td>\n",
       "      <td>(tensor([0.8721]), tensor([0.8257]), tensor([0...</td>\n",
       "      <td>2.647894e-02</td>\n",
       "      <td>39.277412</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>score: 17.733878504672898, grade_level: '18'</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>6855</td>\n",
       "      <td>Thank you very much, first important question...</td>\n",
       "      <td>Stochastic rewriting systems evolving over gra...</td>\n",
       "      <td>The speaker expresses appreciation for the cha...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.15555555555555556, 'p': 0...</td>\n",
       "      <td>(tensor([0.8509]), tensor([0.8131]), tensor([0...</td>\n",
       "      <td>2.312113e-155</td>\n",
       "      <td>55.178707</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>score: 16.031964285714288, grade_level: '16'</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>7058</td>\n",
       "      <td>I was great to be with all of you today. I sa...</td>\n",
       "      <td>In typical military operations, the advantage ...</td>\n",
       "      <td>The speaker, drawing from their military backg...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.1259259259259259, 'p': 0....</td>\n",
       "      <td>(tensor([0.8527]), tensor([0.8152]), tensor([0...</td>\n",
       "      <td>3.955251e-79</td>\n",
       "      <td>23.334041</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>6827</td>\n",
       "      <td>All right. So our next talk is called Hacking...</td>\n",
       "      <td>A firsthand look at efforts to improve diversi...</td>\n",
       "      <td>The talk explores the lack of diversity in the...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.09523809523809523, 'p': 0...</td>\n",
       "      <td>(tensor([0.8683]), tensor([0.8199]), tensor([0...</td>\n",
       "      <td>5.181215e-156</td>\n",
       "      <td>22.310365</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>6969</td>\n",
       "      <td>Welcome, DEF CON 28, the Do No Harm panel. Th...</td>\n",
       "      <td>It is certainly a time of discovery- though th...</td>\n",
       "      <td>A panel discussion on the importance of addres...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.10236220472440945, 'p': 0...</td>\n",
       "      <td>(tensor([0.8598]), tensor([0.8131]), tensor([0...</td>\n",
       "      <td>2.872619e-79</td>\n",
       "      <td>220.420688</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>7628</td>\n",
       "      <td>Good morning. As you can see from the title o...</td>\n",
       "      <td>Roman Architecture (HSAR 252) Professor Kleine...</td>\n",
       "      <td>The speaker describes the view from the sea wa...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.12142857142857143, 'p': 0...</td>\n",
       "      <td>(tensor([0.8759]), tensor([0.8128]), tensor([0...</td>\n",
       "      <td>1.835995e-02</td>\n",
       "      <td>32.104075</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>6855</td>\n",
       "      <td>Thank you very much, first important question...</td>\n",
       "      <td>Stochastic rewriting systems evolving over gra...</td>\n",
       "      <td>Categorical rewriting theory is a potential me...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.08888888888888889, 'p': 0...</td>\n",
       "      <td>(tensor([0.8543]), tensor([0.7944]), tensor([0...</td>\n",
       "      <td>2.004938e-80</td>\n",
       "      <td>16.051817</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>7058</td>\n",
       "      <td>I was great to be with all of you today. I sa...</td>\n",
       "      <td>In typical military operations, the advantage ...</td>\n",
       "      <td>The article explores traditional approaches to...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.0962962962962963, 'p': 0....</td>\n",
       "      <td>(tensor([0.8633]), tensor([0.8067]), tensor([0...</td>\n",
       "      <td>3.646898e-156</td>\n",
       "      <td>14.939501</td>\n",
       "      <td>[Match({'ruleId': 'CYBER_COMPOUNDS', 'message'...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>6827</td>\n",
       "      <td>All right. So our next talk is called Hacking...</td>\n",
       "      <td>A firsthand look at efforts to improve diversi...</td>\n",
       "      <td>In her \"Hacking Diversity\" talk, Professor Chr...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.14285714285714285, 'p': 0...</td>\n",
       "      <td>(tensor([0.8670]), tensor([0.8296]), tensor([0...</td>\n",
       "      <td>2.348627e-79</td>\n",
       "      <td>9.271456</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>6969</td>\n",
       "      <td>Welcome, DEF CON 28, the Do No Harm panel. Th...</td>\n",
       "      <td>It is certainly a time of discovery- though th...</td>\n",
       "      <td>Healthcare security experts gathered for a dis...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.11811023622047244, 'p': 0...</td>\n",
       "      <td>(tensor([0.8567]), tensor([0.8202]), tensor([0...</td>\n",
       "      <td>9.377047e-156</td>\n",
       "      <td>12.480605</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>7628</td>\n",
       "      <td>Good morning. As you can see from the title o...</td>\n",
       "      <td>Roman Architecture (HSAR 252) Professor Kleine...</td>\n",
       "      <td>The lecture discusses domestic architecture in...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.15, 'p': 0.42, 'f': 0.221...</td>\n",
       "      <td>(tensor([0.8893]), tensor([0.8185]), tensor([0...</td>\n",
       "      <td>1.062791e-02</td>\n",
       "      <td>13.262237</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>6855</td>\n",
       "      <td>Thank you very much, first important question...</td>\n",
       "      <td>Stochastic rewriting systems evolving over gra...</td>\n",
       "      <td>The presenter outlined a novel method for anal...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.09444444444444444, 'p': 0...</td>\n",
       "      <td>(tensor([0.8400]), tensor([0.8043]), tensor([0...</td>\n",
       "      <td>1.106479e-79</td>\n",
       "      <td>12.076730</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>7058</td>\n",
       "      <td>I was great to be with all of you today. I sa...</td>\n",
       "      <td>In typical military operations, the advantage ...</td>\n",
       "      <td>In a recent talk, the challenges of cybersecur...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.1037037037037037, 'p': 0....</td>\n",
       "      <td>(tensor([0.8454]), tensor([0.8051]), tensor([0...</td>\n",
       "      <td>9.906425e-156</td>\n",
       "      <td>9.864205</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>6855</td>\n",
       "      <td>Thank you very much, first important question...</td>\n",
       "      <td>Stochastic rewriting systems evolving over gra...</td>\n",
       "      <td>The speaker discussed the manipulation of grap...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.11666666666666667, 'p': 0...</td>\n",
       "      <td>(tensor([0.8445]), tensor([0.8003]), tensor([0...</td>\n",
       "      <td>5.729872e-156</td>\n",
       "      <td>28.755662</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>7058</td>\n",
       "      <td>I was great to be with all of you today. I sa...</td>\n",
       "      <td>In typical military operations, the advantage ...</td>\n",
       "      <td>The speaker at a cyber competition drew parall...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.14074074074074075, 'p': 0...</td>\n",
       "      <td>(tensor([0.8441]), tensor([0.8117]), tensor([0...</td>\n",
       "      <td>6.680508e-79</td>\n",
       "      <td>39.671920</td>\n",
       "      <td>[Match({'ruleId': 'CYBER_COMPOUNDS', 'message'...</td>\n",
       "      <td>score: 17.69577099236641, grade_level: '18'</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>6827</td>\n",
       "      <td>All right. So our next talk is called Hacking...</td>\n",
       "      <td>A firsthand look at efforts to improve diversi...</td>\n",
       "      <td>Professor Christina Tamba-Hester's talk \"Hacki...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.14285714285714285, 'p': 0...</td>\n",
       "      <td>(tensor([0.8696]), tensor([0.8361]), tensor([0...</td>\n",
       "      <td>1.147177e-155</td>\n",
       "      <td>29.731003</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>6969</td>\n",
       "      <td>Welcome, DEF CON 28, the Do No Harm panel. Th...</td>\n",
       "      <td>It is certainly a time of discovery- though th...</td>\n",
       "      <td>The DEF CON 28 Do No Harm panel, comprised of ...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.1889763779527559, 'p': 0....</td>\n",
       "      <td>(tensor([0.8568]), tensor([0.8254]), tensor([0...</td>\n",
       "      <td>1.022824e-78</td>\n",
       "      <td>37.077160</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>score: 19.74571428571429, grade_level: '20'</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>7628</td>\n",
       "      <td>Good morning. As you can see from the title o...</td>\n",
       "      <td>Roman Architecture (HSAR 252) Professor Kleine...</td>\n",
       "      <td>Today's lecture focused on the domestic archit...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.16428571428571428, 'p': 0...</td>\n",
       "      <td>(tensor([0.8804]), tensor([0.8314]), tensor([0...</td>\n",
       "      <td>4.310069e-02</td>\n",
       "      <td>39.765496</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>score: 15.386666666666667, grade_level: '15'</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>6827</td>\n",
       "      <td>All right. So our next talk is called Hacking...</td>\n",
       "      <td>A firsthand look at efforts to improve diversi...</td>\n",
       "      <td>Professor Christina Tamba-Hester discusses the...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.15476190476190477, 'p': 0...</td>\n",
       "      <td>([tensor(0.8728)], [tensor(0.8286)], [tensor(0...</td>\n",
       "      <td>3.458642e-79</td>\n",
       "      <td>29.185579</td>\n",
       "      <td>[Offset 20, length 12, Rule ID: MORFOLOGIK_RUL...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>6969</td>\n",
       "      <td>Welcome, DEF CON 28, the Do No Harm panel. Th...</td>\n",
       "      <td>It is certainly a time of discovery- though th...</td>\n",
       "      <td>The speaker believes that instead of just patc...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.10236220472440945, 'p': 0...</td>\n",
       "      <td>([tensor(0.8494)], [tensor(0.7993)], [tensor(0...</td>\n",
       "      <td>4.055700e-80</td>\n",
       "      <td>304.766041</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>7628</td>\n",
       "      <td>Good morning. As you can see from the title o...</td>\n",
       "      <td>Roman Architecture (HSAR 252) Professor Kleine...</td>\n",
       "      <td>The webinar explores the domestic architecture...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.12857142857142856, 'p': 0...</td>\n",
       "      <td>([tensor(0.8618)], [tensor(0.8083)], [tensor(0...</td>\n",
       "      <td>4.130450e-79</td>\n",
       "      <td>39.523345</td>\n",
       "      <td>[Offset 142, length 12, Rule ID: MORFOLOGIK_RU...</td>\n",
       "      <td>score: 18.454000000000004, grade_level: '18'</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>6855</td>\n",
       "      <td>Thank you very much, first important question...</td>\n",
       "      <td>Stochastic rewriting systems evolving over gra...</td>\n",
       "      <td>The webinar discusses the generalization of di...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.11666666666666667, 'p': 0...</td>\n",
       "      <td>([tensor(0.8499)], [tensor(0.8025)], [tensor(0...</td>\n",
       "      <td>8.666274e-156</td>\n",
       "      <td>36.948316</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>7058</td>\n",
       "      <td>I was great to be with all of you today. I sa...</td>\n",
       "      <td>In typical military operations, the advantage ...</td>\n",
       "      <td>The discussion focused on atypical ways of thi...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.1259259259259259, 'p': 0....</td>\n",
       "      <td>([tensor(0.8491)], [tensor(0.8082)], [tensor(0...</td>\n",
       "      <td>4.703612e-79</td>\n",
       "      <td>36.286263</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>6827</td>\n",
       "      <td>All right. So our next talk is called Hacking...</td>\n",
       "      <td>A firsthand look at efforts to improve diversi...</td>\n",
       "      <td>The webinar \"Hacking Diversity\" by Professor C...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.10714285714285714, 'p': 0...</td>\n",
       "      <td>([tensor(0.8634)], [tensor(0.8278)], [tensor(0...</td>\n",
       "      <td>5.614584e-156</td>\n",
       "      <td>14.871728</td>\n",
       "      <td>[Offset 55, length 12, Rule ID: MORFOLOGIK_RUL...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>6969</td>\n",
       "      <td>Welcome, DEF CON 28, the Do No Harm panel. Th...</td>\n",
       "      <td>It is certainly a time of discovery- though th...</td>\n",
       "      <td>The DEF CON 28 panel discussion, featuring exp...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.12598425196850394, 'p': 0...</td>\n",
       "      <td>([tensor(0.8713)], [tensor(0.8216)], [tensor(0...</td>\n",
       "      <td>2.175606e-79</td>\n",
       "      <td>13.535113</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>7628</td>\n",
       "      <td>Good morning. As you can see from the title o...</td>\n",
       "      <td>Roman Architecture (HSAR 252) Professor Kleine...</td>\n",
       "      <td>The webinar discussed the study of domestic ar...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.12142857142857143, 'p': 0...</td>\n",
       "      <td>([tensor(0.8959)], [tensor(0.8167)], [tensor(0...</td>\n",
       "      <td>2.100801e-79</td>\n",
       "      <td>15.439435</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>6855</td>\n",
       "      <td>Thank you very much, first important question...</td>\n",
       "      <td>Stochastic rewriting systems evolving over gra...</td>\n",
       "      <td>The webinar explores the mathematical connecti...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.11666666666666667, 'p': 0...</td>\n",
       "      <td>([tensor(0.8608)], [tensor(0.8076)], [tensor(0...</td>\n",
       "      <td>4.801092e-156</td>\n",
       "      <td>15.538087</td>\n",
       "      <td>[Offset 291, length 9, Rule ID: MORFOLOGIK_RUL...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>7058</td>\n",
       "      <td>I was great to be with all of you today. I sa...</td>\n",
       "      <td>In typical military operations, the advantage ...</td>\n",
       "      <td>A former military officer discusses the simila...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.1259259259259259, 'p': 0....</td>\n",
       "      <td>([tensor(0.8649)], [tensor(0.8212)], [tensor(0...</td>\n",
       "      <td>1.068941e-02</td>\n",
       "      <td>13.217274</td>\n",
       "      <td>[Offset 483, length 13, Rule ID: CYBER_COMPOUN...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>6827</td>\n",
       "      <td>All right. So our next talk is called Hacking...</td>\n",
       "      <td>A firsthand look at efforts to improve diversi...</td>\n",
       "      <td>In the \"Hacking Diversity\" webinar, Professor ...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.125, 'p': 0.3088235294117...</td>\n",
       "      <td>([tensor(0.8702)], [tensor(0.8340)], [tensor(0...</td>\n",
       "      <td>1.372786e-155</td>\n",
       "      <td>44.298810</td>\n",
       "      <td>[Offset 56, length 12, Rule ID: MORFOLOGIK_RUL...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>6969</td>\n",
       "      <td>Welcome, DEF CON 28, the Do No Harm panel. Th...</td>\n",
       "      <td>It is certainly a time of discovery- though th...</td>\n",
       "      <td>At DEF CON 28's \"Do No Harm\" panel, experts in...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.1968503937007874, 'p': 0....</td>\n",
       "      <td>([tensor(0.8574)], [tensor(0.8264)], [tensor(0...</td>\n",
       "      <td>9.863333e-79</td>\n",
       "      <td>70.015324</td>\n",
       "      <td>[Offset 160, length 8, Rule ID: MORFOLOGIK_RUL...</td>\n",
       "      <td>score: 17.814000000000004, grade_level: '18'</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>7628</td>\n",
       "      <td>Good morning. As you can see from the title o...</td>\n",
       "      <td>Roman Architecture (HSAR 252) Professor Kleine...</td>\n",
       "      <td>The webinar \"Habitats at Herculaneum and Early...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.20714285714285716, 'p': 0...</td>\n",
       "      <td>([tensor(0.8721)], [tensor(0.8339)], [tensor(0...</td>\n",
       "      <td>4.749744e-02</td>\n",
       "      <td>59.575349</td>\n",
       "      <td>[Offset 507, length 7, Rule ID: MORFOLOGIK_RUL...</td>\n",
       "      <td>score: 15.858000000000004, grade_level: '16'</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>6855</td>\n",
       "      <td>Thank you very much, first important question...</td>\n",
       "      <td>Stochastic rewriting systems evolving over gra...</td>\n",
       "      <td>The webinar discussed the intersection of comp...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.11666666666666667, 'p': 0...</td>\n",
       "      <td>([tensor(0.8455)], [tensor(0.8051)], [tensor(0...</td>\n",
       "      <td>1.116947e-155</td>\n",
       "      <td>49.351651</td>\n",
       "      <td>[Offset 371, length 9, Rule ID: MORFOLOGIK_RUL...</td>\n",
       "      <td>score: 18.075407407407408, grade_level: '18'</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>7058</td>\n",
       "      <td>I was great to be with all of you today. I sa...</td>\n",
       "      <td>In typical military operations, the advantage ...</td>\n",
       "      <td>In the webinar, the speaker compares the strat...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.1259259259259259, 'p': 0....</td>\n",
       "      <td>([tensor(0.8529)], [tensor(0.8179)], [tensor(0...</td>\n",
       "      <td>7.591593e-79</td>\n",
       "      <td>37.264941</td>\n",
       "      <td>[]</td>\n",
       "      <td>score: 17.52339622641509, grade_level: '18'</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model     method  max_tokens  num_tokens  \\\n",
       "0   gpt-3.5-turbo-1106  MapReduce       16385        6827   \n",
       "1   gpt-3.5-turbo-1106  MapReduce       16385        7628   \n",
       "2   gpt-3.5-turbo-1106  MapReduce       16385        6855   \n",
       "3   gpt-3.5-turbo-1106  MapReduce       16385        7058   \n",
       "4   gpt-3.5-turbo-1106  MapReduce       16385        6969   \n",
       "5                gpt-4  MapReduce        8192        6969   \n",
       "6   gpt-4-1106-preview  MapReduce      128000        6969   \n",
       "7                gpt-4  MapReduce        8192        6827   \n",
       "8                gpt-4  MapReduce        8192        7628   \n",
       "9                gpt-4  MapReduce        8192        6855   \n",
       "10               gpt-4  MapReduce        8192        7058   \n",
       "11  gpt-4-1106-preview  MapReduce      128000        6827   \n",
       "12  gpt-4-1106-preview  MapReduce      128000        7628   \n",
       "13  gpt-4-1106-preview  MapReduce      128000        6855   \n",
       "14  gpt-4-1106-preview  MapReduce      128000        7058   \n",
       "15  gpt-3.5-turbo-1106  MapReduce       16385        6827   \n",
       "16  gpt-3.5-turbo-1106  MapReduce       16385        6969   \n",
       "17  gpt-3.5-turbo-1106  MapReduce       16385        7628   \n",
       "18  gpt-3.5-turbo-1106  MapReduce       16385        6855   \n",
       "19  gpt-3.5-turbo-1106  MapReduce       16385        7058   \n",
       "20               gpt-4  MapReduce        8192        6827   \n",
       "21               gpt-4  MapReduce        8192        6969   \n",
       "22               gpt-4  MapReduce        8192        7628   \n",
       "23               gpt-4  MapReduce        8192        6855   \n",
       "24               gpt-4  MapReduce        8192        7058   \n",
       "25  gpt-4-1106-preview  MapReduce      128000        6855   \n",
       "26  gpt-4-1106-preview  MapReduce      128000        7058   \n",
       "27  gpt-4-1106-preview  MapReduce      128000        6827   \n",
       "28  gpt-4-1106-preview  MapReduce      128000        6969   \n",
       "29  gpt-4-1106-preview  MapReduce      128000        7628   \n",
       "30  gpt-3.5-turbo-1106  MapReduce       16385        6827   \n",
       "31  gpt-3.5-turbo-1106  MapReduce       16385        6969   \n",
       "32  gpt-3.5-turbo-1106  MapReduce       16385        7628   \n",
       "33  gpt-3.5-turbo-1106  MapReduce       16385        6855   \n",
       "34  gpt-3.5-turbo-1106  MapReduce       16385        7058   \n",
       "35               gpt-4  MapReduce        8192        6827   \n",
       "36               gpt-4  MapReduce        8192        6969   \n",
       "37               gpt-4  MapReduce        8192        7628   \n",
       "38               gpt-4  MapReduce        8192        6855   \n",
       "39               gpt-4  MapReduce        8192        7058   \n",
       "40  gpt-4-1106-preview  MapReduce      128000        6827   \n",
       "41  gpt-4-1106-preview  MapReduce      128000        6969   \n",
       "42  gpt-4-1106-preview  MapReduce      128000        7628   \n",
       "43  gpt-4-1106-preview  MapReduce      128000        6855   \n",
       "44  gpt-4-1106-preview  MapReduce      128000        7058   \n",
       "\n",
       "                                           transcript  \\\n",
       "0    All right. So our next talk is called Hacking...   \n",
       "1    Good morning. As you can see from the title o...   \n",
       "2    Thank you very much, first important question...   \n",
       "3    I was great to be with all of you today. I sa...   \n",
       "4    Welcome, DEF CON 28, the Do No Harm panel. Th...   \n",
       "5    Welcome, DEF CON 28, the Do No Harm panel. Th...   \n",
       "6    Welcome, DEF CON 28, the Do No Harm panel. Th...   \n",
       "7    All right. So our next talk is called Hacking...   \n",
       "8    Good morning. As you can see from the title o...   \n",
       "9    Thank you very much, first important question...   \n",
       "10   I was great to be with all of you today. I sa...   \n",
       "11   All right. So our next talk is called Hacking...   \n",
       "12   Good morning. As you can see from the title o...   \n",
       "13   Thank you very much, first important question...   \n",
       "14   I was great to be with all of you today. I sa...   \n",
       "15   All right. So our next talk is called Hacking...   \n",
       "16   Welcome, DEF CON 28, the Do No Harm panel. Th...   \n",
       "17   Good morning. As you can see from the title o...   \n",
       "18   Thank you very much, first important question...   \n",
       "19   I was great to be with all of you today. I sa...   \n",
       "20   All right. So our next talk is called Hacking...   \n",
       "21   Welcome, DEF CON 28, the Do No Harm panel. Th...   \n",
       "22   Good morning. As you can see from the title o...   \n",
       "23   Thank you very much, first important question...   \n",
       "24   I was great to be with all of you today. I sa...   \n",
       "25   Thank you very much, first important question...   \n",
       "26   I was great to be with all of you today. I sa...   \n",
       "27   All right. So our next talk is called Hacking...   \n",
       "28   Welcome, DEF CON 28, the Do No Harm panel. Th...   \n",
       "29   Good morning. As you can see from the title o...   \n",
       "30   All right. So our next talk is called Hacking...   \n",
       "31   Welcome, DEF CON 28, the Do No Harm panel. Th...   \n",
       "32   Good morning. As you can see from the title o...   \n",
       "33   Thank you very much, first important question...   \n",
       "34   I was great to be with all of you today. I sa...   \n",
       "35   All right. So our next talk is called Hacking...   \n",
       "36   Welcome, DEF CON 28, the Do No Harm panel. Th...   \n",
       "37   Good morning. As you can see from the title o...   \n",
       "38   Thank you very much, first important question...   \n",
       "39   I was great to be with all of you today. I sa...   \n",
       "40   All right. So our next talk is called Hacking...   \n",
       "41   Welcome, DEF CON 28, the Do No Harm panel. Th...   \n",
       "42   Good morning. As you can see from the title o...   \n",
       "43   Thank you very much, first important question...   \n",
       "44   I was great to be with all of you today. I sa...   \n",
       "\n",
       "                                     original summary  \\\n",
       "0   A firsthand look at efforts to improve diversi...   \n",
       "1   Roman Architecture (HSAR 252) Professor Kleine...   \n",
       "2   Stochastic rewriting systems evolving over gra...   \n",
       "3   In typical military operations, the advantage ...   \n",
       "4   It is certainly a time of discovery- though th...   \n",
       "5   It is certainly a time of discovery- though th...   \n",
       "6   It is certainly a time of discovery- though th...   \n",
       "7   A firsthand look at efforts to improve diversi...   \n",
       "8   Roman Architecture (HSAR 252) Professor Kleine...   \n",
       "9   Stochastic rewriting systems evolving over gra...   \n",
       "10  In typical military operations, the advantage ...   \n",
       "11  A firsthand look at efforts to improve diversi...   \n",
       "12  Roman Architecture (HSAR 252) Professor Kleine...   \n",
       "13  Stochastic rewriting systems evolving over gra...   \n",
       "14  In typical military operations, the advantage ...   \n",
       "15  A firsthand look at efforts to improve diversi...   \n",
       "16  It is certainly a time of discovery- though th...   \n",
       "17  Roman Architecture (HSAR 252) Professor Kleine...   \n",
       "18  Stochastic rewriting systems evolving over gra...   \n",
       "19  In typical military operations, the advantage ...   \n",
       "20  A firsthand look at efforts to improve diversi...   \n",
       "21  It is certainly a time of discovery- though th...   \n",
       "22  Roman Architecture (HSAR 252) Professor Kleine...   \n",
       "23  Stochastic rewriting systems evolving over gra...   \n",
       "24  In typical military operations, the advantage ...   \n",
       "25  Stochastic rewriting systems evolving over gra...   \n",
       "26  In typical military operations, the advantage ...   \n",
       "27  A firsthand look at efforts to improve diversi...   \n",
       "28  It is certainly a time of discovery- though th...   \n",
       "29  Roman Architecture (HSAR 252) Professor Kleine...   \n",
       "30  A firsthand look at efforts to improve diversi...   \n",
       "31  It is certainly a time of discovery- though th...   \n",
       "32  Roman Architecture (HSAR 252) Professor Kleine...   \n",
       "33  Stochastic rewriting systems evolving over gra...   \n",
       "34  In typical military operations, the advantage ...   \n",
       "35  A firsthand look at efforts to improve diversi...   \n",
       "36  It is certainly a time of discovery- though th...   \n",
       "37  Roman Architecture (HSAR 252) Professor Kleine...   \n",
       "38  Stochastic rewriting systems evolving over gra...   \n",
       "39  In typical military operations, the advantage ...   \n",
       "40  A firsthand look at efforts to improve diversi...   \n",
       "41  It is certainly a time of discovery- though th...   \n",
       "42  Roman Architecture (HSAR 252) Professor Kleine...   \n",
       "43  Stochastic rewriting systems evolving over gra...   \n",
       "44  In typical military operations, the advantage ...   \n",
       "\n",
       "                                              summary  \\\n",
       "0   Professor Christina Tamba-Hester's talk on Hac...   \n",
       "1   The speaker discusses important developments i...   \n",
       "2   The main goal of the research is to analyze th...   \n",
       "3   The presentation challenged traditional approa...   \n",
       "4   The speaker emphasizes the need to take respon...   \n",
       "5   The DEF CON 28 Do No Harm panel discussed the ...   \n",
       "6   At DEF CON 28, the \"Do No Harm\" panel brought ...   \n",
       "7   In her talk \"Hacking Diversity\", Professor Chr...   \n",
       "8   The lecture explores the architecture of Hercu...   \n",
       "9   The speaker explores the application of combin...   \n",
       "10  The speaker emphasizes the significance of cyb...   \n",
       "11  Professor Christina Tamba-Hester's talk \"Hacki...   \n",
       "12  Today's lecture explored domestic architecture...   \n",
       "13  The speaker expresses appreciation for the cha...   \n",
       "14  The speaker, drawing from their military backg...   \n",
       "15  The talk explores the lack of diversity in the...   \n",
       "16  A panel discussion on the importance of addres...   \n",
       "17  The speaker describes the view from the sea wa...   \n",
       "18  Categorical rewriting theory is a potential me...   \n",
       "19  The article explores traditional approaches to...   \n",
       "20  In her \"Hacking Diversity\" talk, Professor Chr...   \n",
       "21  Healthcare security experts gathered for a dis...   \n",
       "22  The lecture discusses domestic architecture in...   \n",
       "23  The presenter outlined a novel method for anal...   \n",
       "24  In a recent talk, the challenges of cybersecur...   \n",
       "25  The speaker discussed the manipulation of grap...   \n",
       "26  The speaker at a cyber competition drew parall...   \n",
       "27  Professor Christina Tamba-Hester's talk \"Hacki...   \n",
       "28  The DEF CON 28 Do No Harm panel, comprised of ...   \n",
       "29  Today's lecture focused on the domestic archit...   \n",
       "30  Professor Christina Tamba-Hester discusses the...   \n",
       "31  The speaker believes that instead of just patc...   \n",
       "32  The webinar explores the domestic architecture...   \n",
       "33  The webinar discusses the generalization of di...   \n",
       "34  The discussion focused on atypical ways of thi...   \n",
       "35  The webinar \"Hacking Diversity\" by Professor C...   \n",
       "36  The DEF CON 28 panel discussion, featuring exp...   \n",
       "37  The webinar discussed the study of domestic ar...   \n",
       "38  The webinar explores the mathematical connecti...   \n",
       "39  A former military officer discusses the simila...   \n",
       "40  In the \"Hacking Diversity\" webinar, Professor ...   \n",
       "41  At DEF CON 28's \"Do No Harm\" panel, experts in...   \n",
       "42  The webinar \"Habitats at Herculaneum and Early...   \n",
       "43  The webinar discussed the intersection of comp...   \n",
       "44  In the webinar, the speaker compares the strat...   \n",
       "\n",
       "                                                rouge  \\\n",
       "0   [{'rouge-1': {'r': 0.13690476190476192, 'p': 0...   \n",
       "1   [{'rouge-1': {'r': 0.11428571428571428, 'p': 0...   \n",
       "2   [{'rouge-1': {'r': 0.08888888888888889, 'p': 0...   \n",
       "3   [{'rouge-1': {'r': 0.1037037037037037, 'p': 0....   \n",
       "4   [{'rouge-1': {'r': 0.06299212598425197, 'p': 0...   \n",
       "5   [{'rouge-1': {'r': 0.14173228346456693, 'p': 0...   \n",
       "6   [{'rouge-1': {'r': 0.1968503937007874, 'p': 0....   \n",
       "7   [{'rouge-1': {'r': 0.11904761904761904, 'p': 0...   \n",
       "8   [{'rouge-1': {'r': 0.15, 'p': 0.34426229508196...   \n",
       "9   [{'rouge-1': {'r': 0.09444444444444444, 'p': 0...   \n",
       "10  [{'rouge-1': {'r': 0.08148148148148149, 'p': 0...   \n",
       "11  [{'rouge-1': {'r': 0.14285714285714285, 'p': 0...   \n",
       "12  [{'rouge-1': {'r': 0.17142857142857143, 'p': 0...   \n",
       "13  [{'rouge-1': {'r': 0.15555555555555556, 'p': 0...   \n",
       "14  [{'rouge-1': {'r': 0.1259259259259259, 'p': 0....   \n",
       "15  [{'rouge-1': {'r': 0.09523809523809523, 'p': 0...   \n",
       "16  [{'rouge-1': {'r': 0.10236220472440945, 'p': 0...   \n",
       "17  [{'rouge-1': {'r': 0.12142857142857143, 'p': 0...   \n",
       "18  [{'rouge-1': {'r': 0.08888888888888889, 'p': 0...   \n",
       "19  [{'rouge-1': {'r': 0.0962962962962963, 'p': 0....   \n",
       "20  [{'rouge-1': {'r': 0.14285714285714285, 'p': 0...   \n",
       "21  [{'rouge-1': {'r': 0.11811023622047244, 'p': 0...   \n",
       "22  [{'rouge-1': {'r': 0.15, 'p': 0.42, 'f': 0.221...   \n",
       "23  [{'rouge-1': {'r': 0.09444444444444444, 'p': 0...   \n",
       "24  [{'rouge-1': {'r': 0.1037037037037037, 'p': 0....   \n",
       "25  [{'rouge-1': {'r': 0.11666666666666667, 'p': 0...   \n",
       "26  [{'rouge-1': {'r': 0.14074074074074075, 'p': 0...   \n",
       "27  [{'rouge-1': {'r': 0.14285714285714285, 'p': 0...   \n",
       "28  [{'rouge-1': {'r': 0.1889763779527559, 'p': 0....   \n",
       "29  [{'rouge-1': {'r': 0.16428571428571428, 'p': 0...   \n",
       "30  [{'rouge-1': {'r': 0.15476190476190477, 'p': 0...   \n",
       "31  [{'rouge-1': {'r': 0.10236220472440945, 'p': 0...   \n",
       "32  [{'rouge-1': {'r': 0.12857142857142856, 'p': 0...   \n",
       "33  [{'rouge-1': {'r': 0.11666666666666667, 'p': 0...   \n",
       "34  [{'rouge-1': {'r': 0.1259259259259259, 'p': 0....   \n",
       "35  [{'rouge-1': {'r': 0.10714285714285714, 'p': 0...   \n",
       "36  [{'rouge-1': {'r': 0.12598425196850394, 'p': 0...   \n",
       "37  [{'rouge-1': {'r': 0.12142857142857143, 'p': 0...   \n",
       "38  [{'rouge-1': {'r': 0.11666666666666667, 'p': 0...   \n",
       "39  [{'rouge-1': {'r': 0.1259259259259259, 'p': 0....   \n",
       "40  [{'rouge-1': {'r': 0.125, 'p': 0.3088235294117...   \n",
       "41  [{'rouge-1': {'r': 0.1968503937007874, 'p': 0....   \n",
       "42  [{'rouge-1': {'r': 0.20714285714285716, 'p': 0...   \n",
       "43  [{'rouge-1': {'r': 0.11666666666666667, 'p': 0...   \n",
       "44  [{'rouge-1': {'r': 0.1259259259259259, 'p': 0....   \n",
       "\n",
       "                                           bert_score           bleu  \\\n",
       "0   (tensor([0.8656]), tensor([0.8255]), tensor([0...  8.954086e-156   \n",
       "1   (tensor([0.8856]), tensor([0.8039]), tensor([0...  6.397942e-157   \n",
       "2   (tensor([0.8576]), tensor([0.7937]), tensor([0...  1.749485e-156   \n",
       "3   (tensor([0.8622]), tensor([0.8058]), tensor([0...   1.587501e-79   \n",
       "4   (tensor([0.8376]), tensor([0.7977]), tensor([0...  1.465172e-156   \n",
       "5   (tensor([0.8701]), tensor([0.8204]), tensor([0...   2.587246e-79   \n",
       "6   (tensor([0.8469]), tensor([0.8214]), tensor([0...   5.467525e-79   \n",
       "7   (tensor([0.8734]), tensor([0.8299]), tensor([0...   2.314046e-79   \n",
       "8   (tensor([0.8820]), tensor([0.8144]), tensor([0...   2.455021e-02   \n",
       "9   (tensor([0.8588]), tensor([0.7954]), tensor([0...   5.637758e-80   \n",
       "10  (tensor([0.8542]), tensor([0.8088]), tensor([0...   2.474221e-79   \n",
       "11  (tensor([0.8674]), tensor([0.8356]), tensor([0...   4.088394e-79   \n",
       "12  (tensor([0.8721]), tensor([0.8257]), tensor([0...   2.647894e-02   \n",
       "13  (tensor([0.8509]), tensor([0.8131]), tensor([0...  2.312113e-155   \n",
       "14  (tensor([0.8527]), tensor([0.8152]), tensor([0...   3.955251e-79   \n",
       "15  (tensor([0.8683]), tensor([0.8199]), tensor([0...  5.181215e-156   \n",
       "16  (tensor([0.8598]), tensor([0.8131]), tensor([0...   2.872619e-79   \n",
       "17  (tensor([0.8759]), tensor([0.8128]), tensor([0...   1.835995e-02   \n",
       "18  (tensor([0.8543]), tensor([0.7944]), tensor([0...   2.004938e-80   \n",
       "19  (tensor([0.8633]), tensor([0.8067]), tensor([0...  3.646898e-156   \n",
       "20  (tensor([0.8670]), tensor([0.8296]), tensor([0...   2.348627e-79   \n",
       "21  (tensor([0.8567]), tensor([0.8202]), tensor([0...  9.377047e-156   \n",
       "22  (tensor([0.8893]), tensor([0.8185]), tensor([0...   1.062791e-02   \n",
       "23  (tensor([0.8400]), tensor([0.8043]), tensor([0...   1.106479e-79   \n",
       "24  (tensor([0.8454]), tensor([0.8051]), tensor([0...  9.906425e-156   \n",
       "25  (tensor([0.8445]), tensor([0.8003]), tensor([0...  5.729872e-156   \n",
       "26  (tensor([0.8441]), tensor([0.8117]), tensor([0...   6.680508e-79   \n",
       "27  (tensor([0.8696]), tensor([0.8361]), tensor([0...  1.147177e-155   \n",
       "28  (tensor([0.8568]), tensor([0.8254]), tensor([0...   1.022824e-78   \n",
       "29  (tensor([0.8804]), tensor([0.8314]), tensor([0...   4.310069e-02   \n",
       "30  ([tensor(0.8728)], [tensor(0.8286)], [tensor(0...   3.458642e-79   \n",
       "31  ([tensor(0.8494)], [tensor(0.7993)], [tensor(0...   4.055700e-80   \n",
       "32  ([tensor(0.8618)], [tensor(0.8083)], [tensor(0...   4.130450e-79   \n",
       "33  ([tensor(0.8499)], [tensor(0.8025)], [tensor(0...  8.666274e-156   \n",
       "34  ([tensor(0.8491)], [tensor(0.8082)], [tensor(0...   4.703612e-79   \n",
       "35  ([tensor(0.8634)], [tensor(0.8278)], [tensor(0...  5.614584e-156   \n",
       "36  ([tensor(0.8713)], [tensor(0.8216)], [tensor(0...   2.175606e-79   \n",
       "37  ([tensor(0.8959)], [tensor(0.8167)], [tensor(0...   2.100801e-79   \n",
       "38  ([tensor(0.8608)], [tensor(0.8076)], [tensor(0...  4.801092e-156   \n",
       "39  ([tensor(0.8649)], [tensor(0.8212)], [tensor(0...   1.068941e-02   \n",
       "40  ([tensor(0.8702)], [tensor(0.8340)], [tensor(0...  1.372786e-155   \n",
       "41  ([tensor(0.8574)], [tensor(0.8264)], [tensor(0...   9.863333e-79   \n",
       "42  ([tensor(0.8721)], [tensor(0.8339)], [tensor(0...   4.749744e-02   \n",
       "43  ([tensor(0.8455)], [tensor(0.8051)], [tensor(0...  1.116947e-155   \n",
       "44  ([tensor(0.8529)], [tensor(0.8179)], [tensor(0...   7.591593e-79   \n",
       "\n",
       "    time_taken                                            grammar  \\\n",
       "0    21.383893  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "1    11.230562                                                 []   \n",
       "2   115.299044                                                 []   \n",
       "3    14.139802                                                 []   \n",
       "4    93.767647                                                 []   \n",
       "5    11.267398                                                 []   \n",
       "6    16.473476  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "7    13.086216  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "8    14.684876  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "9     8.984848                                                 []   \n",
       "10   12.236066                                                 []   \n",
       "11   29.100684  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "12   39.277412  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "13   55.178707  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "14   23.334041                                                 []   \n",
       "15   22.310365                                                 []   \n",
       "16  220.420688                                                 []   \n",
       "17   32.104075                                                 []   \n",
       "18   16.051817                                                 []   \n",
       "19   14.939501  [Match({'ruleId': 'CYBER_COMPOUNDS', 'message'...   \n",
       "20    9.271456  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "21   12.480605  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "22   13.262237  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "23   12.076730  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "24    9.864205                                                 []   \n",
       "25   28.755662  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "26   39.671920  [Match({'ruleId': 'CYBER_COMPOUNDS', 'message'...   \n",
       "27   29.731003  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "28   37.077160  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "29   39.765496  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "30   29.185579  [Offset 20, length 12, Rule ID: MORFOLOGIK_RUL...   \n",
       "31  304.766041                                                 []   \n",
       "32   39.523345  [Offset 142, length 12, Rule ID: MORFOLOGIK_RU...   \n",
       "33   36.948316                                                 []   \n",
       "34   36.286263                                                 []   \n",
       "35   14.871728  [Offset 55, length 12, Rule ID: MORFOLOGIK_RUL...   \n",
       "36   13.535113                                                 []   \n",
       "37   15.439435                                                 []   \n",
       "38   15.538087  [Offset 291, length 9, Rule ID: MORFOLOGIK_RUL...   \n",
       "39   13.217274  [Offset 483, length 13, Rule ID: CYBER_COMPOUN...   \n",
       "40   44.298810  [Offset 56, length 12, Rule ID: MORFOLOGIK_RUL...   \n",
       "41   70.015324  [Offset 160, length 8, Rule ID: MORFOLOGIK_RUL...   \n",
       "42   59.575349  [Offset 507, length 7, Rule ID: MORFOLOGIK_RUL...   \n",
       "43   49.351651  [Offset 371, length 9, Rule ID: MORFOLOGIK_RUL...   \n",
       "44   37.264941                                                 []   \n",
       "\n",
       "                                     readability  \\\n",
       "0                            100 words required.   \n",
       "1                            100 words required.   \n",
       "2                            100 words required.   \n",
       "3                            100 words required.   \n",
       "4                            100 words required.   \n",
       "5                            100 words required.   \n",
       "6                            100 words required.   \n",
       "7                            100 words required.   \n",
       "8                            100 words required.   \n",
       "9                            100 words required.   \n",
       "10                           100 words required.   \n",
       "11                           100 words required.   \n",
       "12  score: 17.733878504672898, grade_level: '18'   \n",
       "13  score: 16.031964285714288, grade_level: '16'   \n",
       "14                           100 words required.   \n",
       "15                           100 words required.   \n",
       "16                           100 words required.   \n",
       "17                           100 words required.   \n",
       "18                           100 words required.   \n",
       "19                           100 words required.   \n",
       "20                           100 words required.   \n",
       "21                           100 words required.   \n",
       "22                           100 words required.   \n",
       "23                           100 words required.   \n",
       "24                           100 words required.   \n",
       "25                           100 words required.   \n",
       "26   score: 17.69577099236641, grade_level: '18'   \n",
       "27                           100 words required.   \n",
       "28   score: 19.74571428571429, grade_level: '20'   \n",
       "29  score: 15.386666666666667, grade_level: '15'   \n",
       "30                           100 words required.   \n",
       "31                           100 words required.   \n",
       "32  score: 18.454000000000004, grade_level: '18'   \n",
       "33                           100 words required.   \n",
       "34                           100 words required.   \n",
       "35                           100 words required.   \n",
       "36                           100 words required.   \n",
       "37                           100 words required.   \n",
       "38                           100 words required.   \n",
       "39                           100 words required.   \n",
       "40                           100 words required.   \n",
       "41  score: 17.814000000000004, grade_level: '18'   \n",
       "42  score: 15.858000000000004, grade_level: '16'   \n",
       "43  score: 18.075407407407408, grade_level: '18'   \n",
       "44   score: 17.52339622641509, grade_level: '18'   \n",
       "\n",
       "                                               prompt  temperature  \n",
       "0    Write a concise summary of the following: {text}            0  \n",
       "1    Write a concise summary of the following: {text}            0  \n",
       "2    Write a concise summary of the following: {text}            0  \n",
       "3    Write a concise summary of the following: {text}            0  \n",
       "4    Write a concise summary of the following: {text}            0  \n",
       "5    Write a concise summary of the following: {text}            0  \n",
       "6    Write a concise summary of the following: {text}            0  \n",
       "7    Write a concise summary of the following: {text}            0  \n",
       "8    Write a concise summary of the following: {text}            0  \n",
       "9    Write a concise summary of the following: {text}            0  \n",
       "10   Write a concise summary of the following: {text}            0  \n",
       "11   Write a concise summary of the following: {text}            0  \n",
       "12   Write a concise summary of the following: {text}            0  \n",
       "13   Write a concise summary of the following: {text}            0  \n",
       "14   Write a concise summary of the following: {text}            0  \n",
       "15   Write a concise summary of the following: {text}            1  \n",
       "16   Write a concise summary of the following: {text}            1  \n",
       "17   Write a concise summary of the following: {text}            1  \n",
       "18   Write a concise summary of the following: {text}            1  \n",
       "19   Write a concise summary of the following: {text}            1  \n",
       "20   Write a concise summary of the following: {text}            1  \n",
       "21   Write a concise summary of the following: {text}            1  \n",
       "22   Write a concise summary of the following: {text}            1  \n",
       "23   Write a concise summary of the following: {text}            1  \n",
       "24   Write a concise summary of the following: {text}            1  \n",
       "25   Write a concise summary of the following: {text}            1  \n",
       "26   Write a concise summary of the following: {text}            1  \n",
       "27   Write a concise summary of the following: {text}            1  \n",
       "28   Write a concise summary of the following: {text}            1  \n",
       "29   Write a concise summary of the following: {text}            1  \n",
       "30  Write a concise yet comprehensive summary\\n   ...            0  \n",
       "31  Write a concise yet comprehensive summary\\n   ...            0  \n",
       "32  Write a concise yet comprehensive summary\\n   ...            0  \n",
       "33  Write a concise yet comprehensive summary\\n   ...            0  \n",
       "34  Write a concise yet comprehensive summary\\n   ...            0  \n",
       "35  Write a concise yet comprehensive summary\\n   ...            0  \n",
       "36  Write a concise yet comprehensive summary\\n   ...            0  \n",
       "37  Write a concise yet comprehensive summary\\n   ...            0  \n",
       "38  Write a concise yet comprehensive summary\\n   ...            0  \n",
       "39  Write a concise yet comprehensive summary\\n   ...            0  \n",
       "40  Write a concise yet comprehensive summary\\n   ...            0  \n",
       "41  Write a concise yet comprehensive summary\\n   ...            0  \n",
       "42  Write a concise yet comprehensive summary\\n   ...            0  \n",
       "43  Write a concise yet comprehensive summary\\n   ...            0  \n",
       "44  Write a concise yet comprehensive summary\\n   ...            0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Speaker Conversation Summarizer Prompt Engineering (OpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transcript</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Professor C : Uh , is it the twenty - fourth ?...</td>\n",
       "      <td>The meeting covered the issues with different ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          transcript  \\\n",
       "4  Professor C : Uh , is it the twenty - fourth ?...   \n",
       "\n",
       "                                             summary  \n",
       "4  The meeting covered the issues with different ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qmsum_test = pd.read_excel(\"../Data/qmsum_test.xlsx\")\n",
    "df_qmsum_test = df_qmsum_test.iloc[[4]]\n",
    "# df_qmsum_test = df_qmsum_test.head(5)\n",
    "\n",
    "df_qmsum_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>max_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>16385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               models  max_tokens\n",
       "0  gpt-3.5-turbo-1106       16385"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Models\n",
    "openai_models = {\n",
    "    \"models\": [\n",
    "        \"gpt-3.5-turbo-1106\",\n",
    "        # \"gpt-4\",\n",
    "        # \"gpt-4-1106-preview\"\n",
    "    ],\n",
    "    \"max_tokens\": [\n",
    "        16385,\n",
    "        # 8192,\n",
    "        # 128000,\n",
    "\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_openai_models = pd.DataFrame(openai_models)\n",
    "df_openai_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>method</th>\n",
       "      <th>max_tokens</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>transcript</th>\n",
       "      <th>original summary</th>\n",
       "      <th>summary</th>\n",
       "      <th>rouge</th>\n",
       "      <th>bert_score</th>\n",
       "      <th>bleu</th>\n",
       "      <th>time_taken</th>\n",
       "      <th>grammar</th>\n",
       "      <th>readability</th>\n",
       "      <th>prompt</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [model, method, max_tokens, num_tokens, transcript, original summary, summary, rouge, bert_score, bleu, time_taken, grammar, readability, prompt, temperature]\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read and continue update dataframe\n",
    "# df_scores = pd.read_excel(\"./result/closed_source_model_openai_api.xlsx\")\n",
    "# df_scores.head(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt Template Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_openai_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_index, model_row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdf_openai_models\u001b[49m\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m      2\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m model_row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(model_name)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_openai_models' is not defined"
     ]
    }
   ],
   "source": [
    "for model_index, model_row in df_openai_models.iterrows():\n",
    "    model_name = model_row[\"models\"]\n",
    "    print(model_name)\n",
    "\n",
    "    temperature = 0\n",
    "    llm = ChatOpenAI(temperature=temperature, model_name=model_name, openai_api_key=openai_api_key)\n",
    "    \n",
    "    prompt_template = \"\"\"\n",
    "                    Transcript:\n",
    "                    {text}\n",
    "\n",
    "                    Given a transcripts between multiple speakers above, provide a concise summary within 200 words for each speaker highlighting their key points or contributions with the given format below:\n",
    "\n",
    "                    Speaker 1 Name: (Summary for speaker 1)\n",
    "                    \n",
    "\n",
    "                    Speaker 2 Name: (Summary for speaker 2)\n",
    "                    \n",
    "                    \"\"\"\n",
    "    \n",
    "\n",
    "    PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "    for index, row in df_qmsum_test.iterrows():\n",
    "        method = \"MapReduce\"\n",
    "\n",
    "        # get the summary\n",
    "        start_time = time.time()\n",
    "        num_tokens = llm.get_num_tokens(row['transcript'])\n",
    "        print(\"Number of tokens:\", num_tokens)\n",
    "\n",
    "        max_tokens = model_row[\"max_tokens\"]\n",
    "\n",
    "        text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=max_tokens-100, chunk_overlap=100)\n",
    "        docs = text_splitter.create_documents([row['transcript']])\n",
    "        print(\"Number of chunks:\", len(docs))\n",
    "\n",
    "        # break\n",
    "        summary_chain = load_summarize_chain(llm=llm, chain_type='map_reduce', token_max=max_tokens , map_prompt=PROMPT)\n",
    "        summary = summary_chain.run(docs)\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        metrics = SummarizationMetrics(row['summary'], summary)\n",
    "\n",
    "        new_result = {\n",
    "            'model': model_name,\n",
    "            'method': method,\n",
    "            'max_tokens': max_tokens,\n",
    "            'transcript': row['transcript'],\n",
    "            'original summary': row['summary'],\n",
    "            'summary': summary,\n",
    "            'rouge': metrics.rouge_scores(),\n",
    "            'bert_score': metrics.bert_score(),\n",
    "            'bleu': metrics.bleu_score(),\n",
    "            'time_taken': elapsed_time,\n",
    "            'grammar': metrics.grammar_check(),\n",
    "            'readability': metrics.readability_index(),\n",
    "            'num_tokens': num_tokens,\n",
    "            'prompt': prompt_template,\n",
    "            'temperature': temperature\n",
    "        }\n",
    "\n",
    "\n",
    "        new_row = pd.DataFrame([new_result])\n",
    "\n",
    "        df_scores = pd.concat([df_scores, new_row], ignore_index=True)\n",
    "        time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo-1106\n",
      "Number of tokens: 8983\n",
      "Number of chunks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 177.74it/s]\n",
      "c:\\Users\\Zhang Xiang\\Desktop\\Year 3\\Sem 2\\FYPJ\\Project\\RD_TextSummarizerForWebinar\\Development\\.venv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "c:\\Users\\Zhang Xiang\\Desktop\\Year 3\\Sem 2\\FYPJ\\Project\\RD_TextSummarizerForWebinar\\Development\\.venv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.79 seconds, 1.26 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "for model_index, model_row in df_openai_models.iterrows():\n",
    "    model_name = model_row[\"models\"]\n",
    "    print(model_name)\n",
    "\n",
    "    temperature = 0\n",
    "    llm = ChatOpenAI(temperature=temperature, model_name=model_name, openai_api_key=openai_api_key)\n",
    "    \n",
    "    prompt_template = \"\"\"Compose concise yet comprehensive individual summaries for each speaker based on the provided transcript:\n",
    "\n",
    "\n",
    "                    Follow the format below in \"markdown format\", ensuring each speaker summary is approximately 100 to 200 words. Include details about their perspectives, key points, and any noteworthy insights.\n",
    "\n",
    "                    Speaker 1 Name:\n",
    "                    - Provide a brief introduction to Speaker 1.\n",
    "                    - Summarize their key contributions to the discussion.\n",
    "                    - Highlight notable opinions or stances expressed by Speaker 1.\n",
    "\n",
    "                    Speaker 2 Name:\n",
    "                    - Introduce Speaker 2 briefly.\n",
    "                    - Outline the main points and ideas put forth by Speaker 2.\n",
    "                    - Emphasize any distinct perspectives or viewpoints presented by Speaker 2.\n",
    "\n",
    "                    Transcript:\n",
    "                    {text}\n",
    "                    \n",
    "                    \"\"\"\n",
    "    PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "    for index, row in df_qmsum_test.iterrows():\n",
    "        method = \"MapReduce\"\n",
    "\n",
    "        # get the summary\n",
    "        start_time = time.time()\n",
    "        num_tokens = llm.get_num_tokens(row['transcript'])\n",
    "        print(\"Number of tokens:\", num_tokens)\n",
    "\n",
    "        max_tokens = model_row[\"max_tokens\"]\n",
    "\n",
    "        text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=max_tokens-100, chunk_overlap=100)\n",
    "        docs = text_splitter.create_documents([row['transcript']])\n",
    "        print(\"Number of chunks:\", len(docs))\n",
    "\n",
    "        # break\n",
    "        summary_chain = load_summarize_chain(llm=llm, chain_type='map_reduce', token_max=max_tokens , map_prompt=PROMPT)\n",
    "        summary = summary_chain.run(docs)\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        metrics = SummarizationMetrics(row['summary'], summary)\n",
    "\n",
    "        new_result = {\n",
    "            'model': model_name,\n",
    "            'method': method,\n",
    "            'max_tokens': max_tokens,\n",
    "            'transcript': row['transcript'],\n",
    "            'original summary': row['summary'],\n",
    "            'summary': summary,\n",
    "            'rouge': metrics.rouge_scores(),\n",
    "            'bert_score': metrics.bert_score(),\n",
    "            'bleu': metrics.bleu_score(),\n",
    "            'time_taken': elapsed_time,\n",
    "            'grammar': metrics.grammar_check(),\n",
    "            'readability': metrics.readability_index(),\n",
    "            'num_tokens': num_tokens,\n",
    "            'prompt': prompt_template,\n",
    "            'temperature': temperature\n",
    "        }\n",
    "\n",
    "\n",
    "        new_row = pd.DataFrame([new_result])\n",
    "\n",
    "        df_scores = pd.concat([df_scores, new_row], ignore_index=True)\n",
    "        time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores['max_tokens'] = df_scores['max_tokens'].astype(int)\n",
    "\n",
    "# df_scores.to_excel(\"./result/closed_source_model_openai_api.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>method</th>\n",
       "      <th>max_tokens</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>transcript</th>\n",
       "      <th>original summary</th>\n",
       "      <th>summary</th>\n",
       "      <th>rouge</th>\n",
       "      <th>bert_score</th>\n",
       "      <th>bleu</th>\n",
       "      <th>time_taken</th>\n",
       "      <th>grammar</th>\n",
       "      <th>readability</th>\n",
       "      <th>prompt</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>6827</td>\n",
       "      <td>All right. So our next talk is called Hacking...</td>\n",
       "      <td>A firsthand look at efforts to improve diversi...</td>\n",
       "      <td>Professor Christina Tamba-Hester's talk on Hac...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.13690476190476192, 'p': 0...</td>\n",
       "      <td>(tensor([0.8656]), tensor([0.8255]), tensor([0...</td>\n",
       "      <td>8.954086e-156</td>\n",
       "      <td>21.383893</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>7628</td>\n",
       "      <td>Good morning. As you can see from the title o...</td>\n",
       "      <td>Roman Architecture (HSAR 252) Professor Kleine...</td>\n",
       "      <td>The speaker discusses important developments i...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.11428571428571428, 'p': 0...</td>\n",
       "      <td>(tensor([0.8856]), tensor([0.8039]), tensor([0...</td>\n",
       "      <td>6.397942e-157</td>\n",
       "      <td>11.230562</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>6855</td>\n",
       "      <td>Thank you very much, first important question...</td>\n",
       "      <td>Stochastic rewriting systems evolving over gra...</td>\n",
       "      <td>The main goal of the research is to analyze th...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.08888888888888889, 'p': 0...</td>\n",
       "      <td>(tensor([0.8576]), tensor([0.7937]), tensor([0...</td>\n",
       "      <td>1.749485e-156</td>\n",
       "      <td>115.299044</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>7058</td>\n",
       "      <td>I was great to be with all of you today. I sa...</td>\n",
       "      <td>In typical military operations, the advantage ...</td>\n",
       "      <td>The presentation challenged traditional approa...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.1037037037037037, 'p': 0....</td>\n",
       "      <td>(tensor([0.8622]), tensor([0.8058]), tensor([0...</td>\n",
       "      <td>1.587501e-79</td>\n",
       "      <td>14.139802</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>6969</td>\n",
       "      <td>Welcome, DEF CON 28, the Do No Harm panel. Th...</td>\n",
       "      <td>It is certainly a time of discovery- though th...</td>\n",
       "      <td>The speaker emphasizes the need to take respon...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.06299212598425197, 'p': 0...</td>\n",
       "      <td>(tensor([0.8376]), tensor([0.7977]), tensor([0...</td>\n",
       "      <td>1.465172e-156</td>\n",
       "      <td>93.767647</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>6969</td>\n",
       "      <td>Welcome, DEF CON 28, the Do No Harm panel. Th...</td>\n",
       "      <td>It is certainly a time of discovery- though th...</td>\n",
       "      <td>The DEF CON 28 Do No Harm panel discussed the ...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.14173228346456693, 'p': 0...</td>\n",
       "      <td>(tensor([0.8701]), tensor([0.8204]), tensor([0...</td>\n",
       "      <td>2.587246e-79</td>\n",
       "      <td>11.267398</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>6969</td>\n",
       "      <td>Welcome, DEF CON 28, the Do No Harm panel. Th...</td>\n",
       "      <td>It is certainly a time of discovery- though th...</td>\n",
       "      <td>At DEF CON 28, the \"Do No Harm\" panel brought ...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.1968503937007874, 'p': 0....</td>\n",
       "      <td>(tensor([0.8469]), tensor([0.8214]), tensor([0...</td>\n",
       "      <td>5.467525e-79</td>\n",
       "      <td>16.473476</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>6827</td>\n",
       "      <td>All right. So our next talk is called Hacking...</td>\n",
       "      <td>A firsthand look at efforts to improve diversi...</td>\n",
       "      <td>In her talk \"Hacking Diversity\", Professor Chr...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.11904761904761904, 'p': 0...</td>\n",
       "      <td>(tensor([0.8734]), tensor([0.8299]), tensor([0...</td>\n",
       "      <td>2.314046e-79</td>\n",
       "      <td>13.086216</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>7628</td>\n",
       "      <td>Good morning. As you can see from the title o...</td>\n",
       "      <td>Roman Architecture (HSAR 252) Professor Kleine...</td>\n",
       "      <td>The lecture explores the architecture of Hercu...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.15, 'p': 0.34426229508196...</td>\n",
       "      <td>(tensor([0.8820]), tensor([0.8144]), tensor([0...</td>\n",
       "      <td>2.455021e-02</td>\n",
       "      <td>14.684876</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>6855</td>\n",
       "      <td>Thank you very much, first important question...</td>\n",
       "      <td>Stochastic rewriting systems evolving over gra...</td>\n",
       "      <td>The speaker explores the application of combin...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.09444444444444444, 'p': 0...</td>\n",
       "      <td>(tensor([0.8588]), tensor([0.7954]), tensor([0...</td>\n",
       "      <td>5.637758e-80</td>\n",
       "      <td>8.984848</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>7058</td>\n",
       "      <td>I was great to be with all of you today. I sa...</td>\n",
       "      <td>In typical military operations, the advantage ...</td>\n",
       "      <td>The speaker emphasizes the significance of cyb...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.08148148148148149, 'p': 0...</td>\n",
       "      <td>(tensor([0.8542]), tensor([0.8088]), tensor([0...</td>\n",
       "      <td>2.474221e-79</td>\n",
       "      <td>12.236066</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>6827</td>\n",
       "      <td>All right. So our next talk is called Hacking...</td>\n",
       "      <td>A firsthand look at efforts to improve diversi...</td>\n",
       "      <td>Professor Christina Tamba-Hester's talk \"Hacki...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.14285714285714285, 'p': 0...</td>\n",
       "      <td>(tensor([0.8674]), tensor([0.8356]), tensor([0...</td>\n",
       "      <td>4.088394e-79</td>\n",
       "      <td>29.100684</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>7628</td>\n",
       "      <td>Good morning. As you can see from the title o...</td>\n",
       "      <td>Roman Architecture (HSAR 252) Professor Kleine...</td>\n",
       "      <td>Today's lecture explored domestic architecture...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.17142857142857143, 'p': 0...</td>\n",
       "      <td>(tensor([0.8721]), tensor([0.8257]), tensor([0...</td>\n",
       "      <td>2.647894e-02</td>\n",
       "      <td>39.277412</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>score: 17.733878504672898, grade_level: '18'</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>6855</td>\n",
       "      <td>Thank you very much, first important question...</td>\n",
       "      <td>Stochastic rewriting systems evolving over gra...</td>\n",
       "      <td>The speaker expresses appreciation for the cha...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.15555555555555556, 'p': 0...</td>\n",
       "      <td>(tensor([0.8509]), tensor([0.8131]), tensor([0...</td>\n",
       "      <td>2.312113e-155</td>\n",
       "      <td>55.178707</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>score: 16.031964285714288, grade_level: '16'</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>7058</td>\n",
       "      <td>I was great to be with all of you today. I sa...</td>\n",
       "      <td>In typical military operations, the advantage ...</td>\n",
       "      <td>The speaker, drawing from their military backg...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.1259259259259259, 'p': 0....</td>\n",
       "      <td>(tensor([0.8527]), tensor([0.8152]), tensor([0...</td>\n",
       "      <td>3.955251e-79</td>\n",
       "      <td>23.334041</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>6827</td>\n",
       "      <td>All right. So our next talk is called Hacking...</td>\n",
       "      <td>A firsthand look at efforts to improve diversi...</td>\n",
       "      <td>The talk explores the lack of diversity in the...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.09523809523809523, 'p': 0...</td>\n",
       "      <td>(tensor([0.8683]), tensor([0.8199]), tensor([0...</td>\n",
       "      <td>5.181215e-156</td>\n",
       "      <td>22.310365</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>6969</td>\n",
       "      <td>Welcome, DEF CON 28, the Do No Harm panel. Th...</td>\n",
       "      <td>It is certainly a time of discovery- though th...</td>\n",
       "      <td>A panel discussion on the importance of addres...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.10236220472440945, 'p': 0...</td>\n",
       "      <td>(tensor([0.8598]), tensor([0.8131]), tensor([0...</td>\n",
       "      <td>2.872619e-79</td>\n",
       "      <td>220.420688</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>7628</td>\n",
       "      <td>Good morning. As you can see from the title o...</td>\n",
       "      <td>Roman Architecture (HSAR 252) Professor Kleine...</td>\n",
       "      <td>The speaker describes the view from the sea wa...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.12142857142857143, 'p': 0...</td>\n",
       "      <td>(tensor([0.8759]), tensor([0.8128]), tensor([0...</td>\n",
       "      <td>1.835995e-02</td>\n",
       "      <td>32.104075</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>6855</td>\n",
       "      <td>Thank you very much, first important question...</td>\n",
       "      <td>Stochastic rewriting systems evolving over gra...</td>\n",
       "      <td>Categorical rewriting theory is a potential me...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.08888888888888889, 'p': 0...</td>\n",
       "      <td>(tensor([0.8543]), tensor([0.7944]), tensor([0...</td>\n",
       "      <td>2.004938e-80</td>\n",
       "      <td>16.051817</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>7058</td>\n",
       "      <td>I was great to be with all of you today. I sa...</td>\n",
       "      <td>In typical military operations, the advantage ...</td>\n",
       "      <td>The article explores traditional approaches to...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.0962962962962963, 'p': 0....</td>\n",
       "      <td>(tensor([0.8633]), tensor([0.8067]), tensor([0...</td>\n",
       "      <td>3.646898e-156</td>\n",
       "      <td>14.939501</td>\n",
       "      <td>[Match({'ruleId': 'CYBER_COMPOUNDS', 'message'...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>6827</td>\n",
       "      <td>All right. So our next talk is called Hacking...</td>\n",
       "      <td>A firsthand look at efforts to improve diversi...</td>\n",
       "      <td>In her \"Hacking Diversity\" talk, Professor Chr...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.14285714285714285, 'p': 0...</td>\n",
       "      <td>(tensor([0.8670]), tensor([0.8296]), tensor([0...</td>\n",
       "      <td>2.348627e-79</td>\n",
       "      <td>9.271456</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>6969</td>\n",
       "      <td>Welcome, DEF CON 28, the Do No Harm panel. Th...</td>\n",
       "      <td>It is certainly a time of discovery- though th...</td>\n",
       "      <td>Healthcare security experts gathered for a dis...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.11811023622047244, 'p': 0...</td>\n",
       "      <td>(tensor([0.8567]), tensor([0.8202]), tensor([0...</td>\n",
       "      <td>9.377047e-156</td>\n",
       "      <td>12.480605</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>7628</td>\n",
       "      <td>Good morning. As you can see from the title o...</td>\n",
       "      <td>Roman Architecture (HSAR 252) Professor Kleine...</td>\n",
       "      <td>The lecture discusses domestic architecture in...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.15, 'p': 0.42, 'f': 0.221...</td>\n",
       "      <td>(tensor([0.8893]), tensor([0.8185]), tensor([0...</td>\n",
       "      <td>1.062791e-02</td>\n",
       "      <td>13.262237</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>6855</td>\n",
       "      <td>Thank you very much, first important question...</td>\n",
       "      <td>Stochastic rewriting systems evolving over gra...</td>\n",
       "      <td>The presenter outlined a novel method for anal...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.09444444444444444, 'p': 0...</td>\n",
       "      <td>(tensor([0.8400]), tensor([0.8043]), tensor([0...</td>\n",
       "      <td>1.106479e-79</td>\n",
       "      <td>12.076730</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>7058</td>\n",
       "      <td>I was great to be with all of you today. I sa...</td>\n",
       "      <td>In typical military operations, the advantage ...</td>\n",
       "      <td>In a recent talk, the challenges of cybersecur...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.1037037037037037, 'p': 0....</td>\n",
       "      <td>(tensor([0.8454]), tensor([0.8051]), tensor([0...</td>\n",
       "      <td>9.906425e-156</td>\n",
       "      <td>9.864205</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>6855</td>\n",
       "      <td>Thank you very much, first important question...</td>\n",
       "      <td>Stochastic rewriting systems evolving over gra...</td>\n",
       "      <td>The speaker discussed the manipulation of grap...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.11666666666666667, 'p': 0...</td>\n",
       "      <td>(tensor([0.8445]), tensor([0.8003]), tensor([0...</td>\n",
       "      <td>5.729872e-156</td>\n",
       "      <td>28.755662</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>7058</td>\n",
       "      <td>I was great to be with all of you today. I sa...</td>\n",
       "      <td>In typical military operations, the advantage ...</td>\n",
       "      <td>The speaker at a cyber competition drew parall...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.14074074074074075, 'p': 0...</td>\n",
       "      <td>(tensor([0.8441]), tensor([0.8117]), tensor([0...</td>\n",
       "      <td>6.680508e-79</td>\n",
       "      <td>39.671920</td>\n",
       "      <td>[Match({'ruleId': 'CYBER_COMPOUNDS', 'message'...</td>\n",
       "      <td>score: 17.69577099236641, grade_level: '18'</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>6827</td>\n",
       "      <td>All right. So our next talk is called Hacking...</td>\n",
       "      <td>A firsthand look at efforts to improve diversi...</td>\n",
       "      <td>Professor Christina Tamba-Hester's talk \"Hacki...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.14285714285714285, 'p': 0...</td>\n",
       "      <td>(tensor([0.8696]), tensor([0.8361]), tensor([0...</td>\n",
       "      <td>1.147177e-155</td>\n",
       "      <td>29.731003</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>6969</td>\n",
       "      <td>Welcome, DEF CON 28, the Do No Harm panel. Th...</td>\n",
       "      <td>It is certainly a time of discovery- though th...</td>\n",
       "      <td>The DEF CON 28 Do No Harm panel, comprised of ...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.1889763779527559, 'p': 0....</td>\n",
       "      <td>(tensor([0.8568]), tensor([0.8254]), tensor([0...</td>\n",
       "      <td>1.022824e-78</td>\n",
       "      <td>37.077160</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>score: 19.74571428571429, grade_level: '20'</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>7628</td>\n",
       "      <td>Good morning. As you can see from the title o...</td>\n",
       "      <td>Roman Architecture (HSAR 252) Professor Kleine...</td>\n",
       "      <td>Today's lecture focused on the domestic archit...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.16428571428571428, 'p': 0...</td>\n",
       "      <td>(tensor([0.8804]), tensor([0.8314]), tensor([0...</td>\n",
       "      <td>4.310069e-02</td>\n",
       "      <td>39.765496</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>score: 15.386666666666667, grade_level: '15'</td>\n",
       "      <td>Write a concise summary of the following: {text}</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>6827</td>\n",
       "      <td>All right. So our next talk is called Hacking...</td>\n",
       "      <td>A firsthand look at efforts to improve diversi...</td>\n",
       "      <td>Professor Christina Tamba-Hester discusses the...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.15476190476190477, 'p': 0...</td>\n",
       "      <td>(tensor([0.8728]), tensor([0.8286]), tensor([0...</td>\n",
       "      <td>3.458642e-79</td>\n",
       "      <td>29.185579</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>6969</td>\n",
       "      <td>Welcome, DEF CON 28, the Do No Harm panel. Th...</td>\n",
       "      <td>It is certainly a time of discovery- though th...</td>\n",
       "      <td>The speaker believes that instead of just patc...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.10236220472440945, 'p': 0...</td>\n",
       "      <td>(tensor([0.8494]), tensor([0.7993]), tensor([0...</td>\n",
       "      <td>4.055700e-80</td>\n",
       "      <td>304.766041</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>7628</td>\n",
       "      <td>Good morning. As you can see from the title o...</td>\n",
       "      <td>Roman Architecture (HSAR 252) Professor Kleine...</td>\n",
       "      <td>The webinar explores the domestic architecture...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.12857142857142856, 'p': 0...</td>\n",
       "      <td>(tensor([0.8618]), tensor([0.8083]), tensor([0...</td>\n",
       "      <td>4.130450e-79</td>\n",
       "      <td>39.523345</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>score: 18.454000000000004, grade_level: '18'</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>6855</td>\n",
       "      <td>Thank you very much, first important question...</td>\n",
       "      <td>Stochastic rewriting systems evolving over gra...</td>\n",
       "      <td>The webinar discusses the generalization of di...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.11666666666666667, 'p': 0...</td>\n",
       "      <td>(tensor([0.8499]), tensor([0.8025]), tensor([0...</td>\n",
       "      <td>8.666274e-156</td>\n",
       "      <td>36.948316</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>7058</td>\n",
       "      <td>I was great to be with all of you today. I sa...</td>\n",
       "      <td>In typical military operations, the advantage ...</td>\n",
       "      <td>The discussion focused on atypical ways of thi...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.1259259259259259, 'p': 0....</td>\n",
       "      <td>(tensor([0.8491]), tensor([0.8082]), tensor([0...</td>\n",
       "      <td>4.703612e-79</td>\n",
       "      <td>36.286263</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>6827</td>\n",
       "      <td>All right. So our next talk is called Hacking...</td>\n",
       "      <td>A firsthand look at efforts to improve diversi...</td>\n",
       "      <td>The webinar \"Hacking Diversity\" by Professor C...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.10714285714285714, 'p': 0...</td>\n",
       "      <td>(tensor([0.8634]), tensor([0.8278]), tensor([0...</td>\n",
       "      <td>5.614584e-156</td>\n",
       "      <td>14.871728</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>6969</td>\n",
       "      <td>Welcome, DEF CON 28, the Do No Harm panel. Th...</td>\n",
       "      <td>It is certainly a time of discovery- though th...</td>\n",
       "      <td>The DEF CON 28 panel discussion, featuring exp...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.12598425196850394, 'p': 0...</td>\n",
       "      <td>(tensor([0.8713]), tensor([0.8216]), tensor([0...</td>\n",
       "      <td>2.175606e-79</td>\n",
       "      <td>13.535113</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>7628</td>\n",
       "      <td>Good morning. As you can see from the title o...</td>\n",
       "      <td>Roman Architecture (HSAR 252) Professor Kleine...</td>\n",
       "      <td>The webinar discussed the study of domestic ar...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.12142857142857143, 'p': 0...</td>\n",
       "      <td>(tensor([0.8959]), tensor([0.8167]), tensor([0...</td>\n",
       "      <td>2.100801e-79</td>\n",
       "      <td>15.439435</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>6855</td>\n",
       "      <td>Thank you very much, first important question...</td>\n",
       "      <td>Stochastic rewriting systems evolving over gra...</td>\n",
       "      <td>The webinar explores the mathematical connecti...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.11666666666666667, 'p': 0...</td>\n",
       "      <td>(tensor([0.8608]), tensor([0.8076]), tensor([0...</td>\n",
       "      <td>4.801092e-156</td>\n",
       "      <td>15.538087</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>7058</td>\n",
       "      <td>I was great to be with all of you today. I sa...</td>\n",
       "      <td>In typical military operations, the advantage ...</td>\n",
       "      <td>A former military officer discusses the simila...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.1259259259259259, 'p': 0....</td>\n",
       "      <td>(tensor([0.8649]), tensor([0.8212]), tensor([0...</td>\n",
       "      <td>1.068941e-02</td>\n",
       "      <td>13.217274</td>\n",
       "      <td>[Match({'ruleId': 'CYBER_COMPOUNDS', 'message'...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>6827</td>\n",
       "      <td>All right. So our next talk is called Hacking...</td>\n",
       "      <td>A firsthand look at efforts to improve diversi...</td>\n",
       "      <td>In the \"Hacking Diversity\" webinar, Professor ...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.125, 'p': 0.3088235294117...</td>\n",
       "      <td>(tensor([0.8702]), tensor([0.8340]), tensor([0...</td>\n",
       "      <td>1.372786e-155</td>\n",
       "      <td>44.298810</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>6969</td>\n",
       "      <td>Welcome, DEF CON 28, the Do No Harm panel. Th...</td>\n",
       "      <td>It is certainly a time of discovery- though th...</td>\n",
       "      <td>At DEF CON 28's \"Do No Harm\" panel, experts in...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.1968503937007874, 'p': 0....</td>\n",
       "      <td>(tensor([0.8574]), tensor([0.8264]), tensor([0...</td>\n",
       "      <td>9.863333e-79</td>\n",
       "      <td>70.015324</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>score: 17.814000000000004, grade_level: '18'</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>7628</td>\n",
       "      <td>Good morning. As you can see from the title o...</td>\n",
       "      <td>Roman Architecture (HSAR 252) Professor Kleine...</td>\n",
       "      <td>The webinar \"Habitats at Herculaneum and Early...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.20714285714285716, 'p': 0...</td>\n",
       "      <td>(tensor([0.8721]), tensor([0.8339]), tensor([0...</td>\n",
       "      <td>4.749744e-02</td>\n",
       "      <td>59.575349</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>score: 15.858000000000004, grade_level: '16'</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>6855</td>\n",
       "      <td>Thank you very much, first important question...</td>\n",
       "      <td>Stochastic rewriting systems evolving over gra...</td>\n",
       "      <td>The webinar discussed the intersection of comp...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.11666666666666667, 'p': 0...</td>\n",
       "      <td>(tensor([0.8455]), tensor([0.8051]), tensor([0...</td>\n",
       "      <td>1.116947e-155</td>\n",
       "      <td>49.351651</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>score: 18.075407407407408, grade_level: '18'</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>7058</td>\n",
       "      <td>I was great to be with all of you today. I sa...</td>\n",
       "      <td>In typical military operations, the advantage ...</td>\n",
       "      <td>In the webinar, the speaker compares the strat...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.1259259259259259, 'p': 0....</td>\n",
       "      <td>(tensor([0.8529]), tensor([0.8179]), tensor([0...</td>\n",
       "      <td>7.591593e-79</td>\n",
       "      <td>37.264941</td>\n",
       "      <td>[]</td>\n",
       "      <td>score: 17.52339622641509, grade_level: '18'</td>\n",
       "      <td>Write a concise yet comprehensive summary\\n   ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>gpt-4</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>8192</td>\n",
       "      <td>8983</td>\n",
       "      <td>Grad C : Nice . Grad D : OK . Grad A : to {dis...</td>\n",
       "      <td>The group discussed the first version of the B...</td>\n",
       "      <td>The discussion involves Grad A and Grad C, who...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.14736842105263157, 'p': 0...</td>\n",
       "      <td>(tensor([0.8378]), tensor([0.8253]), tensor([0...</td>\n",
       "      <td>2.441696e-155</td>\n",
       "      <td>28.560694</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>score: 13.933524752475247, grade_level: '14'</td>\n",
       "      <td>Compose concise yet comprehensive individual s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>128000</td>\n",
       "      <td>8983</td>\n",
       "      <td>Grad C : Nice . Grad D : OK . Grad A : to {dis...</td>\n",
       "      <td>The group discussed the first version of the B...</td>\n",
       "      <td>Grad A and Grad B engaged in a discussion abou...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.15789473684210525, 'p': 0...</td>\n",
       "      <td>(tensor([0.8384]), tensor([0.8362]), tensor([0...</td>\n",
       "      <td>4.853597e-155</td>\n",
       "      <td>53.416301</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>score: 19.93522556390978, grade_level: '20'</td>\n",
       "      <td>Compose concise yet comprehensive individual s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>8983</td>\n",
       "      <td>Grad C : Nice . Grad D : OK . Grad A : to {dis...</td>\n",
       "      <td>The group discussed the first version of the B...</td>\n",
       "      <td>The discussion involves Grad B and Grad C prov...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.08421052631578947, 'p': 0...</td>\n",
       "      <td>(tensor([0.8486]), tensor([0.8200]), tensor([0...</td>\n",
       "      <td>6.267410e-79</td>\n",
       "      <td>9.655459</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Compose concise yet comprehensive individual s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>8983</td>\n",
       "      <td>Grad C : Nice . Grad D : OK . Grad A : to {dis...</td>\n",
       "      <td>The group discussed the first version of the B...</td>\n",
       "      <td>Grads A and B are both focused on refining the...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.09473684210526316, 'p': 0...</td>\n",
       "      <td>(tensor([0.8514]), tensor([0.8359]), tensor([0...</td>\n",
       "      <td>6.916317e-79</td>\n",
       "      <td>7.836615</td>\n",
       "      <td>[Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Compose concise yet comprehensive individual s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>8983</td>\n",
       "      <td>Grad C : Nice . Grad D : OK . Grad A : to {dis...</td>\n",
       "      <td>The group discussed the first version of the B...</td>\n",
       "      <td>Grad C and Grad B discuss the concept of the m...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.14736842105263157, 'p': 0...</td>\n",
       "      <td>([tensor(0.8566)], [tensor(0.8315)], [tensor(0...</td>\n",
       "      <td>7.922619e-79</td>\n",
       "      <td>6.554743</td>\n",
       "      <td>[Offset 446, length 9, Rule ID: MORFOLOGIK_RUL...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>\\n                    Given a conversation bet...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>8983</td>\n",
       "      <td>Grad C : Nice . Grad D : OK . Grad A : to {dis...</td>\n",
       "      <td>The group discussed the first version of the B...</td>\n",
       "      <td>Three speakers, Grad C, Grad B, and Grad D, di...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.07368421052631578, 'p': 0...</td>\n",
       "      <td>([tensor(0.8446)], [tensor(0.8214)], [tensor(0...</td>\n",
       "      <td>7.254744e-156</td>\n",
       "      <td>5.529194</td>\n",
       "      <td>[]</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>\\n                    Given a conversation bet...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>8983</td>\n",
       "      <td>Grad C : Nice . Grad D : OK . Grad A : to {dis...</td>\n",
       "      <td>The group discussed the first version of the B...</td>\n",
       "      <td>Grad A focuses on discussing the middle layer ...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.10526315789473684, 'p': 0...</td>\n",
       "      <td>([tensor(0.8463)], [tensor(0.8237)], [tensor(0...</td>\n",
       "      <td>2.191490e-155</td>\n",
       "      <td>7.556895</td>\n",
       "      <td>[Offset 51, length 14, Rule ID: MORFOLOGIK_RUL...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>Compose concise yet comprehensive individual s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>gpt-3.5-turbo-1106</td>\n",
       "      <td>MapReduce</td>\n",
       "      <td>16385</td>\n",
       "      <td>8983</td>\n",
       "      <td>Grad C : Nice . Grad D : OK . Grad A : to {dis...</td>\n",
       "      <td>The group discussed the first version of the B...</td>\n",
       "      <td>Grad C discusses the middle layer of the belie...</td>\n",
       "      <td>[{'rouge-1': {'r': 0.12631578947368421, 'p': 0...</td>\n",
       "      <td>([tensor(0.8446)], [tensor(0.8295)], [tensor(0...</td>\n",
       "      <td>6.104099e-79</td>\n",
       "      <td>8.170220</td>\n",
       "      <td>[Offset 104, length 9, Rule ID: MORFOLOGIK_RUL...</td>\n",
       "      <td>100 words required.</td>\n",
       "      <td>\\n                    Transcript:\\n           ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model     method  max_tokens  num_tokens  \\\n",
       "0   gpt-3.5-turbo-1106  MapReduce       16385        6827   \n",
       "1   gpt-3.5-turbo-1106  MapReduce       16385        7628   \n",
       "2   gpt-3.5-turbo-1106  MapReduce       16385        6855   \n",
       "3   gpt-3.5-turbo-1106  MapReduce       16385        7058   \n",
       "4   gpt-3.5-turbo-1106  MapReduce       16385        6969   \n",
       "5                gpt-4  MapReduce        8192        6969   \n",
       "6   gpt-4-1106-preview  MapReduce      128000        6969   \n",
       "7                gpt-4  MapReduce        8192        6827   \n",
       "8                gpt-4  MapReduce        8192        7628   \n",
       "9                gpt-4  MapReduce        8192        6855   \n",
       "10               gpt-4  MapReduce        8192        7058   \n",
       "11  gpt-4-1106-preview  MapReduce      128000        6827   \n",
       "12  gpt-4-1106-preview  MapReduce      128000        7628   \n",
       "13  gpt-4-1106-preview  MapReduce      128000        6855   \n",
       "14  gpt-4-1106-preview  MapReduce      128000        7058   \n",
       "15  gpt-3.5-turbo-1106  MapReduce       16385        6827   \n",
       "16  gpt-3.5-turbo-1106  MapReduce       16385        6969   \n",
       "17  gpt-3.5-turbo-1106  MapReduce       16385        7628   \n",
       "18  gpt-3.5-turbo-1106  MapReduce       16385        6855   \n",
       "19  gpt-3.5-turbo-1106  MapReduce       16385        7058   \n",
       "20               gpt-4  MapReduce        8192        6827   \n",
       "21               gpt-4  MapReduce        8192        6969   \n",
       "22               gpt-4  MapReduce        8192        7628   \n",
       "23               gpt-4  MapReduce        8192        6855   \n",
       "24               gpt-4  MapReduce        8192        7058   \n",
       "25  gpt-4-1106-preview  MapReduce      128000        6855   \n",
       "26  gpt-4-1106-preview  MapReduce      128000        7058   \n",
       "27  gpt-4-1106-preview  MapReduce      128000        6827   \n",
       "28  gpt-4-1106-preview  MapReduce      128000        6969   \n",
       "29  gpt-4-1106-preview  MapReduce      128000        7628   \n",
       "30  gpt-3.5-turbo-1106  MapReduce       16385        6827   \n",
       "31  gpt-3.5-turbo-1106  MapReduce       16385        6969   \n",
       "32  gpt-3.5-turbo-1106  MapReduce       16385        7628   \n",
       "33  gpt-3.5-turbo-1106  MapReduce       16385        6855   \n",
       "34  gpt-3.5-turbo-1106  MapReduce       16385        7058   \n",
       "35               gpt-4  MapReduce        8192        6827   \n",
       "36               gpt-4  MapReduce        8192        6969   \n",
       "37               gpt-4  MapReduce        8192        7628   \n",
       "38               gpt-4  MapReduce        8192        6855   \n",
       "39               gpt-4  MapReduce        8192        7058   \n",
       "40  gpt-4-1106-preview  MapReduce      128000        6827   \n",
       "41  gpt-4-1106-preview  MapReduce      128000        6969   \n",
       "42  gpt-4-1106-preview  MapReduce      128000        7628   \n",
       "43  gpt-4-1106-preview  MapReduce      128000        6855   \n",
       "44  gpt-4-1106-preview  MapReduce      128000        7058   \n",
       "45               gpt-4  MapReduce        8192        8983   \n",
       "46  gpt-4-1106-preview  MapReduce      128000        8983   \n",
       "47  gpt-3.5-turbo-1106  MapReduce       16385        8983   \n",
       "48  gpt-3.5-turbo-1106  MapReduce       16385        8983   \n",
       "49  gpt-3.5-turbo-1106  MapReduce       16385        8983   \n",
       "50  gpt-3.5-turbo-1106  MapReduce       16385        8983   \n",
       "51  gpt-3.5-turbo-1106  MapReduce       16385        8983   \n",
       "52  gpt-3.5-turbo-1106  MapReduce       16385        8983   \n",
       "\n",
       "                                           transcript  \\\n",
       "0    All right. So our next talk is called Hacking...   \n",
       "1    Good morning. As you can see from the title o...   \n",
       "2    Thank you very much, first important question...   \n",
       "3    I was great to be with all of you today. I sa...   \n",
       "4    Welcome, DEF CON 28, the Do No Harm panel. Th...   \n",
       "5    Welcome, DEF CON 28, the Do No Harm panel. Th...   \n",
       "6    Welcome, DEF CON 28, the Do No Harm panel. Th...   \n",
       "7    All right. So our next talk is called Hacking...   \n",
       "8    Good morning. As you can see from the title o...   \n",
       "9    Thank you very much, first important question...   \n",
       "10   I was great to be with all of you today. I sa...   \n",
       "11   All right. So our next talk is called Hacking...   \n",
       "12   Good morning. As you can see from the title o...   \n",
       "13   Thank you very much, first important question...   \n",
       "14   I was great to be with all of you today. I sa...   \n",
       "15   All right. So our next talk is called Hacking...   \n",
       "16   Welcome, DEF CON 28, the Do No Harm panel. Th...   \n",
       "17   Good morning. As you can see from the title o...   \n",
       "18   Thank you very much, first important question...   \n",
       "19   I was great to be with all of you today. I sa...   \n",
       "20   All right. So our next talk is called Hacking...   \n",
       "21   Welcome, DEF CON 28, the Do No Harm panel. Th...   \n",
       "22   Good morning. As you can see from the title o...   \n",
       "23   Thank you very much, first important question...   \n",
       "24   I was great to be with all of you today. I sa...   \n",
       "25   Thank you very much, first important question...   \n",
       "26   I was great to be with all of you today. I sa...   \n",
       "27   All right. So our next talk is called Hacking...   \n",
       "28   Welcome, DEF CON 28, the Do No Harm panel. Th...   \n",
       "29   Good morning. As you can see from the title o...   \n",
       "30   All right. So our next talk is called Hacking...   \n",
       "31   Welcome, DEF CON 28, the Do No Harm panel. Th...   \n",
       "32   Good morning. As you can see from the title o...   \n",
       "33   Thank you very much, first important question...   \n",
       "34   I was great to be with all of you today. I sa...   \n",
       "35   All right. So our next talk is called Hacking...   \n",
       "36   Welcome, DEF CON 28, the Do No Harm panel. Th...   \n",
       "37   Good morning. As you can see from the title o...   \n",
       "38   Thank you very much, first important question...   \n",
       "39   I was great to be with all of you today. I sa...   \n",
       "40   All right. So our next talk is called Hacking...   \n",
       "41   Welcome, DEF CON 28, the Do No Harm panel. Th...   \n",
       "42   Good morning. As you can see from the title o...   \n",
       "43   Thank you very much, first important question...   \n",
       "44   I was great to be with all of you today. I sa...   \n",
       "45  Grad C : Nice . Grad D : OK . Grad A : to {dis...   \n",
       "46  Grad C : Nice . Grad D : OK . Grad A : to {dis...   \n",
       "47  Grad C : Nice . Grad D : OK . Grad A : to {dis...   \n",
       "48  Grad C : Nice . Grad D : OK . Grad A : to {dis...   \n",
       "49  Grad C : Nice . Grad D : OK . Grad A : to {dis...   \n",
       "50  Grad C : Nice . Grad D : OK . Grad A : to {dis...   \n",
       "51  Grad C : Nice . Grad D : OK . Grad A : to {dis...   \n",
       "52  Grad C : Nice . Grad D : OK . Grad A : to {dis...   \n",
       "\n",
       "                                     original summary  \\\n",
       "0   A firsthand look at efforts to improve diversi...   \n",
       "1   Roman Architecture (HSAR 252) Professor Kleine...   \n",
       "2   Stochastic rewriting systems evolving over gra...   \n",
       "3   In typical military operations, the advantage ...   \n",
       "4   It is certainly a time of discovery- though th...   \n",
       "5   It is certainly a time of discovery- though th...   \n",
       "6   It is certainly a time of discovery- though th...   \n",
       "7   A firsthand look at efforts to improve diversi...   \n",
       "8   Roman Architecture (HSAR 252) Professor Kleine...   \n",
       "9   Stochastic rewriting systems evolving over gra...   \n",
       "10  In typical military operations, the advantage ...   \n",
       "11  A firsthand look at efforts to improve diversi...   \n",
       "12  Roman Architecture (HSAR 252) Professor Kleine...   \n",
       "13  Stochastic rewriting systems evolving over gra...   \n",
       "14  In typical military operations, the advantage ...   \n",
       "15  A firsthand look at efforts to improve diversi...   \n",
       "16  It is certainly a time of discovery- though th...   \n",
       "17  Roman Architecture (HSAR 252) Professor Kleine...   \n",
       "18  Stochastic rewriting systems evolving over gra...   \n",
       "19  In typical military operations, the advantage ...   \n",
       "20  A firsthand look at efforts to improve diversi...   \n",
       "21  It is certainly a time of discovery- though th...   \n",
       "22  Roman Architecture (HSAR 252) Professor Kleine...   \n",
       "23  Stochastic rewriting systems evolving over gra...   \n",
       "24  In typical military operations, the advantage ...   \n",
       "25  Stochastic rewriting systems evolving over gra...   \n",
       "26  In typical military operations, the advantage ...   \n",
       "27  A firsthand look at efforts to improve diversi...   \n",
       "28  It is certainly a time of discovery- though th...   \n",
       "29  Roman Architecture (HSAR 252) Professor Kleine...   \n",
       "30  A firsthand look at efforts to improve diversi...   \n",
       "31  It is certainly a time of discovery- though th...   \n",
       "32  Roman Architecture (HSAR 252) Professor Kleine...   \n",
       "33  Stochastic rewriting systems evolving over gra...   \n",
       "34  In typical military operations, the advantage ...   \n",
       "35  A firsthand look at efforts to improve diversi...   \n",
       "36  It is certainly a time of discovery- though th...   \n",
       "37  Roman Architecture (HSAR 252) Professor Kleine...   \n",
       "38  Stochastic rewriting systems evolving over gra...   \n",
       "39  In typical military operations, the advantage ...   \n",
       "40  A firsthand look at efforts to improve diversi...   \n",
       "41  It is certainly a time of discovery- though th...   \n",
       "42  Roman Architecture (HSAR 252) Professor Kleine...   \n",
       "43  Stochastic rewriting systems evolving over gra...   \n",
       "44  In typical military operations, the advantage ...   \n",
       "45  The group discussed the first version of the B...   \n",
       "46  The group discussed the first version of the B...   \n",
       "47  The group discussed the first version of the B...   \n",
       "48  The group discussed the first version of the B...   \n",
       "49  The group discussed the first version of the B...   \n",
       "50  The group discussed the first version of the B...   \n",
       "51  The group discussed the first version of the B...   \n",
       "52  The group discussed the first version of the B...   \n",
       "\n",
       "                                              summary  \\\n",
       "0   Professor Christina Tamba-Hester's talk on Hac...   \n",
       "1   The speaker discusses important developments i...   \n",
       "2   The main goal of the research is to analyze th...   \n",
       "3   The presentation challenged traditional approa...   \n",
       "4   The speaker emphasizes the need to take respon...   \n",
       "5   The DEF CON 28 Do No Harm panel discussed the ...   \n",
       "6   At DEF CON 28, the \"Do No Harm\" panel brought ...   \n",
       "7   In her talk \"Hacking Diversity\", Professor Chr...   \n",
       "8   The lecture explores the architecture of Hercu...   \n",
       "9   The speaker explores the application of combin...   \n",
       "10  The speaker emphasizes the significance of cyb...   \n",
       "11  Professor Christina Tamba-Hester's talk \"Hacki...   \n",
       "12  Today's lecture explored domestic architecture...   \n",
       "13  The speaker expresses appreciation for the cha...   \n",
       "14  The speaker, drawing from their military backg...   \n",
       "15  The talk explores the lack of diversity in the...   \n",
       "16  A panel discussion on the importance of addres...   \n",
       "17  The speaker describes the view from the sea wa...   \n",
       "18  Categorical rewriting theory is a potential me...   \n",
       "19  The article explores traditional approaches to...   \n",
       "20  In her \"Hacking Diversity\" talk, Professor Chr...   \n",
       "21  Healthcare security experts gathered for a dis...   \n",
       "22  The lecture discusses domestic architecture in...   \n",
       "23  The presenter outlined a novel method for anal...   \n",
       "24  In a recent talk, the challenges of cybersecur...   \n",
       "25  The speaker discussed the manipulation of grap...   \n",
       "26  The speaker at a cyber competition drew parall...   \n",
       "27  Professor Christina Tamba-Hester's talk \"Hacki...   \n",
       "28  The DEF CON 28 Do No Harm panel, comprised of ...   \n",
       "29  Today's lecture focused on the domestic archit...   \n",
       "30  Professor Christina Tamba-Hester discusses the...   \n",
       "31  The speaker believes that instead of just patc...   \n",
       "32  The webinar explores the domestic architecture...   \n",
       "33  The webinar discusses the generalization of di...   \n",
       "34  The discussion focused on atypical ways of thi...   \n",
       "35  The webinar \"Hacking Diversity\" by Professor C...   \n",
       "36  The DEF CON 28 panel discussion, featuring exp...   \n",
       "37  The webinar discussed the study of domestic ar...   \n",
       "38  The webinar explores the mathematical connecti...   \n",
       "39  A former military officer discusses the simila...   \n",
       "40  In the \"Hacking Diversity\" webinar, Professor ...   \n",
       "41  At DEF CON 28's \"Do No Harm\" panel, experts in...   \n",
       "42  The webinar \"Habitats at Herculaneum and Early...   \n",
       "43  The webinar discussed the intersection of comp...   \n",
       "44  In the webinar, the speaker compares the strat...   \n",
       "45  The discussion involves Grad A and Grad C, who...   \n",
       "46  Grad A and Grad B engaged in a discussion abou...   \n",
       "47  The discussion involves Grad B and Grad C prov...   \n",
       "48  Grads A and B are both focused on refining the...   \n",
       "49  Grad C and Grad B discuss the concept of the m...   \n",
       "50  Three speakers, Grad C, Grad B, and Grad D, di...   \n",
       "51  Grad A focuses on discussing the middle layer ...   \n",
       "52  Grad C discusses the middle layer of the belie...   \n",
       "\n",
       "                                                rouge  \\\n",
       "0   [{'rouge-1': {'r': 0.13690476190476192, 'p': 0...   \n",
       "1   [{'rouge-1': {'r': 0.11428571428571428, 'p': 0...   \n",
       "2   [{'rouge-1': {'r': 0.08888888888888889, 'p': 0...   \n",
       "3   [{'rouge-1': {'r': 0.1037037037037037, 'p': 0....   \n",
       "4   [{'rouge-1': {'r': 0.06299212598425197, 'p': 0...   \n",
       "5   [{'rouge-1': {'r': 0.14173228346456693, 'p': 0...   \n",
       "6   [{'rouge-1': {'r': 0.1968503937007874, 'p': 0....   \n",
       "7   [{'rouge-1': {'r': 0.11904761904761904, 'p': 0...   \n",
       "8   [{'rouge-1': {'r': 0.15, 'p': 0.34426229508196...   \n",
       "9   [{'rouge-1': {'r': 0.09444444444444444, 'p': 0...   \n",
       "10  [{'rouge-1': {'r': 0.08148148148148149, 'p': 0...   \n",
       "11  [{'rouge-1': {'r': 0.14285714285714285, 'p': 0...   \n",
       "12  [{'rouge-1': {'r': 0.17142857142857143, 'p': 0...   \n",
       "13  [{'rouge-1': {'r': 0.15555555555555556, 'p': 0...   \n",
       "14  [{'rouge-1': {'r': 0.1259259259259259, 'p': 0....   \n",
       "15  [{'rouge-1': {'r': 0.09523809523809523, 'p': 0...   \n",
       "16  [{'rouge-1': {'r': 0.10236220472440945, 'p': 0...   \n",
       "17  [{'rouge-1': {'r': 0.12142857142857143, 'p': 0...   \n",
       "18  [{'rouge-1': {'r': 0.08888888888888889, 'p': 0...   \n",
       "19  [{'rouge-1': {'r': 0.0962962962962963, 'p': 0....   \n",
       "20  [{'rouge-1': {'r': 0.14285714285714285, 'p': 0...   \n",
       "21  [{'rouge-1': {'r': 0.11811023622047244, 'p': 0...   \n",
       "22  [{'rouge-1': {'r': 0.15, 'p': 0.42, 'f': 0.221...   \n",
       "23  [{'rouge-1': {'r': 0.09444444444444444, 'p': 0...   \n",
       "24  [{'rouge-1': {'r': 0.1037037037037037, 'p': 0....   \n",
       "25  [{'rouge-1': {'r': 0.11666666666666667, 'p': 0...   \n",
       "26  [{'rouge-1': {'r': 0.14074074074074075, 'p': 0...   \n",
       "27  [{'rouge-1': {'r': 0.14285714285714285, 'p': 0...   \n",
       "28  [{'rouge-1': {'r': 0.1889763779527559, 'p': 0....   \n",
       "29  [{'rouge-1': {'r': 0.16428571428571428, 'p': 0...   \n",
       "30  [{'rouge-1': {'r': 0.15476190476190477, 'p': 0...   \n",
       "31  [{'rouge-1': {'r': 0.10236220472440945, 'p': 0...   \n",
       "32  [{'rouge-1': {'r': 0.12857142857142856, 'p': 0...   \n",
       "33  [{'rouge-1': {'r': 0.11666666666666667, 'p': 0...   \n",
       "34  [{'rouge-1': {'r': 0.1259259259259259, 'p': 0....   \n",
       "35  [{'rouge-1': {'r': 0.10714285714285714, 'p': 0...   \n",
       "36  [{'rouge-1': {'r': 0.12598425196850394, 'p': 0...   \n",
       "37  [{'rouge-1': {'r': 0.12142857142857143, 'p': 0...   \n",
       "38  [{'rouge-1': {'r': 0.11666666666666667, 'p': 0...   \n",
       "39  [{'rouge-1': {'r': 0.1259259259259259, 'p': 0....   \n",
       "40  [{'rouge-1': {'r': 0.125, 'p': 0.3088235294117...   \n",
       "41  [{'rouge-1': {'r': 0.1968503937007874, 'p': 0....   \n",
       "42  [{'rouge-1': {'r': 0.20714285714285716, 'p': 0...   \n",
       "43  [{'rouge-1': {'r': 0.11666666666666667, 'p': 0...   \n",
       "44  [{'rouge-1': {'r': 0.1259259259259259, 'p': 0....   \n",
       "45  [{'rouge-1': {'r': 0.14736842105263157, 'p': 0...   \n",
       "46  [{'rouge-1': {'r': 0.15789473684210525, 'p': 0...   \n",
       "47  [{'rouge-1': {'r': 0.08421052631578947, 'p': 0...   \n",
       "48  [{'rouge-1': {'r': 0.09473684210526316, 'p': 0...   \n",
       "49  [{'rouge-1': {'r': 0.14736842105263157, 'p': 0...   \n",
       "50  [{'rouge-1': {'r': 0.07368421052631578, 'p': 0...   \n",
       "51  [{'rouge-1': {'r': 0.10526315789473684, 'p': 0...   \n",
       "52  [{'rouge-1': {'r': 0.12631578947368421, 'p': 0...   \n",
       "\n",
       "                                           bert_score           bleu  \\\n",
       "0   (tensor([0.8656]), tensor([0.8255]), tensor([0...  8.954086e-156   \n",
       "1   (tensor([0.8856]), tensor([0.8039]), tensor([0...  6.397942e-157   \n",
       "2   (tensor([0.8576]), tensor([0.7937]), tensor([0...  1.749485e-156   \n",
       "3   (tensor([0.8622]), tensor([0.8058]), tensor([0...   1.587501e-79   \n",
       "4   (tensor([0.8376]), tensor([0.7977]), tensor([0...  1.465172e-156   \n",
       "5   (tensor([0.8701]), tensor([0.8204]), tensor([0...   2.587246e-79   \n",
       "6   (tensor([0.8469]), tensor([0.8214]), tensor([0...   5.467525e-79   \n",
       "7   (tensor([0.8734]), tensor([0.8299]), tensor([0...   2.314046e-79   \n",
       "8   (tensor([0.8820]), tensor([0.8144]), tensor([0...   2.455021e-02   \n",
       "9   (tensor([0.8588]), tensor([0.7954]), tensor([0...   5.637758e-80   \n",
       "10  (tensor([0.8542]), tensor([0.8088]), tensor([0...   2.474221e-79   \n",
       "11  (tensor([0.8674]), tensor([0.8356]), tensor([0...   4.088394e-79   \n",
       "12  (tensor([0.8721]), tensor([0.8257]), tensor([0...   2.647894e-02   \n",
       "13  (tensor([0.8509]), tensor([0.8131]), tensor([0...  2.312113e-155   \n",
       "14  (tensor([0.8527]), tensor([0.8152]), tensor([0...   3.955251e-79   \n",
       "15  (tensor([0.8683]), tensor([0.8199]), tensor([0...  5.181215e-156   \n",
       "16  (tensor([0.8598]), tensor([0.8131]), tensor([0...   2.872619e-79   \n",
       "17  (tensor([0.8759]), tensor([0.8128]), tensor([0...   1.835995e-02   \n",
       "18  (tensor([0.8543]), tensor([0.7944]), tensor([0...   2.004938e-80   \n",
       "19  (tensor([0.8633]), tensor([0.8067]), tensor([0...  3.646898e-156   \n",
       "20  (tensor([0.8670]), tensor([0.8296]), tensor([0...   2.348627e-79   \n",
       "21  (tensor([0.8567]), tensor([0.8202]), tensor([0...  9.377047e-156   \n",
       "22  (tensor([0.8893]), tensor([0.8185]), tensor([0...   1.062791e-02   \n",
       "23  (tensor([0.8400]), tensor([0.8043]), tensor([0...   1.106479e-79   \n",
       "24  (tensor([0.8454]), tensor([0.8051]), tensor([0...  9.906425e-156   \n",
       "25  (tensor([0.8445]), tensor([0.8003]), tensor([0...  5.729872e-156   \n",
       "26  (tensor([0.8441]), tensor([0.8117]), tensor([0...   6.680508e-79   \n",
       "27  (tensor([0.8696]), tensor([0.8361]), tensor([0...  1.147177e-155   \n",
       "28  (tensor([0.8568]), tensor([0.8254]), tensor([0...   1.022824e-78   \n",
       "29  (tensor([0.8804]), tensor([0.8314]), tensor([0...   4.310069e-02   \n",
       "30  (tensor([0.8728]), tensor([0.8286]), tensor([0...   3.458642e-79   \n",
       "31  (tensor([0.8494]), tensor([0.7993]), tensor([0...   4.055700e-80   \n",
       "32  (tensor([0.8618]), tensor([0.8083]), tensor([0...   4.130450e-79   \n",
       "33  (tensor([0.8499]), tensor([0.8025]), tensor([0...  8.666274e-156   \n",
       "34  (tensor([0.8491]), tensor([0.8082]), tensor([0...   4.703612e-79   \n",
       "35  (tensor([0.8634]), tensor([0.8278]), tensor([0...  5.614584e-156   \n",
       "36  (tensor([0.8713]), tensor([0.8216]), tensor([0...   2.175606e-79   \n",
       "37  (tensor([0.8959]), tensor([0.8167]), tensor([0...   2.100801e-79   \n",
       "38  (tensor([0.8608]), tensor([0.8076]), tensor([0...  4.801092e-156   \n",
       "39  (tensor([0.8649]), tensor([0.8212]), tensor([0...   1.068941e-02   \n",
       "40  (tensor([0.8702]), tensor([0.8340]), tensor([0...  1.372786e-155   \n",
       "41  (tensor([0.8574]), tensor([0.8264]), tensor([0...   9.863333e-79   \n",
       "42  (tensor([0.8721]), tensor([0.8339]), tensor([0...   4.749744e-02   \n",
       "43  (tensor([0.8455]), tensor([0.8051]), tensor([0...  1.116947e-155   \n",
       "44  (tensor([0.8529]), tensor([0.8179]), tensor([0...   7.591593e-79   \n",
       "45  (tensor([0.8378]), tensor([0.8253]), tensor([0...  2.441696e-155   \n",
       "46  (tensor([0.8384]), tensor([0.8362]), tensor([0...  4.853597e-155   \n",
       "47  (tensor([0.8486]), tensor([0.8200]), tensor([0...   6.267410e-79   \n",
       "48  (tensor([0.8514]), tensor([0.8359]), tensor([0...   6.916317e-79   \n",
       "49  ([tensor(0.8566)], [tensor(0.8315)], [tensor(0...   7.922619e-79   \n",
       "50  ([tensor(0.8446)], [tensor(0.8214)], [tensor(0...  7.254744e-156   \n",
       "51  ([tensor(0.8463)], [tensor(0.8237)], [tensor(0...  2.191490e-155   \n",
       "52  ([tensor(0.8446)], [tensor(0.8295)], [tensor(0...   6.104099e-79   \n",
       "\n",
       "    time_taken                                            grammar  \\\n",
       "0    21.383893  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "1    11.230562                                                 []   \n",
       "2   115.299044                                                 []   \n",
       "3    14.139802                                                 []   \n",
       "4    93.767647                                                 []   \n",
       "5    11.267398                                                 []   \n",
       "6    16.473476  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "7    13.086216  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "8    14.684876  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "9     8.984848                                                 []   \n",
       "10   12.236066                                                 []   \n",
       "11   29.100684  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "12   39.277412  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "13   55.178707  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "14   23.334041                                                 []   \n",
       "15   22.310365                                                 []   \n",
       "16  220.420688                                                 []   \n",
       "17   32.104075                                                 []   \n",
       "18   16.051817                                                 []   \n",
       "19   14.939501  [Match({'ruleId': 'CYBER_COMPOUNDS', 'message'...   \n",
       "20    9.271456  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "21   12.480605  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "22   13.262237  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "23   12.076730  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "24    9.864205                                                 []   \n",
       "25   28.755662  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "26   39.671920  [Match({'ruleId': 'CYBER_COMPOUNDS', 'message'...   \n",
       "27   29.731003  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "28   37.077160  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "29   39.765496  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "30   29.185579  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "31  304.766041                                                 []   \n",
       "32   39.523345  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "33   36.948316                                                 []   \n",
       "34   36.286263                                                 []   \n",
       "35   14.871728  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "36   13.535113                                                 []   \n",
       "37   15.439435                                                 []   \n",
       "38   15.538087  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "39   13.217274  [Match({'ruleId': 'CYBER_COMPOUNDS', 'message'...   \n",
       "40   44.298810  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "41   70.015324  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "42   59.575349  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "43   49.351651  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "44   37.264941                                                 []   \n",
       "45   28.560694  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "46   53.416301  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "47    9.655459                                                 []   \n",
       "48    7.836615  [Match({'ruleId': 'MORFOLOGIK_RULE_EN_US', 'me...   \n",
       "49    6.554743  [Offset 446, length 9, Rule ID: MORFOLOGIK_RUL...   \n",
       "50    5.529194                                                 []   \n",
       "51    7.556895  [Offset 51, length 14, Rule ID: MORFOLOGIK_RUL...   \n",
       "52    8.170220  [Offset 104, length 9, Rule ID: MORFOLOGIK_RUL...   \n",
       "\n",
       "                                     readability  \\\n",
       "0                            100 words required.   \n",
       "1                            100 words required.   \n",
       "2                            100 words required.   \n",
       "3                            100 words required.   \n",
       "4                            100 words required.   \n",
       "5                            100 words required.   \n",
       "6                            100 words required.   \n",
       "7                            100 words required.   \n",
       "8                            100 words required.   \n",
       "9                            100 words required.   \n",
       "10                           100 words required.   \n",
       "11                           100 words required.   \n",
       "12  score: 17.733878504672898, grade_level: '18'   \n",
       "13  score: 16.031964285714288, grade_level: '16'   \n",
       "14                           100 words required.   \n",
       "15                           100 words required.   \n",
       "16                           100 words required.   \n",
       "17                           100 words required.   \n",
       "18                           100 words required.   \n",
       "19                           100 words required.   \n",
       "20                           100 words required.   \n",
       "21                           100 words required.   \n",
       "22                           100 words required.   \n",
       "23                           100 words required.   \n",
       "24                           100 words required.   \n",
       "25                           100 words required.   \n",
       "26   score: 17.69577099236641, grade_level: '18'   \n",
       "27                           100 words required.   \n",
       "28   score: 19.74571428571429, grade_level: '20'   \n",
       "29  score: 15.386666666666667, grade_level: '15'   \n",
       "30                           100 words required.   \n",
       "31                           100 words required.   \n",
       "32  score: 18.454000000000004, grade_level: '18'   \n",
       "33                           100 words required.   \n",
       "34                           100 words required.   \n",
       "35                           100 words required.   \n",
       "36                           100 words required.   \n",
       "37                           100 words required.   \n",
       "38                           100 words required.   \n",
       "39                           100 words required.   \n",
       "40                           100 words required.   \n",
       "41  score: 17.814000000000004, grade_level: '18'   \n",
       "42  score: 15.858000000000004, grade_level: '16'   \n",
       "43  score: 18.075407407407408, grade_level: '18'   \n",
       "44   score: 17.52339622641509, grade_level: '18'   \n",
       "45  score: 13.933524752475247, grade_level: '14'   \n",
       "46   score: 19.93522556390978, grade_level: '20'   \n",
       "47                           100 words required.   \n",
       "48                           100 words required.   \n",
       "49                           100 words required.   \n",
       "50                           100 words required.   \n",
       "51                           100 words required.   \n",
       "52                           100 words required.   \n",
       "\n",
       "                                               prompt  temperature  \n",
       "0    Write a concise summary of the following: {text}            0  \n",
       "1    Write a concise summary of the following: {text}            0  \n",
       "2    Write a concise summary of the following: {text}            0  \n",
       "3    Write a concise summary of the following: {text}            0  \n",
       "4    Write a concise summary of the following: {text}            0  \n",
       "5    Write a concise summary of the following: {text}            0  \n",
       "6    Write a concise summary of the following: {text}            0  \n",
       "7    Write a concise summary of the following: {text}            0  \n",
       "8    Write a concise summary of the following: {text}            0  \n",
       "9    Write a concise summary of the following: {text}            0  \n",
       "10   Write a concise summary of the following: {text}            0  \n",
       "11   Write a concise summary of the following: {text}            0  \n",
       "12   Write a concise summary of the following: {text}            0  \n",
       "13   Write a concise summary of the following: {text}            0  \n",
       "14   Write a concise summary of the following: {text}            0  \n",
       "15   Write a concise summary of the following: {text}            1  \n",
       "16   Write a concise summary of the following: {text}            1  \n",
       "17   Write a concise summary of the following: {text}            1  \n",
       "18   Write a concise summary of the following: {text}            1  \n",
       "19   Write a concise summary of the following: {text}            1  \n",
       "20   Write a concise summary of the following: {text}            1  \n",
       "21   Write a concise summary of the following: {text}            1  \n",
       "22   Write a concise summary of the following: {text}            1  \n",
       "23   Write a concise summary of the following: {text}            1  \n",
       "24   Write a concise summary of the following: {text}            1  \n",
       "25   Write a concise summary of the following: {text}            1  \n",
       "26   Write a concise summary of the following: {text}            1  \n",
       "27   Write a concise summary of the following: {text}            1  \n",
       "28   Write a concise summary of the following: {text}            1  \n",
       "29   Write a concise summary of the following: {text}            1  \n",
       "30  Write a concise yet comprehensive summary\\n   ...            0  \n",
       "31  Write a concise yet comprehensive summary\\n   ...            0  \n",
       "32  Write a concise yet comprehensive summary\\n   ...            0  \n",
       "33  Write a concise yet comprehensive summary\\n   ...            0  \n",
       "34  Write a concise yet comprehensive summary\\n   ...            0  \n",
       "35  Write a concise yet comprehensive summary\\n   ...            0  \n",
       "36  Write a concise yet comprehensive summary\\n   ...            0  \n",
       "37  Write a concise yet comprehensive summary\\n   ...            0  \n",
       "38  Write a concise yet comprehensive summary\\n   ...            0  \n",
       "39  Write a concise yet comprehensive summary\\n   ...            0  \n",
       "40  Write a concise yet comprehensive summary\\n   ...            0  \n",
       "41  Write a concise yet comprehensive summary\\n   ...            0  \n",
       "42  Write a concise yet comprehensive summary\\n   ...            0  \n",
       "43  Write a concise yet comprehensive summary\\n   ...            0  \n",
       "44  Write a concise yet comprehensive summary\\n   ...            0  \n",
       "45  Compose concise yet comprehensive individual s...            0  \n",
       "46  Compose concise yet comprehensive individual s...            0  \n",
       "47  Compose concise yet comprehensive individual s...            0  \n",
       "48  Compose concise yet comprehensive individual s...            0  \n",
       "49  \\n                    Given a conversation bet...            0  \n",
       "50  \\n                    Given a conversation bet...            0  \n",
       "51  Compose concise yet comprehensive individual s...            0  \n",
       "52  \\n                    Transcript:\\n           ...            0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores.eahd(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Few-Shot Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"question\": \"\"\"\n",
    "Transcript:\n",
    "\n",
    "Grad A : Ah , so comfortable . Grad F : Smooth . Grad A : Mm - hmm . Good . I know that he 's going to like , Taiwan and other places to eat . So . Grad D : On ? Am I on ? Grad A : Yep . Yep . Grad D : I think I 'm on ? Grad B : Yeah . Grad D : Good . Good . Grad A : Bye . Grad B : Actually {disfmarker} Grad F : I just had one of the most frustrating meetings of my career . Grad A : It 's definitely not the most frustrating meeting I 've ever had . Grad D : You a You 're {disfmarker} you remember you 're being recorded at this point . Grad A : Oh , yeah , so , w we didn't yet specify with whom . Professor E : Yeah . Grad F : Yeah . Professor E : Right . Grad A : But um . Professor E : Uh , right . Grad A : So that 's why Keith and I are going to be a little dazed for the first half m the meeting . Professor E : Uh . Grad F : Huh . Yeah , I 'm just gonna sit here and Professor E : Right . Yeah , I {disfmarker} I {disfmarker} I avoided that as long as I could for you guys , Grad F : growl . Professor E : but , uh {disfmarker} Grad F : Yeah . Grad A : Mm - hmm . Grad F : For which we thank you , by the way . Grad A : Are very appreciative , yeah . Professor E : Right . Grad F : I know you were {disfmarker} you were doing that , but , anyway . Grad D : Oh yeah , how di how d exactly did , uh , that paper lead to anti - lock brakes ? Grad F : Oh , I could tell you had a rough day , man ! Grad D : Nah . Grad A : What ? Grad D : I love that story . Grad F : Yeah , it 's a great story . Grad C : OK . Grad F : Oh my goodness . Grad C : Oh yeah , um , Liz suggested we could start off by uh , doing the digits all at the same time . Grad A : What ? Grad D : All at the same time . I don't know if {disfmarker} I would get distracted and confused , probably . Professor E : e Grad A : Really ? Do we have to like , synchronize ? Professor E : Well , I think you 're supposed to {disfmarker} OK . We can do this . Grad F : Are you being silly ? Grad D : Oh wait do we have t Professor E : Everybody 's got different digits , Grad C : Yep . Professor E : right ? Grad D : Yeah , do we have to time them at the same time or just overlapping {disfmarker} Grad F : Uh . Grad A : You 're kidding . Grad C : No , no , just {disfmarker} just start whenever you want . Professor E : No . Grad A : And any rate ? Professor E : e yeah , the Grad F : Alright . Professor E : Well , they {disfmarker} they have s they have the close talking microphones for each of us , Grad A : Yeah , that 's true . Professor E : so {disfmarker} Grad C : Yeah . Professor E : yeah , there 's separate channels . Grad F : Alright . Grad A : OK . Grad C : Yeah . Professor E : So when I say Grad F : Just plug one ear . Grad A : You lose . Professor E : OK . Grad F : OK , bye ! That was a great meeting ! Professor E : Right . Grad D : Alright . Grad F : So - {vocalsound} Now , uh , why ? Grad C : Just to save time . Grad F : OK . Grad C : Does matter for them . Grad A : Are we gonna start all our meetings out that way from now on ? Professor E : No . Grad A : Oh . Too bad . I kinda like it . Grad F : Well , could we ? Grad D : It 's strangely satisfying . Grad A : Yeah . It 's a ritual . Grad D : Are we to r Just to make sure I know what 's going on , we 're talking about Robert 's thesis proposal today ? Is that Grad C : We could . \n",
    "\n",
    "Given a transcripts between multiple speakers above, provide a concise summary within 200 words for each speaker highlighting their key learning points or contributions with the given format below:\n",
    "\n",
    "Also add a \"Overall Summary\" section to summarise the entire discussion.\n",
    "\n",
    "\"\"\",\n",
    "        \n",
    "        \"answer\":\"\"\"\n",
    "\n",
    "Grad A: Grad A expresses comfort and satisfaction, mentioning someone's upcoming travels to Taiwan for food. They confirm Grad D is on the call and later discuss being recorded. Despite initial confusion, they thank Professor E for delaying a topic. Grad A seems interested in starting meetings with a synchronized ritual.\n",
    "\n",
    "Grad D: Grad D questions if they are on the call and later asks about the connection between a paper and anti-lock brakes. Despite being told the story before, Grad D expresses enthusiasm. They also inquire about the meeting's agenda, focusing on Robert's thesis proposal.\n",
    "\n",
    "Grad F: Grad F shares frustration over a recent career meeting but acknowledges it's not the worst. They commend Professor E for delaying a topic to spare them from confusion. Grad F shows interest in a story about the paper and anti-lock brakes and proposes starting meetings with a synchronized ritual.\n",
    "\n",
    "Professor E: Professor E explains the delayed topic, addressing the confusion caused by recording. They discuss the possibility of starting meetings with a synchronized ritual and clarify the meeting agenda, focusing on Robert's thesis proposal.\n",
    "\n",
    "Grad C: Grad C suggests starting the meeting with everyone saying their digits simultaneously. They clarify the lack of synchronization requirement and propose it to save time. Grad C also mentions the discussion of Robert's thesis proposal.\n",
    "\n",
    "Overall Summary: The group discussed the first version of the Bayes-net used to work out a user's intentions when asking for directions from a navigation device. Three intentions were identified: Vista (to view), Enter (to visit) and Tango (to approach). The structure of the belief-net comprises, firstly, a feature layer, which includes linguistic, discourse and world knowledge information that can be gleaned from the data. It is possible for these variables to form thematic clusters( eg \"entrance\", \"type of object\", \"verb\"), each one with a separate middle layer.  At this stage, all the actual probabilities are ad-hoc and hand-coded. However, there has been progress in the design and organisation of experiments, that will eventually provide data more useful and appropriate for this task.\n",
    "\n",
    "\"\"\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"question\": \"\"\"\n",
    "Transcript:\n",
    "\n",
    "Project Manager : {vocalsound} I just forgot their name , so uh you're i sorry , I just forgot them all . So {disfmarker} {vocalsound} I have to write it down . Marketing : {vocalsound} Okay . Project Manager : So {disfmarker} Marketing : Fine . Project Manager : Do you know them or {disfmarker} Marketing : The names ? Project Manager : Yeah . Marketing : For for for my sur um Project Manager : Yeah . Marketing : Jens . Project Manager : Yeah , no , but your b your surname . Marketing : Uh Damman . D_ A_ W_ . Project Manager : W_O_ da . Okay . Marketing : Uh uh M_ M_ . I mean M_ . Double M_ . Project Manager : Okay . And what's your name ? User Interface : Paul Wiezer . Paul Wiezer . Project Manager : W_I_E_S_ z Z_ or S_ ? User Interface : A_ E_ Z_ zee zee Project Manager : Uh uh zee {gap} . Okay . User Interface : E_ R_ . Project Manager : What's your name ? Industrial Designer : Uh Martijn . Project Manager : Yeah , but your surname . {vocalsound} Your surname . Industrial Designer : What ? Uh Abbing . A_ B_ B_ I_ N_ G_ . Project Manager : Okay , thanks . User Interface : Uh . Industrial Designer : I was a little short on time , Project Manager : Yeah , me too , so that's not {disfmarker} Industrial Designer : but {disfmarker} User Interface : Yeah , same here . Project Manager : No no no , I just fi first my {disfmarker} {vocalsound} Marketing : Oh . {vocalsound} Sorry . User Interface : Uh let's see . Which one was mine ? Project Manager : So let's have a look , we have forty minutes , so it's it's more than enough . {gap} Okay , perfect . So we have {disfmarker} Oh no , what's that ? So so we have uh forty minutes for this uh for this second meeting , and we have to make uh sure that we going t that we are sure , that we are , User Interface : Good . Project Manager : that we know what we're going to make uh th what the product is going to like {disfmarker} look like . Uh first I have the notes of the last meeting , so I showed uh show them to you . Oh , sorry about that , I just escape this one . How do I escape this ? How do I I escape this s uh presentation ? Industrial Designer : What ? User Interface : Uh left . Industrial Designer : Uh {disfmarker} Project Manager : Ah okay . User Interface : So {disfmarker} Industrial Designer : Just {disfmarker} Yeah . Project Manager : And show , sorry . Okay , so let's have a look s at this one . Okay , so the f the f the points we had last meeting was the um {disfmarker} Should be a univ uh universal remote control {disfmarker} No , that's {disfmarker} I uh s I just got a email from the from the personal coach and it should be a T_V_ remote control only . So have you changed that part ? Marketing : {vocalsound} User Interface : Okay . Marketing : Okay . {vocalsound} Project Manager : Um so {disfmarker} yeah , it still has to be uh f a r a remote control for kids and elderly . It's it's still the same . Um {disfmarker} All these points uh we have to look at . You all know them . But uh there's another point . The um uh the main uh people of interest of this company are forty plus people . So they're old and not younger people . So we have to look at that as well . 'Specially old people , maybe bi bigger buttons or something , I dunno . User Interface : Yeah , okay . Project Manager : Uh so {disfmarker} So {disfmarker} yeah , that's it , so just you can do your presentation for uh {disfmarker} User Interface : Which one first ? Marketing : Okay . Project Manager : Oh it doesn't matter , just start with the {disfmarker} User Interface : Okay . Marketing : Mm . Uh {disfmarker} User Interface : Functional requirements , yeah Marketing : Okay . Well my name is Jens Damman , but we're in a group , and I I will start it . Wait . Um I've used a marketing report on uh the site . Uh I think you've uh read it too . Uh and uh f and furthermore I uh surfed the o the other site . Project Manager : I I didn't read i read it , so it's not for me , Marketing : You didn't read it ? Project Manager : I didn't get it uh anyway . User Interface : No , I didn don't thing we got it . Project Manager : It's only for you . Marketing : Oh okay , I I was the only one who get it . Project Manager : Yeah . User Interface : Yes . Marketing : Okay it was uh uh uh um um {vocalsound} a report about uh an experiment with uh a lot of users . And uh they had a lot of findings in their report uh with statistical uh uh uh thing uh with statistical uh proof . So I um I had three pages with findings and sev a lot of uh a lot of findings . So we can use this uh to uh create our own remote control . Uh seventy five percent of the users find uh most remote controls ugly . Yeah , I think uh uh that's a lot , so we have to make a beautiful remote control . Uh eighty percent of users would spend when uh a remote control will l uh look fancy . I think this fits uh at the {vocalsound} uh what what uh Michael said about uh older people . Older people will uh spend more money uh for uh something uh uh what's good . Because younger people are more critical uh about uh uh where they spend their money money at . Uh seventy five percent uh seventy five percent of the users say they zap a lot . Well okay , that's uh normal . I think uh we we have to make uh good zap buttons . But that's one of our requirements . Project Manager : The last point is quite an interesting {disfmarker} {vocalsound} Marketing : Yes , fifty percent of users say they only use ten percent of the buttons . Project Manager : So Marketing : Um Martijn alr already said it . Project Manager : if we {disfmarker} Yeah . Marketing : And uh maybe our uh fold open system is is a good one , but {disfmarker} I don't think it's uh Project Manager : Yeah , we should have the ten percent on the on the top , Marketing : reachable . Project Manager : then you're you're {disfmarker} Marketing : Yeah , the ten percent on the top , yeah . Industrial Designer : Yeah . Marketing : That that's a good one . Um uh page two . Remote controls are often lost somewhere in the room . That's exactly what we said about um maybe a home station for uh for it uh to uh recharge the batteries or something . Uh I thought mo maybe we could make a clap system , so when you {vocalsound} clap your hands it will beep or something . Uh you must find it uh quickly . User Interface : Uh . Maybe just a button on the home station . So remote control beeps when you click that button on the home station . Marketing : Okay , yeah . Yeah , we can uh combine that . Uh it takes too much time to learn how to use a r new remote control . Uh I think we must t uh take a look at this . It's only uh th thirty four of the {vocalsound} thirty four percent . But it's uh a tough one . Because if we make a ha whole new product , our own style , we we c uh this is so difficult , uh a difficulty I think . Uh next , remote controls are bad for R_S_I_ . Yeah , but only if they zap a lot , and they watch over five hours T_V_ or something . I don't {disfmarker} We we haven't {disfmarker} Uh we mustn't look too much at uh the last point . Okay , last page .\n",
    "\n",
    "\n",
    "Given a transcripts between multiple speakers above, provide a concise summary within 200 words for each speaker highlighting their key learning points or contributions with the given format below:\n",
    "\n",
    "Also add a \"Overall Summary\" section to summarise the entire discussion.\n",
    "\n",
    "\"\"\",\n",
    "        \n",
    "        \"answer\":\"\"\"\n",
    "\n",
    "Project Manager: The Project Manager starts the meeting with some difficulty recalling names and apologizes. They quickly gather the names and surnames of team members, emphasizing the need for efficient time management. The Project Manager discusses the focus on a TV remote control for kids and elderly users, reiterating key points from the last meeting and highlighting the target audience of forty-plus individuals. The manager directs the team to present their progress.\n",
    "\n",
    "User Interface: The User Interface team member, Paul Wiezer, provides insights into functional requirements for the remote control. The team discusses findings from a marketing report, emphasizing the importance of aesthetics and functionality. They propose a fold-open system and a home station with a clap system or a button for finding lost remote controls quickly. The team addresses the challenge of user learning curves and potential risks of repetitive strain injuries (RSI).\n",
    "\n",
    "Marketing: Jens Damman from the Marketing team presents the marketing report findings, emphasizing user preferences for aesthetically pleasing remote controls. They propose incorporating these findings into the design, such as making buttons for the top ten percent of frequently used functions. Marketing suggests a home station with a button to locate a lost remote control and discusses challenges related to product adoption and the impact on RSI for heavy users.\n",
    "\n",
    "Industrial Designer: Martijn Abbing, the Industrial Designer, briefly mentions time constraints but aligns with the proposed solutions, including the top-ten buttons on the remote and the home station. The team collectively discusses potential design considerations, such as larger buttons for older users.\n",
    "\n",
    "Overall Summary: This meeting was about the functional design of the remote control. Firstly, Marketing gave a presentation on functional requirements. Group decided to focus on the fancy and fashionable look, usability, and different colors. Next, User Interface gave a presentation on the technical function design. Also, the group discussed this topic, and they decided to design the menu buttons of the remote similar to the mobile phone. Then, Industrial Designer gave a presentation on the working design. Group mates discussed deciding on the use of LED light on the buttons to indicate the transmitting of the Morse code when pressing the button. They also decided to use a more intelligent chip than the standard one when the circuit was closed, it would produce the pattern. For the age group, they would target the age group below forty since it was a young market.\n",
    "\n",
    "\"\"\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"question\": \"\"\"\n",
    "Transcript: \n",
    "\n",
    "The Chair (Hon. Anthony Rota (NipissingTimiskaming, Lib.)) : I call this meeting to order. Welcome to the sixth meeting of the House of Commons Special Committee on the COVID-19 pandemic. Today's meeting is taking place by videoconference. Before speaking, please wait until I recognize you by name. When you are ready to speak, please activate your mic. When you are not speaking, leave your mic on mute. Of course, change the language when you change the language on the screen.  I would remind hon. members that if you want to speak English, you should be on the English channel; if you want to speak French, you should be on the French channel; and should you wish to alternate between the two languages, as I just did, you should change the channel to the language that you are speaking, each time you switch languages. In addition, please direct your remarks through the chair and speak slowly and clearly at all times to help our interpreters. Finally, for members who will be speaking, we strongly recommend that you use a headset. I recommend the headset for your fellow members, but also for the interpreters as it gets loud, up and down, and it squeaks. It really does make it difficult for them if you do not have the prescribed headsets. We'll go on to ministerial announcements. I understand that there are no ministerial announcements today, so we will proceed to presenting petitions, for a period not exceeding 15 minutes. I would like to remind members that any petition presented during a meeting of the special committee must have already been certified by the clerk of petitions. We will now proceed to presenting petitions. Ms. Heather McPherson (Edmonton Strathcona, NDP) : Thank you, Mr. Chair. World Maternal Mental Health Day took place last week, and today I'd like to take a moment to present a very important petition on behalf of the Canadian Perinatal Mental Health Collaborative. Whereas perinatal mood and anxiety disorders are the most common obstetrical complication, whereas in Canada and worldwide 20% of women and 10% of men suffer from a perinatal mental illness, resulting in an annual economic cost to Canada of approximately $11 billion, and whereas the U.K., Australia and parts of the U.S. have perinatal mental health strategies and screening guidelines in place and Canada does not, the Canadian Perinatal Mental Health Collaborative is calling upon the House of Commons in Parliament assembled to create a national perinatal mental health strategy that will provide direction, policy and funding to develop specialized, comprehensive perinatal mental health care services, which include universal screening and timely access to treatment for all women and men during pregnancy and the postpartum period. Mr. Scott Reid (LanarkFrontenacKingston, CPC) : Thank you, Mr. Chair. My petition relates to cystic fibrosis. If we were in the House now, as May is Cystic Fibrosis Awareness Month, one of the days this month we would all be wearing yellow roses in sympathy and solidarity with those who suffer from what is the number one disease killer in Canada of young people. The petitioners have asked us to look at the situation with the Patented Medicine Prices Review Board, which is scheduled to go through some important and potentially detrimental regulatory changes very soon. They ask that the amendments to the Patented Medicine Prices Review Board be rescinded, as these will restrict Canadians from receiving life-saving medications for cystic fibrosis and other illnesses, but in particular, a medicine called Trikafta, which can have the effect of treating cystic fibrosis in the case of 90% of cystic fibrosis sufferers. They ask the government to work with the provinces to find a strategy to jointly allow for the delivery of this life-saving medicine to Canadians across the country and to take a leadership role in negotiating a price for gene modulators throughout all the provinces of Canada. Ms. Elizabeth May (SaanichGulf Islands, GP) : Thank you, Mr. Chair. It's an honour to take the mike today, with all colleagues here. It's good to see you all virtually and safe. Petitioners in my community point out in this petition, which, of course, predates the pandemic, that the family doctor shortage is severe in this country. Nearly five million Canadians lack a regular family doctor. This problem is particularly profound in more rural areas, including, as the petitioners reference, the community in which I live, Sydney, British Columbia. We have a very significant crisis and a lack of family doctors. The petitioners call on the government to work with provinces and territories to find a collaborative, holistic solution so that every Canadian has a family doctor and we address the family doctor shortage. Mr. Brad Vis (MissionMatsquiFraser Canyon, CPC) : Good morning, Mr. Chair. I'm presenting a timely petition today that emphasizes the concerns constituents in my riding of MissionMatsquiFraser Canyon have with the Liberal government's inherently flawed and undemocratic approach to firearms legislation and regulation. The petitioners call upon the Government of Canada to stop targeting law-abiding firearms owners; to cancel all plans to confiscate firearms legally owned by federally licensed RCMP-vetted Canadians; to focus taxpayer dollars where they will actually increase public safety, which is on keeping at-risk youth from being involved in gangs and on anti-gang enforcement; and to provide our men and women in uniform at the Canada Border Services Agency with the resources they need to stop the flow of illegal guns into this country. Through this petition, my constituents take issue with how the Liberal government continues to target law-abiding firearms owners instead of the gangs, drug traffickers and illegal weapons smugglers responsible for the violence in our communities. They note that the use of the phrase military-style assault rifle is purely political posturing, as the term is undefined in Canadian law. They also draw attention to the numerous inaccuracies about current firearms legislation and regulation The Chair : I'd like to remind the honourable members that this is a concise prcis of what a petition says, not a speech. I'll let Mr. Vis continue. I'm sure he'll be very brief in wrapping up. Mr. Brad Vis : Yes. Thank you, Mr. Chair. That's sufficient. The Chair : Okay. Now we'll go to Mr. Johns. Mr. Gord Johns (CourtenayAlberni, NDP) : Thank you, Mr. Chair. It's a huge honour to table e-petition 2512, which was signed by 1,198 petitioners, primarily from the province of Nova Scotia. The Province of Nova Scotia invited multinational companies to scope out and develop expansive open-net salmon farming operations. The petitioners cite that the expansion would increase environmental degradation, as seen in similar aquaculture operations in British Columbia, Newfoundland, Norway, Vietnam and elsewhere in the world. It also, they cite, would pose risks to native fish stocks, pollute coastal ecosystems, impair at-risk wild Atlantic salmon, and threaten established fisheries and tourism operations. They also raise concerns that open-net fish farming would not create significant employment and would undermine existing lobster and other fisheries. They are calling on the government to uphold Bill C-68 and species-at-risk legislation, protect our oceans, ban expansion of open-net finfish aquaculture in our oceans, work to phase out any existing open-net fish farming operations currently in place and, lastly, invest in land-based, closed-containment finfish aquaculture. I want to thank these petitioners for fighting for clean oceans, for their local economy and for the well-being of Nova Scotia. Mr. Paul Manly (NanaimoLadysmith, GP) : Thank you, Mr. Chair. This petition was signed and sent in by constituents of my riding of NanaimoLadysmith. It calls upon the House of Commons to commit to upholding the UN Declaration on the Rights of Indigenous Peoples and the calls to action from the Truth and Reconciliation Commission of Canada by immediately halting all existing and planned construction of the Coastal GasLink project on Wet'suwet'en territory, ordering the RCMP to dismantle its exclusion zone and stand down, scheduling nation-to-nation talks between the Wet'suwet'en nation and the federal and provincial governmentssomething that has already happened, thankfullyand prioritizing the real implementation of the UN Declaration on the Rights of Indigenous Peoples. Ms. Yasmin Ratansi (Don Valley East, Lib.) : Thank you, Mr. Chair. I have the pleasure of presenting a petition on behalf of my constituents of Don Valley East. The petitioners are asking that the Government of Canada not provide any financial assistance to Canadian airlines until they promptly provide full refunds for flights that were cancelled due to COVID-19. They are asking the same for any foreign airlines that fly to, within or from Canada. The petitioners feel that these Canadians are facing economic hardship and need a refund. The Chair : We'll now proceed to questioning ministers. The first question will go to Mr. Albas. Mr. Dan Albas (Central OkanaganSimilkameenNicola, CPC) : Thank you, Mr. Chair. Today we've learned that federal workers have been told to ignore obvious signs of fraud when it comes to applying for government benefits. Can the Prime Minister confirm that 200,000 applications have been flagged as potentially fraudulent? Right Hon. Justin Trudeau (Prime Minister) : Thank you, Mr. Chair. Our priority from the beginning has been to make sure that Canadians get the support they need. We moved very quickly to get the Canada emergency response benefit out, to get the wage subsidy out and to help Canadians in this unprecedented situation. We recognize there will be challenges, and we are going to work through those challenges. Our priority every step of the way was to make sure we helped as many Canadians as possible. Mr. Dan Albas : Mr. Chair, can the Prime Minister confirm that the instruction has been given to federal employees to ignore these 200,000 applications being flagged as potentially fraudulent? This is important. Right Hon. Justin Trudeau : Our focus has been on helping as many people as we possible can. Our decision from the very beginning was to get the help out to people and figure out, with retroactive action if necessary, where and when there may have been fraudulent use. Our priority was getting that help out. Mr. Dan Albas : Mr. Chair, this came from a memo issued by a deputy minister. Did the minister's office or the Prime Minister sign off on this memo? Right Hon. Justin Trudeau : Again, in this unprecedented situation, our focus has been on helping as many people as possible, as quickly as possible. Other parties might have made a different choice had they been in government, but our focus was getting help to people when they needed it as quickly as possible and cleaning it up afterwards. Mr. Dan Albas : Mr. Chair, I asked a very simple question. Did the Prime Minister or his minister sign off on this memo that was issued by the deputy minister, yes or no? Right Hon. Justin Trudeau : Mr. Chair, we have been focused entirely on getting help to Canadians when they need it, and that has meant that yes, there will be things we will need to clean up after the fact and work to fix, but getting that help into Canadians' pockets during this pandemic was our priority. Mr. Dan Albas : I'm asking the Prime Minister to show some accountability. Did he or his office sign off on this memo? Right Hon. Justin Trudeau : Mr. Chair, my office and I have been absolutely focused on getting the necessary help to Canadians. Perhaps, as Mr. Albas points out, other parties would have been slower to get the money out. We were flowing money to people who needed it.\n",
    "\n",
    "Given a transcripts between multiple speakers above, provide a concise summary within 200 words for each speaker highlighting their key learning points or contributions with the given format below:\n",
    "\n",
    "Also add a \"Overall Summary\" section to summarise the entire discussion.\n",
    "\n",
    "\"\"\",\n",
    "        \n",
    "        \"answer\":\"\"\"\n",
    "\n",
    "The Chair (Hon. Anthony Rota): The Chair establishes meeting rules and emphasizes language channels, mic usage, and headset recommendations. They move on to petitions, covering topics like perinatal mental health, changes to the Patented Medicine Prices Review Board, the shortage of family doctors, firearms legislation concerns, open-net salmon farming, the Coastal GasLink project, and airline refunds.\n",
    "\n",
    "Ms. Heather McPherson (Edmonton Strathcona, NDP): Presents a petition on World Maternal Mental Health Day, urging the creation of a national perinatal mental health strategy.\n",
    "\n",
    "Mr. Scott Reid (LanarkFrontenacKingston, CPC): Discusses a petition related to cystic fibrosis, calling for rescinding amendments to the Patented Medicine Prices Review Board.\n",
    "\n",
    "Ms. Elizabeth May (SaanichGulf Islands, GP): Highlights a petition addressing the severe family doctor shortage in Canada and urges collaboration for a solution.\n",
    "\n",
    "Mr. Brad Vis (MissionMatsquiFraser Canyon, CPC): Presents a petition on firearms legislation, emphasizing the flawed approach and its impact on law-abiding owners.\n",
    "\n",
    "Mr. Gord Johns (CourtenayAlberni, NDP): Presents a petition against expanding open-net salmon farming, citing environmental and economic concerns.\n",
    "\n",
    "Mr. Paul Manly (NanaimoLadysmith, GP): Presents a petition calling for upholding the UN Declaration on the Rights of Indigenous Peoples regarding the Coastal GasLink project.\n",
    "\n",
    "Ms. Yasmin Ratansi (Don Valley East, Lib.): Presents a petition urging the government not to provide financial assistance to airlines without refunding canceled flights.\n",
    "\n",
    "Mr. Dan Albas (Central OkanaganSimilkameenNicola, CPC): Questions the Prime Minister about a memo instructing federal workers to ignore potential fraud in benefit applications.\n",
    "\n",
    "Right Hon. Justin Trudeau (Prime Minister): Defends the government's focus on quick assistance during the pandemic, acknowledging challenges and the need for retrospective action. Deflects accountability on signing off the memo, emphasizing the priority of rapid aid over bureaucratic details.\n",
    "\n",
    "Overall Summary: The whole meeting was a special Committee on the COVID-19 Pandemic. After some regulations proposed by The Chair, the members presented many petitions on behalf of different areas. Then the meeting proceeded to questioning ministers, the attendees asked for the reasons that the government put easy policy for fraudulence and tax evasion of businessmen. Moreover, the participants required government support under the COVID-19 Pandemic, not only for the elderly and vulnerable people, but also for energy resources and tourism sectors. At the same time, the exact funding from the government should be given to green economies including agriculture and forestry. In addition, the meeting also discussed the current situations of different sectors such as employment, fishing and tourism, oil and gas and business affected by the Covid-19 and called for government support for these sectors. Last but not least, the attendees required strict implementations of the laws and appealed for process following. They wanted a transparency and open environment for voting and debating under the precondition of community safety. Also, they wanted affordable medication including vaccines as a part of a sound health care system for their people.\n",
    "\n",
    "\"\"\"\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(examples)):\n",
    "    cleaned_text = re.sub(r'\\s*{\\s*([^}]+)\\s*}\\s*', ' ', examples[i]['question'])\n",
    "    examples[i]['question'] = cleaned_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': '\\nTranscript:\\n\\nGrad A : Ah , so comfortable . Grad F : Smooth . Grad A : Mm - hmm . Good . I know that he \\'s going to like , Taiwan and other places to eat . So . Grad D : On ? Am I on ? Grad A : Yep . Yep . Grad D : I think I \\'m on ? Grad B : Yeah . Grad D : Good . Good . Grad A : Bye . Grad B : Actually Grad F : I just had one of the most frustrating meetings of my career . Grad A : It \\'s definitely not the most frustrating meeting I \\'ve ever had . Grad D : You a You \\'re you remember you \\'re being recorded at this point . Grad A : Oh , yeah , so , w we didn\\'t yet specify with whom . Professor E : Yeah . Grad F : Yeah . Professor E : Right . Grad A : But um . Professor E : Uh , right . Grad A : So that \\'s why Keith and I are going to be a little dazed for the first half m the meeting . Professor E : Uh . Grad F : Huh . Yeah , I \\'m just gonna sit here and Professor E : Right . Yeah , I I I avoided that as long as I could for you guys , Grad F : growl . Professor E : but , uh Grad F : Yeah . Grad A : Mm - hmm . Grad F : For which we thank you , by the way . Grad A : Are very appreciative , yeah . Professor E : Right . Grad F : I know you were you were doing that , but , anyway . Grad D : Oh yeah , how di how d exactly did , uh , that paper lead to anti - lock brakes ? Grad F : Oh , I could tell you had a rough day , man ! Grad D : Nah . Grad A : What ? Grad D : I love that story . Grad F : Yeah , it \\'s a great story . Grad C : OK . Grad F : Oh my goodness . Grad C : Oh yeah , um , Liz suggested we could start off by uh , doing the digits all at the same time . Grad A : What ? Grad D : All at the same time . I don\\'t know if I would get distracted and confused , probably . Professor E : e Grad A : Really ? Do we have to like , synchronize ? Professor E : Well , I think you \\'re supposed to OK . We can do this . Grad F : Are you being silly ? Grad D : Oh wait do we have t Professor E : Everybody \\'s got different digits , Grad C : Yep . Professor E : right ? Grad D : Yeah , do we have to time them at the same time or just overlapping Grad F : Uh . Grad A : You \\'re kidding . Grad C : No , no , just just start whenever you want . Professor E : No . Grad A : And any rate ? Professor E : e yeah , the Grad F : Alright . Professor E : Well , they they have s they have the close talking microphones for each of us , Grad A : Yeah , that \\'s true . Professor E : so Grad C : Yeah . Professor E : yeah , there \\'s separate channels . Grad F : Alright . Grad A : OK . Grad C : Yeah . Professor E : So when I say Grad F : Just plug one ear . Grad A : You lose . Professor E : OK . Grad F : OK , bye ! That was a great meeting ! Professor E : Right . Grad D : Alright . Grad F : So - Now , uh , why ? Grad C : Just to save time . Grad F : OK . Grad C : Does matter for them . Grad A : Are we gonna start all our meetings out that way from now on ? Professor E : No . Grad A : Oh . Too bad . I kinda like it . Grad F : Well , could we ? Grad D : It \\'s strangely satisfying . Grad A : Yeah . It \\'s a ritual . Grad D : Are we to r Just to make sure I know what \\'s going on , we \\'re talking about Robert \\'s thesis proposal today ? Is that Grad C : We could . \\n\\nGiven a transcripts between multiple speakers above, provide a concise summary within 200 words for each speaker highlighting their key learning points or contributions with the given format below:\\n\\nAlso add a \"Overall Summary\" section to summarise the entire discussion.\\n\\n',\n",
       "  'answer': '\\n\\nGrad A: Grad A expresses comfort and satisfaction, mentioning someone\\'s upcoming travels to Taiwan for food. They confirm Grad D is on the call and later discuss being recorded. Despite initial confusion, they thank Professor E for delaying a topic. Grad A seems interested in starting meetings with a synchronized ritual.\\n\\nGrad D: Grad D questions if they are on the call and later asks about the connection between a paper and anti-lock brakes. Despite being told the story before, Grad D expresses enthusiasm. They also inquire about the meeting\\'s agenda, focusing on Robert\\'s thesis proposal.\\n\\nGrad F: Grad F shares frustration over a recent career meeting but acknowledges it\\'s not the worst. They commend Professor E for delaying a topic to spare them from confusion. Grad F shows interest in a story about the paper and anti-lock brakes and proposes starting meetings with a synchronized ritual.\\n\\nProfessor E: Professor E explains the delayed topic, addressing the confusion caused by recording. They discuss the possibility of starting meetings with a synchronized ritual and clarify the meeting agenda, focusing on Robert\\'s thesis proposal.\\n\\nGrad C: Grad C suggests starting the meeting with everyone saying their digits simultaneously. They clarify the lack of synchronization requirement and propose it to save time. Grad C also mentions the discussion of Robert\\'s thesis proposal.\\n\\nOverall Summary: The group discussed the first version of the Bayes-net used to work out a user\\'s intentions when asking for directions from a navigation device. Three intentions were identified: Vista (to view), Enter (to visit) and Tango (to approach). The structure of the belief-net comprises, firstly, a feature layer, which includes linguistic, discourse and world knowledge information that can be gleaned from the data. It is possible for these variables to form thematic clusters( eg \"entrance\", \"type of object\", \"verb\"), each one with a separate middle layer.  At this stage, all the actual probabilities are ad-hoc and hand-coded. However, there has been progress in the design and organisation of experiments, that will eventually provide data more useful and appropriate for this task.\\n\\n'},\n",
       " {'question': '\\nTranscript:\\n\\nProject Manager : I just forgot their name , so uh you\\'re i sorry , I just forgot them all . So  I have to write it down . Marketing : Okay . Project Manager : So Marketing : Fine . Project Manager : Do you know them or Marketing : The names ? Project Manager : Yeah . Marketing : For for for my sur um Project Manager : Yeah . Marketing : Jens . Project Manager : Yeah , no , but your b your surname . Marketing : Uh Damman . D_ A_ W_ . Project Manager : W_O_ da . Okay . Marketing : Uh uh M_ M_ . I mean M_ . Double M_ . Project Manager : Okay . And what\\'s your name ? User Interface : Paul Wiezer . Paul Wiezer . Project Manager : W_I_E_S_ z Z_ or S_ ? User Interface : A_ E_ Z_ zee zee Project Manager : Uh uh zee . Okay . User Interface : E_ R_ . Project Manager : What\\'s your name ? Industrial Designer : Uh Martijn . Project Manager : Yeah , but your surname . Your surname . Industrial Designer : What ? Uh Abbing . A_ B_ B_ I_ N_ G_ . Project Manager : Okay , thanks . User Interface : Uh . Industrial Designer : I was a little short on time , Project Manager : Yeah , me too , so that\\'s not Industrial Designer : but User Interface : Yeah , same here . Project Manager : No no no , I just fi first my  Marketing : Oh . Sorry . User Interface : Uh let\\'s see . Which one was mine ? Project Manager : So let\\'s have a look , we have forty minutes , so it\\'s it\\'s more than enough . Okay , perfect . So we have Oh no , what\\'s that ? So so we have uh forty minutes for this uh for this second meeting , and we have to make uh sure that we going t that we are sure , that we are , User Interface : Good . Project Manager : that we know what we\\'re going to make uh th what the product is going to like look like . Uh first I have the notes of the last meeting , so I showed uh show them to you . Oh , sorry about that , I just escape this one . How do I escape this ? How do I I escape this s uh presentation ? Industrial Designer : What ? User Interface : Uh left . Industrial Designer : Uh Project Manager : Ah okay . User Interface : So Industrial Designer : Just Yeah . Project Manager : And show , sorry . Okay , so let\\'s have a look s at this one . Okay , so the f the f the points we had last meeting was the um Should be a univ uh universal remote control No , that\\'s I uh s I just got a email from the from the personal coach and it should be a T_V_ remote control only . So have you changed that part ? Marketing : User Interface : Okay . Marketing : Okay . Project Manager : Um so yeah , it still has to be uh f a r a remote control for kids and elderly . It\\'s it\\'s still the same . Um All these points uh we have to look at . You all know them . But uh there\\'s another point . The um uh the main uh people of interest of this company are forty plus people . So they\\'re old and not younger people . So we have to look at that as well . \\'Specially old people , maybe bi bigger buttons or something , I dunno . User Interface : Yeah , okay . Project Manager : Uh so So yeah , that\\'s it , so just you can do your presentation for uh User Interface : Which one first ? Marketing : Okay . Project Manager : Oh it doesn\\'t matter , just start with the User Interface : Okay . Marketing : Mm . Uh User Interface : Functional requirements , yeah Marketing : Okay . Well my name is Jens Damman , but we\\'re in a group , and I I will start it . Wait . Um I\\'ve used a marketing report on uh the site . Uh I think you\\'ve uh read it too . Uh and uh f and furthermore I uh surfed the o the other site . Project Manager : I I didn\\'t read i read it , so it\\'s not for me , Marketing : You didn\\'t read it ? Project Manager : I didn\\'t get it uh anyway . User Interface : No , I didn don\\'t thing we got it . Project Manager : It\\'s only for you . Marketing : Oh okay , I I was the only one who get it . Project Manager : Yeah . User Interface : Yes . Marketing : Okay it was uh uh uh um um a report about uh an experiment with uh a lot of users . And uh they had a lot of findings in their report uh with statistical uh uh uh thing uh with statistical uh proof . So I um I had three pages with findings and sev a lot of uh a lot of findings . So we can use this uh to uh create our own remote control . Uh seventy five percent of the users find uh most remote controls ugly . Yeah , I think uh uh that\\'s a lot , so we have to make a beautiful remote control . Uh eighty percent of users would spend when uh a remote control will l uh look fancy . I think this fits uh at the uh what what uh Michael said about uh older people . Older people will uh spend more money uh for uh something uh uh what\\'s good . Because younger people are more critical uh about uh uh where they spend their money money at . Uh seventy five percent uh seventy five percent of the users say they zap a lot . Well okay , that\\'s uh normal . I think uh we we have to make uh good zap buttons . But that\\'s one of our requirements . Project Manager : The last point is quite an interesting  Marketing : Yes , fifty percent of users say they only use ten percent of the buttons . Project Manager : So Marketing : Um Martijn alr already said it . Project Manager : if we Yeah . Marketing : And uh maybe our uh fold open system is is a good one , but I don\\'t think it\\'s uh Project Manager : Yeah , we should have the ten percent on the on the top , Marketing : reachable . Project Manager : then you\\'re you\\'re Marketing : Yeah , the ten percent on the top , yeah . Industrial Designer : Yeah . Marketing : That that\\'s a good one . Um uh page two . Remote controls are often lost somewhere in the room . That\\'s exactly what we said about um maybe a home station for uh for it uh to uh recharge the batteries or something . Uh I thought mo maybe we could make a clap system , so when you clap your hands it will beep or something . Uh you must find it uh quickly . User Interface : Uh . Maybe just a button on the home station . So remote control beeps when you click that button on the home station . Marketing : Okay , yeah . Yeah , we can uh combine that . Uh it takes too much time to learn how to use a r new remote control . Uh I think we must t uh take a look at this . It\\'s only uh th thirty four of the thirty four percent . But it\\'s uh a tough one . Because if we make a ha whole new product , our own style , we we c uh this is so difficult , uh a difficulty I think . Uh next , remote controls are bad for R_S_I_ . Yeah , but only if they zap a lot , and they watch over five hours T_V_ or something . I don\\'t We we haven\\'t Uh we mustn\\'t look too much at uh the last point . Okay , last page .\\n\\n\\nGiven a transcripts between multiple speakers above, provide a concise summary within 200 words for each speaker highlighting their key learning points or contributions with the given format below:\\n\\nAlso add a \"Overall Summary\" section to summarise the entire discussion.\\n\\n',\n",
       "  'answer': '\\n\\nProject Manager: The Project Manager starts the meeting with some difficulty recalling names and apologizes. They quickly gather the names and surnames of team members, emphasizing the need for efficient time management. The Project Manager discusses the focus on a TV remote control for kids and elderly users, reiterating key points from the last meeting and highlighting the target audience of forty-plus individuals. The manager directs the team to present their progress.\\n\\nUser Interface: The User Interface team member, Paul Wiezer, provides insights into functional requirements for the remote control. The team discusses findings from a marketing report, emphasizing the importance of aesthetics and functionality. They propose a fold-open system and a home station with a clap system or a button for finding lost remote controls quickly. The team addresses the challenge of user learning curves and potential risks of repetitive strain injuries (RSI).\\n\\nMarketing: Jens Damman from the Marketing team presents the marketing report findings, emphasizing user preferences for aesthetically pleasing remote controls. They propose incorporating these findings into the design, such as making buttons for the top ten percent of frequently used functions. Marketing suggests a home station with a button to locate a lost remote control and discusses challenges related to product adoption and the impact on RSI for heavy users.\\n\\nIndustrial Designer: Martijn Abbing, the Industrial Designer, briefly mentions time constraints but aligns with the proposed solutions, including the top-ten buttons on the remote and the home station. The team collectively discusses potential design considerations, such as larger buttons for older users.\\n\\nOverall Summary: This meeting was about the functional design of the remote control. Firstly, Marketing gave a presentation on functional requirements. Group decided to focus on the fancy and fashionable look, usability, and different colors. Next, User Interface gave a presentation on the technical function design. Also, the group discussed this topic, and they decided to design the menu buttons of the remote similar to the mobile phone. Then, Industrial Designer gave a presentation on the working design. Group mates discussed deciding on the use of LED light on the buttons to indicate the transmitting of the Morse code when pressing the button. They also decided to use a more intelligent chip than the standard one when the circuit was closed, it would produce the pattern. For the age group, they would target the age group below forty since it was a young market.\\n\\n'},\n",
       " {'question': '\\nTranscript: \\n\\nThe Chair (Hon. Anthony Rota (NipissingTimiskaming, Lib.)) : I call this meeting to order. Welcome to the sixth meeting of the House of Commons Special Committee on the COVID-19 pandemic. Today\\'s meeting is taking place by videoconference. Before speaking, please wait until I recognize you by name. When you are ready to speak, please activate your mic. When you are not speaking, leave your mic on mute. Of course, change the language when you change the language on the screen.  I would remind hon. members that if you want to speak English, you should be on the English channel; if you want to speak French, you should be on the French channel; and should you wish to alternate between the two languages, as I just did, you should change the channel to the language that you are speaking, each time you switch languages. In addition, please direct your remarks through the chair and speak slowly and clearly at all times to help our interpreters. Finally, for members who will be speaking, we strongly recommend that you use a headset. I recommend the headset for your fellow members, but also for the interpreters as it gets loud, up and down, and it squeaks. It really does make it difficult for them if you do not have the prescribed headsets. We\\'ll go on to ministerial announcements. I understand that there are no ministerial announcements today, so we will proceed to presenting petitions, for a period not exceeding 15 minutes. I would like to remind members that any petition presented during a meeting of the special committee must have already been certified by the clerk of petitions. We will now proceed to presenting petitions. Ms. Heather McPherson (Edmonton Strathcona, NDP) : Thank you, Mr. Chair. World Maternal Mental Health Day took place last week, and today I\\'d like to take a moment to present a very important petition on behalf of the Canadian Perinatal Mental Health Collaborative. Whereas perinatal mood and anxiety disorders are the most common obstetrical complication, whereas in Canada and worldwide 20% of women and 10% of men suffer from a perinatal mental illness, resulting in an annual economic cost to Canada of approximately $11 billion, and whereas the U.K., Australia and parts of the U.S. have perinatal mental health strategies and screening guidelines in place and Canada does not, the Canadian Perinatal Mental Health Collaborative is calling upon the House of Commons in Parliament assembled to create a national perinatal mental health strategy that will provide direction, policy and funding to develop specialized, comprehensive perinatal mental health care services, which include universal screening and timely access to treatment for all women and men during pregnancy and the postpartum period. Mr. Scott Reid (LanarkFrontenacKingston, CPC) : Thank you, Mr. Chair. My petition relates to cystic fibrosis. If we were in the House now, as May is Cystic Fibrosis Awareness Month, one of the days this month we would all be wearing yellow roses in sympathy and solidarity with those who suffer from what is the number one disease killer in Canada of young people. The petitioners have asked us to look at the situation with the Patented Medicine Prices Review Board, which is scheduled to go through some important and potentially detrimental regulatory changes very soon. They ask that the amendments to the Patented Medicine Prices Review Board be rescinded, as these will restrict Canadians from receiving life-saving medications for cystic fibrosis and other illnesses, but in particular, a medicine called Trikafta, which can have the effect of treating cystic fibrosis in the case of 90% of cystic fibrosis sufferers. They ask the government to work with the provinces to find a strategy to jointly allow for the delivery of this life-saving medicine to Canadians across the country and to take a leadership role in negotiating a price for gene modulators throughout all the provinces of Canada. Ms. Elizabeth May (SaanichGulf Islands, GP) : Thank you, Mr. Chair. It\\'s an honour to take the mike today, with all colleagues here. It\\'s good to see you all virtually and safe. Petitioners in my community point out in this petition, which, of course, predates the pandemic, that the family doctor shortage is severe in this country. Nearly five million Canadians lack a regular family doctor. This problem is particularly profound in more rural areas, including, as the petitioners reference, the community in which I live, Sydney, British Columbia. We have a very significant crisis and a lack of family doctors. The petitioners call on the government to work with provinces and territories to find a collaborative, holistic solution so that every Canadian has a family doctor and we address the family doctor shortage. Mr. Brad Vis (MissionMatsquiFraser Canyon, CPC) : Good morning, Mr. Chair. I\\'m presenting a timely petition today that emphasizes the concerns constituents in my riding of MissionMatsquiFraser Canyon have with the Liberal government\\'s inherently flawed and undemocratic approach to firearms legislation and regulation. The petitioners call upon the Government of Canada to stop targeting law-abiding firearms owners; to cancel all plans to confiscate firearms legally owned by federally licensed RCMP-vetted Canadians; to focus taxpayer dollars where they will actually increase public safety, which is on keeping at-risk youth from being involved in gangs and on anti-gang enforcement; and to provide our men and women in uniform at the Canada Border Services Agency with the resources they need to stop the flow of illegal guns into this country. Through this petition, my constituents take issue with how the Liberal government continues to target law-abiding firearms owners instead of the gangs, drug traffickers and illegal weapons smugglers responsible for the violence in our communities. They note that the use of the phrase military-style assault rifle is purely political posturing, as the term is undefined in Canadian law. They also draw attention to the numerous inaccuracies about current firearms legislation and regulation The Chair : I\\'d like to remind the honourable members that this is a concise prcis of what a petition says, not a speech. I\\'ll let Mr. Vis continue. I\\'m sure he\\'ll be very brief in wrapping up. Mr. Brad Vis : Yes. Thank you, Mr. Chair. That\\'s sufficient. The Chair : Okay. Now we\\'ll go to Mr. Johns. Mr. Gord Johns (CourtenayAlberni, NDP) : Thank you, Mr. Chair. It\\'s a huge honour to table e-petition 2512, which was signed by 1,198 petitioners, primarily from the province of Nova Scotia. The Province of Nova Scotia invited multinational companies to scope out and develop expansive open-net salmon farming operations. The petitioners cite that the expansion would increase environmental degradation, as seen in similar aquaculture operations in British Columbia, Newfoundland, Norway, Vietnam and elsewhere in the world. It also, they cite, would pose risks to native fish stocks, pollute coastal ecosystems, impair at-risk wild Atlantic salmon, and threaten established fisheries and tourism operations. They also raise concerns that open-net fish farming would not create significant employment and would undermine existing lobster and other fisheries. They are calling on the government to uphold Bill C-68 and species-at-risk legislation, protect our oceans, ban expansion of open-net finfish aquaculture in our oceans, work to phase out any existing open-net fish farming operations currently in place and, lastly, invest in land-based, closed-containment finfish aquaculture. I want to thank these petitioners for fighting for clean oceans, for their local economy and for the well-being of Nova Scotia. Mr. Paul Manly (NanaimoLadysmith, GP) : Thank you, Mr. Chair. This petition was signed and sent in by constituents of my riding of NanaimoLadysmith. It calls upon the House of Commons to commit to upholding the UN Declaration on the Rights of Indigenous Peoples and the calls to action from the Truth and Reconciliation Commission of Canada by immediately halting all existing and planned construction of the Coastal GasLink project on Wet\\'suwet\\'en territory, ordering the RCMP to dismantle its exclusion zone and stand down, scheduling nation-to-nation talks between the Wet\\'suwet\\'en nation and the federal and provincial governmentssomething that has already happened, thankfullyand prioritizing the real implementation of the UN Declaration on the Rights of Indigenous Peoples. Ms. Yasmin Ratansi (Don Valley East, Lib.) : Thank you, Mr. Chair. I have the pleasure of presenting a petition on behalf of my constituents of Don Valley East. The petitioners are asking that the Government of Canada not provide any financial assistance to Canadian airlines until they promptly provide full refunds for flights that were cancelled due to COVID-19. They are asking the same for any foreign airlines that fly to, within or from Canada. The petitioners feel that these Canadians are facing economic hardship and need a refund. The Chair : We\\'ll now proceed to questioning ministers. The first question will go to Mr. Albas. Mr. Dan Albas (Central OkanaganSimilkameenNicola, CPC) : Thank you, Mr. Chair. Today we\\'ve learned that federal workers have been told to ignore obvious signs of fraud when it comes to applying for government benefits. Can the Prime Minister confirm that 200,000 applications have been flagged as potentially fraudulent? Right Hon. Justin Trudeau (Prime Minister) : Thank you, Mr. Chair. Our priority from the beginning has been to make sure that Canadians get the support they need. We moved very quickly to get the Canada emergency response benefit out, to get the wage subsidy out and to help Canadians in this unprecedented situation. We recognize there will be challenges, and we are going to work through those challenges. Our priority every step of the way was to make sure we helped as many Canadians as possible. Mr. Dan Albas : Mr. Chair, can the Prime Minister confirm that the instruction has been given to federal employees to ignore these 200,000 applications being flagged as potentially fraudulent? This is important. Right Hon. Justin Trudeau : Our focus has been on helping as many people as we possible can. Our decision from the very beginning was to get the help out to people and figure out, with retroactive action if necessary, where and when there may have been fraudulent use. Our priority was getting that help out. Mr. Dan Albas : Mr. Chair, this came from a memo issued by a deputy minister. Did the minister\\'s office or the Prime Minister sign off on this memo? Right Hon. Justin Trudeau : Again, in this unprecedented situation, our focus has been on helping as many people as possible, as quickly as possible. Other parties might have made a different choice had they been in government, but our focus was getting help to people when they needed it as quickly as possible and cleaning it up afterwards. Mr. Dan Albas : Mr. Chair, I asked a very simple question. Did the Prime Minister or his minister sign off on this memo that was issued by the deputy minister, yes or no? Right Hon. Justin Trudeau : Mr. Chair, we have been focused entirely on getting help to Canadians when they need it, and that has meant that yes, there will be things we will need to clean up after the fact and work to fix, but getting that help into Canadians\\' pockets during this pandemic was our priority. Mr. Dan Albas : I\\'m asking the Prime Minister to show some accountability. Did he or his office sign off on this memo? Right Hon. Justin Trudeau : Mr. Chair, my office and I have been absolutely focused on getting the necessary help to Canadians. Perhaps, as Mr. Albas points out, other parties would have been slower to get the money out. We were flowing money to people who needed it.\\n\\nGiven a transcripts between multiple speakers above, provide a concise summary within 200 words for each speaker highlighting their key learning points or contributions with the given format below:\\n\\nAlso add a \"Overall Summary\" section to summarise the entire discussion.\\n\\n',\n",
       "  'answer': \"\\n\\nThe Chair (Hon. Anthony Rota): The Chair establishes meeting rules and emphasizes language channels, mic usage, and headset recommendations. They move on to petitions, covering topics like perinatal mental health, changes to the Patented Medicine Prices Review Board, the shortage of family doctors, firearms legislation concerns, open-net salmon farming, the Coastal GasLink project, and airline refunds.\\n\\nMs. Heather McPherson (Edmonton Strathcona, NDP): Presents a petition on World Maternal Mental Health Day, urging the creation of a national perinatal mental health strategy.\\n\\nMr. Scott Reid (LanarkFrontenacKingston, CPC): Discusses a petition related to cystic fibrosis, calling for rescinding amendments to the Patented Medicine Prices Review Board.\\n\\nMs. Elizabeth May (SaanichGulf Islands, GP): Highlights a petition addressing the severe family doctor shortage in Canada and urges collaboration for a solution.\\n\\nMr. Brad Vis (MissionMatsquiFraser Canyon, CPC): Presents a petition on firearms legislation, emphasizing the flawed approach and its impact on law-abiding owners.\\n\\nMr. Gord Johns (CourtenayAlberni, NDP): Presents a petition against expanding open-net salmon farming, citing environmental and economic concerns.\\n\\nMr. Paul Manly (NanaimoLadysmith, GP): Presents a petition calling for upholding the UN Declaration on the Rights of Indigenous Peoples regarding the Coastal GasLink project.\\n\\nMs. Yasmin Ratansi (Don Valley East, Lib.): Presents a petition urging the government not to provide financial assistance to airlines without refunding canceled flights.\\n\\nMr. Dan Albas (Central OkanaganSimilkameenNicola, CPC): Questions the Prime Minister about a memo instructing federal workers to ignore potential fraud in benefit applications.\\n\\nRight Hon. Justin Trudeau (Prime Minister): Defends the government's focus on quick assistance during the pandemic, acknowledging challenges and the need for retrospective action. Deflects accountability on signing off the memo, emphasizing the priority of rapid aid over bureaucratic details.\\n\\nOverall Summary: The whole meeting was a special Committee on the COVID-19 Pandemic. After some regulations proposed by The Chair, the members presented many petitions on behalf of different areas. Then the meeting proceeded to questioning ministers, the attendees asked for the reasons that the government put easy policy for fraudulence and tax evasion of businessmen. Moreover, the participants required government support under the COVID-19 Pandemic, not only for the elderly and vulnerable people, but also for energy resources and tourism sectors. At the same time, the exact funding from the government should be given to green economies including agriculture and forestry. In addition, the meeting also discussed the current situations of different sectors such as employment, fishing and tourism, oil and gas and business affected by the Covid-19 and called for government support for these sectors. Last but not least, the attendees required strict implementations of the laws and appealed for process following. They wanted a transparency and open environment for voting and debating under the precondition of community safety. Also, they wanted affordable medication including vaccines as a part of a sound health care system for their people.\\n\\n\"}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Summary:\n",
      "The discussion involved multiple speakers, including Professor E, Grad C, Postdoc F, PhD A, PhD B, and Grad D. The conversation covered various topics related to the recording and transcription of meetings, including the use of microphones, audio monitoring, transcription of speech, and the handling of technical jargon and acronyms. The speakers also discussed the use of different features for speech recognition and the process of bleep editing to exclude certain sections of the meeting. There was also a focus on the privacy issue and the use of passwords to restrict access to meeting transcripts. The conversation was detailed and technical, with a focus on improving the transcription and recording process for future meetings.\n",
      "\n",
      "Each Speaker's Contribution:\n",
      "- Professor E: Led the discussion and raised questions about the use of different features for speech recognition and the process of bleep editing.\n",
      "- Grad C: Discussed the use of microphones, audio monitoring, and the process of bleep editing to exclude certain sections of the meeting.\n",
      "- Postdoc F: Shared insights on the transcription process, including the handling of technical jargon and acronyms, and the use of different features for speech recognition.\n",
      "- PhD A: Discussed the use of different features for speech recognition and the process of bleep editing to exclude certain sections of the meeting.\n",
      "- PhD B: Contributed to the discussion on the use of different features for speech recognition and the process of bleep editing.\n",
      "- Grad D: Asked questions and contributed to the conversation about the use of different features for speech recognition and the process of bleep editing.\n"
     ]
    }
   ],
   "source": [
    "print(df_scores[\"summary\"].iloc[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map & Combine load_summarize_chain()\n",
    "\n",
    "Best methods found in formatting summary in ideal format with prompt engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo-1106\n",
      "Number of tokens: 8437\n",
      "Number of chunks: 1\n",
      "PhD F: Provided detailed information about the use of wireless headsets, the process of running jobs using P-make and Customs, and the benefits of using \"run command\" for job execution. Also discussed the attributes associated with machines and the need to limit the number of jobs running simultaneously.\n",
      "\n",
      "PhD A: Shared experiences with speech enhancement algorithms, including the use of LDA filters and on-line normalization. Also discussed the addition of endpoint information to the baseline and the impact on different test sets.\n",
      "\n",
      "PhD D: Discussed the use of spectral subtraction from France Telecom and the need to retune time constants for on-line normalization. Also mentioned the impact of adding endpoint information on different test sets and the potential changes in qualification criteria.\n",
      "\n",
      "Overall Summary: The discussion covered various aspects of recording and computing tasks, including the use of lapel microphones, wireless headsets, and different algorithms for speech enhancement. The addition of new machines for a compute farm and the use of \"run command\" for job execution were also highlighted. The speakers emphasized the importance of considering the impact of different techniques and algorithms on test sets and the need to limit the number of jobs running simultaneously.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 142.75it/s]\n",
      "c:\\Users\\Zhang Xiang\\Desktop\\Year 3\\Sem 2\\FYPJ\\Project\\RD_TextSummarizerForWebinar\\Development\\.venv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.26 seconds, 0.79 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "from langchain import FewShotPromptTemplate\n",
    "from langchain.chains import (\n",
    "    LLMChain,\n",
    "    StuffDocumentsChain,\n",
    "    ReduceDocumentsChain,\n",
    "    MapReduceDocumentsChain,\n",
    ")\n",
    "\n",
    "for model_index, model_row in df_openai_models.iterrows():\n",
    "    model_name = model_row[\"models\"]\n",
    "    print(model_name)\n",
    "\n",
    "    temperature = 0\n",
    "    llm = ChatOpenAI(temperature=temperature, model_name=model_name, openai_api_key=openai_api_key)\n",
    "    \n",
    "    map_template = \"\"\"\n",
    "The following is a set of documents\n",
    "{text}\n",
    "Based on this list of docs, generate summary for each speaker.\n",
    "Helpful Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    reduce_template = \"\"\"\n",
    "Transcript:\n",
    "\n",
    "{text}\n",
    "\n",
    "Given a transcripts between multiple speakers above, provide a concise summary within 200 words for each speaker highlighting their key learning points or contributions with the given format below:\n",
    "\n",
    "Also add a \"Overall Summary\" section to summarise the entire discussion.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "    # document_prompt = PromptTemplate(template=\"{content}\", input_variables=[\"content\"])\n",
    "    # document_variable_name = \"context\"\n",
    "\n",
    "    # prompt = PromptTemplate.from_template(\n",
    "    #     \"Summarize this content: {context}\"\n",
    "    # )\n",
    "    \n",
    "    map_prompt = PromptTemplate(template=map_template, input_variables=[\"text\"])\n",
    "    \n",
    "    reduce_prompt = PromptTemplate(template=reduce_template, input_variables=[\"text\"])\n",
    "\n",
    "\n",
    "    # few_shot_prompt = FewShotPromptTemplate(\n",
    "    #     examples=examples,\n",
    "    #     example_prompt=reduce_prompt,\n",
    "    #     suffix=\"{transcript}\",\n",
    "    #     input_variables = ['transcript'])\n",
    "\n",
    "    for index, row in df_qmsum_test.iterrows():\n",
    "        method = \"MapReduce\"\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # return token of full text\n",
    "        num_tokens = llm.get_num_tokens(row['transcript'])\n",
    "        print(\"Number of tokens:\", num_tokens)\n",
    "\n",
    "\n",
    "        max_tokens = model_row[\"max_tokens\"]\n",
    "\n",
    "        # CHUNKING \"Split documents to shorter length.\"\n",
    "        text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=max_tokens-100, chunk_overlap=100)\n",
    "        docs = text_splitter.create_documents([row['transcript']])\n",
    "        print(\"Number of chunks:\", len(docs))\n",
    "\n",
    "\n",
    "        # # Take a single piece of text, feed it into the template and Summarize it.\n",
    "        # map_chain = LLMChain(llm=llm, prompt=map_prompt)\n",
    "\n",
    "        # # Have a whole bunch of summaries each of a part of the text, \n",
    "        # # Have to combine all these summaries, reducing them to a single summary.        \n",
    "        # reduce_chain = LLMChain(llm=llm, prompt=reduce_prompt)\n",
    "\n",
    "        # # It will take smaller documents and combine them back into one bigger document\n",
    "        # combine_documents_chain = StuffDocumentsChain(\n",
    "        #                             llm_chain=reduce_chain, \n",
    "        #                             document_variable_name=\"transcript\"\n",
    "        #                             )\n",
    "        # # If all summaries add up and become too large, and exceed the model limit.\n",
    "        # # Recursively calling  provided chain until all the summaries and summaries of summaries are combined into a single summary.\n",
    "        # reduce_documents_chain = ReduceDocumentsChain(\n",
    "        #                             combine_documents_chain=combine_documents_chain, \n",
    "        #                             collapse_documents_chain=combine_documents_chain, \n",
    "        #                             token_max=max_tokens\n",
    "        #                             )\n",
    "\n",
    "        # # Ask for a summary of a single chunk of the whole text, \n",
    "        # # and a chain that will feed groups of summaries and reduce them until there is only a single summary left.\n",
    "        # map_reduce_chain = MapReduceDocumentsChain(\n",
    "        #                             llm_chain=map_chain, \n",
    "        #                             reduce_documents_chain=reduce_documents_chain, \n",
    "        #                             document_variable_name=\"docs\", \n",
    "        #                             return_intermediate_steps=False\n",
    "        #                             )\n",
    "\n",
    "        # summary_chain = map_reduce_chain\n",
    "\n",
    "\n",
    "        summary_chain = load_summarize_chain (\n",
    "            llm=llm,\n",
    "            chain_type='map_reduce',\n",
    "            map_prompt = map_prompt,\n",
    "            combine_prompt=reduce_prompt,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "\n",
    "                \n",
    "        summary = summary_chain.run(docs)\n",
    "        print(summary)\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        metrics = SummarizationMetrics(row['summary'], summary)\n",
    "\n",
    "        new_result = {\n",
    "            'model': model_name,\n",
    "            'method': method,\n",
    "            'max_tokens': max_tokens,\n",
    "            'transcript': row['transcript'],\n",
    "            'original summary': row['summary'],\n",
    "            'summary': summary,\n",
    "            'rouge': metrics.rouge_scores(),\n",
    "            'bert_score': metrics.bert_score(),\n",
    "            'bleu': metrics.bleu_score(),\n",
    "            'time_taken': elapsed_time,\n",
    "            'grammar': metrics.grammar_check(),\n",
    "            'readability': metrics.readability_index(),\n",
    "            'num_tokens': num_tokens,\n",
    "            'prompt': reduce_template,\n",
    "            'temperature': temperature\n",
    "        }\n",
    "\n",
    "\n",
    "        new_row = pd.DataFrame([new_result])\n",
    "\n",
    "        df_scores = pd.concat([df_scores, new_row], ignore_index=True)\n",
    "        time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Professor C : Uh , is it the twenty - fourth ? PhD F : now we 're on . Professor C : Yeah . PhD A : Uh Chuck , is the mike type wireless {disfmarker} PhD F : Yes . PhD A : wireless headset ? OK . PhD F : Yes . Professor C : Yeah . PhD F : For you it is . Professor C : Yeah . We uh {disfmarker} we abandoned the lapel because they sort of were not too {disfmarker} not too hot , not too cold , they were {disfmarker} you know , they were {vocalsound} uh , far enough away that you got more background noise , uh , and uh {disfmarker} and so forth PhD A : Uh - huh . Professor C : but they weren't so close that they got quite the {disfmarker} you know , the really good {disfmarker} No , th PhD A : OK . Professor C : they {disfmarker} I mean they didn't {disfmarker} Wait a minute . I 'm saying that wrong . They were not so far away that they were really good representative distant mikes , PhD A : Uh - huh . Professor C : but on the other hand they were not so close that they got rid of all the interference . So it was no {disfmarker} didn't seem to be a good point to them . On the other hand if you only had to have one mike in some ways you could argue the lapel was a good choice , precisely because it 's in the middle . PhD A : Yeah , yeah . Professor C : There 's uh , some kinds of junk that you get with these things that you don't get with the lapel uh , little mouth clicks and breaths and so forth are worse with these than with the lapel , but given the choice we {disfmarker} there seemed to be very strong opinions for uh , getting rid of lapels . PhD A : The mike number is {disfmarker} Professor C : So , PhD F : Uh , your mike number 's written on the back of that unit there . PhD A : Oh yeah . One . PhD F : And then the channel number 's usually one less than that . PhD A : Oh , OK . OK . PhD F : It - it 's one less than what 's written on the back of your {disfmarker} PhD A : OK . OK . PhD F : yeah . So you should be zero , actually . PhD A : Hello ? Yeah . PhD F : For your uh , channel number . PhD A : Yep , yep . Professor C : And you should do a lot of talking so we get a lot more of your pronunciations . no , they don't {disfmarker} don't have a {disfmarker} have any Indian pronunciations . PhD F : So what we usually do is um , we typically will have our meetings Professor C : Yeah . PhD F : and then at the end of the meetings we 'll read the digits . Everybody goes around and reads the digits on the {disfmarker} the bottom of their forms . Professor C : Session R PhD D : R - nineteen ? PhD A : OK . Professor C : R - nineteen . PhD F : Yeah . We 're {disfmarker} This is session R - nineteen . Professor C : If you say so . O K . Do we have anything like an agenda ? What 's going on ? Um . I guess um . So . One thing {disfmarker} PhD F : Sunil 's here for the summer ? Professor C : Sunil 's here for the summer , right . Um , so , one thing is to talk about a kick off meeting maybe uh , and then just uh , I guess uh , progress reports individually , and then uh , plans for where we go between now and then , pretty much . Um . PhD F : I could say a few words about um , some of the uh , compute stuff that 's happening around here , so that people in the group know . Professor C : Mm - hmm . OK . Why don't you start with that ? That 's sort of {disfmarker} PhD F : OK . Professor C : Yeah ? PhD F : We um {disfmarker} So we just put in an order for about twelve new machines , uh , to use as sort of a compute farm . And um , uh , we ordered uh , SUN - Blade - one - hundreds , and um , I 'm not sure exactly how long it 'll take for those to come in , but , uh , in addition , we 're running {disfmarker} So the plan for using these is , uh , we 're running P - make and Customs here and Andreas has sort of gotten that all uh , fixed up and up to speed . And he 's got a number of little utilities that make it very easy to um , {vocalsound} run things using P - make and Customs . You don't actually have to write P - make scripts and things like that . The simplest thing {disfmarker} And I can send an email around or , maybe I should do an FAQ on the web site about it or something . Um , Professor C : How about an email that points to the FAQ , PhD F : there 's a c Professor C : you know what I 'm saying ? PhD F : Yeah , yeah . Professor C : so that you can {disfmarker} Yeah . PhD F : Uh , there 's a command , uh , that you can use called \" run command \" . \" Run dash command \" , \" run hyphen command \" . And , if you say that and then some job that you want to execute , uh , it will find the fastest currently available machine , and export your job to that machine , and uh {disfmarker} and run it there and it 'll duplicate your environment . So you can try this as a simple test with uh , the L S command . So you can say \" run dash command L S \" , and , um , it 'll actually export that {vocalsound} LS command to some machine in the institute , and um , do an LS on your current directory . So , substitute LS for whatever command you want to run , and um {disfmarker} And that 's a simple way to get started using {disfmarker} using this . And , so , soon , when we get all the new machines up , {vocalsound} um , e then we 'll have lots more compute to use . Now th one of the nice things is that uh , each machine that 's part of the P - make and Customs network has attributes associated with it . Uh , attributes like how much memory the machine has , what its speed is , what its operating system , and when you use something like \" run command \" , you can specify those attributes for your program . For example if you only want your thing to run under Linux , you can give it the Linux attribute , and then it will find the fastest available Linux machine and run it on that . So . You can control where your jobs go , to a certain extent , all the way down to an individual machine . Each machine has an attribute which is the name of itself . So you can give that as an attribute and it 'll only run on that . If there 's already a job running , on some machine that you 're trying to select , your job will get queued up , and then when that resource , that machine becomes available , your job will get exported there . So , there 's a lot of nice features to it and it kinda helps to balance the load of the machines and uh , right now Andreas and I have been the main ones using it and we 're {disfmarker} Uh . The SRI recognizer has all this P - make customs stuff built into it . Professor C : So as I understand , you know , he 's using all the machines and you 're using all the machines , PhD F : So . Professor C : is the rough division of {disfmarker} PhD F : Yeah . Exactly . Yeah , you know , I {disfmarker} I sort of got started {comment} using the recognizer just recently and uh , uh I fired off a training job , and then I fired off a recognition job and I get this email about midnight from Andreas saying , \" uh , are you running two {vocalsound} trainings simultaneously s my m my jobs are not getting run . \" So I had to back off a little bit . But , soon as we get some more machines then uh {disfmarker} then we 'll have more compute available . So , um , that 's just a quick update about what we 've got . So . Grad G : Um , I have {disfmarker} I have a question about the uh , parallelization ? PhD F : Mm - hmm . Grad G : So , um , let 's say I have like , a thousand little {disfmarker} little jobs to do ? PhD F : Mm - hmm . Grad G : Um , how do I do it with \" run command \" ? I mean do {disfmarker} PhD F : You could write a script uh , which called run command on each sub - job Grad G : Uh - huh . A thousand times ? PhD F : right ? But you probably wanna be careful with that Grad G : OK . PhD F : because um , you don't wanna saturate the network . Uh , so , um , you know , you should {disfmarker} you should probably not run more than , say ten jobs yourself at any one time , uh , just because then it would keep other people {disfmarker} Grad G : Oh , too much file transfer and stuff . PhD F : Well it 's not that so much as that , you know , e with {disfmarker} if everybody ran fifty jobs at once then it would just bring everything to a halt and , you know , people 's jobs would get delayed , so it 's sort of a sharing thing . Um , Grad G : OK . PhD F : so you should try to limit it to somet sometim some number around ten jobs at a time . Um . So if you had a script for example that had a thousand things it needed to run , um , you 'd somehow need to put some logic in there if you were gonna use \" run command \" , uh , to only have ten of those going at a time . And uh , then , when one of those finished you 'd fire off another one . Um , Professor C : I remember I {disfmarker} I forget whether it was when the Rutgers or {disfmarker} or Hopkins workshop , I remember one of the workshops I was at there were {disfmarker} everybody was real excited cuz they got twenty - five machines and there was some kind of P - make like thing that sit sent things out . PhD F : Mm - hmm . Mm - hmm . Professor C : So all twenty - five people were sending things to all twenty - five machines PhD F : Mm - hmm . Yeah . Professor C : and {vocalsound} and things were a lot less efficient than if you 'd just use your own machine . PhD F : Yeah . Yep . Yeah , exactly . Yeah , you have to be a little bit careful . Professor C : as I recall , but . Yeah . PhD D : Hmm . PhD F : Um , but uh , you can also {disfmarker} If you have that level of parallelization um , and you don't wanna have to worry about writing the logic in {disfmarker} in a Perl script to take care of that , you can use um , P - make Grad G : Just do P - make . PhD F : and {disfmarker} and you basically write a Make file that uh , you know your final job depends on these one thousand things , Grad G : s Mm - hmm . PhD F : and when you run P - make , uh , on your Make file , you can give it the dash capital J and {disfmarker} and then a number , Grad G : Mm - hmm . PhD F : and that number represents how many uh , machines to use at once . And then it 'll make sure that it never goes above that . Grad G : Right . PhD F : So , Grad G : Right . OK . PhD F : I can get some documentation . PhD D : So it {disfmarker} it 's {disfmarker} it 's not systematically queued . I mean all the jobs are running . If you launch twenty jobs , they are all running . Alright . PhD F : It depends . If you {disfmarker} \" Run command \" , that I mentioned before , is {disfmarker} doesn't know about other things that you might be running . PhD D : Uh - huh . PhD F : So , it would be possible to run a hundred run jobs at once , PhD D : Right . PhD F : and they wouldn't know about each other . But if you use P - make , then , it knows about all the jobs that it has to run PhD D : Mm - hmm . PhD F : and it can control , uh , how many it runs simultaneously . Professor C : So \" run command \" doesn't use P - make , or {disfmarker} ? PhD F : It uses \" export \" underlyingly . But , if you {disfmarker} i It 's meant to be run one job at a time ? So you could fire off a thousand of those , and it doesn't know {disfmarker} any one of those doesn't know about the other ones that are running . Professor C : So why would one use that rather than P - make ? PhD F : Well , if you have , um {disfmarker} Like , for example , uh if you didn't wanna write a P - make script and you just had a , uh {disfmarker} an HTK training job that you know is gonna take uh , six hours to run , and somebody 's using , uh , the machine you typically use , you can say \" run command \" and your HTK thing and it 'll find another machine , the fastest currently available machine and {disfmarker} and run your job there . Professor C : Now , does it have the same sort of behavior as P - make , which is that , you know , if you run something on somebody 's machine and they come in and hit a key then it {disfmarker} PhD F : Yes . Yeah , there are um {disfmarker} Right . So some of the machines at the institute , um , have this attribute called \" no evict \" . And if you specify that , in {disfmarker} in one of your attribute lines , then it 'll go to a machine which your job won't be evicted from . Professor C : Mm - hmm . PhD F : But , the machines that don't have that attribute , if a job gets fired up on that , which could be somebody 's desktop machine , and {disfmarker} and they were at lunch , Professor C : Mm - hmm . PhD F : they come back from lunch and they start typing on the console , then your machine will get evicted {disfmarker} your job {comment} will get evicted from their machine and be restarted on another machine . Automatically . So {disfmarker} which can cause you to lose time , right ? If you had a two hour job , and it got halfway through and then somebody came back to their machine and it got evicted . So . If you don't want your job to run on a machine where it could be evicted , then you give it the minus {disfmarker} the attribute , you know , \" no evict \" , and it 'll pick a machine that it can't be evicted from . So . Professor C : Um , what {disfmarker} what about {disfmarker} I remember always used to be an issue , maybe it 's not anymore , that if you {disfmarker} if something required {disfmarker} if your machine required somebody hitting a key in order to evict things that are on it so you could work , but if you were logged into it from home ? PhD F : Mm - hmm . Professor C : and you weren't hitting any keys ? cuz you were , home ? PhD F : Yeah , I {disfmarker} I 'm not sure how that works . Professor C : Yeah . PhD F : Uh , it seems like Andreas did something for that . Professor C : Hmm . PhD F : Um . Professor C : OK . We can ask him sometime . PhD F : But {disfmarker} Yeah . I don't know whether it monitors the keyboard or actually looks at the console TTY , so maybe if you echoed something to the you know , dev {disfmarker} dev console or something . Professor C : You probably wouldn't ordinarily , though . Yeah . Right ? You probably wouldn't ordinarily . PhD F : Hmm ? Professor C : I mean you sort of {disfmarker} you 're at home and you 're trying to log in , and it takes forever to even log you in , and you probably go , \" screw this \" , PhD F : Yeah , yeah . Professor C : and {disfmarker} {vocalsound} You know . PhD F : Yeah . Yeah , so , um , Professor C : Yeah . PhD F : yeah . I {disfmarker} I can {disfmarker} I 'm not sure about that one . Professor C : yeah . PhD F : But uh . Professor C : OK . PhD A : Uh , I need a little orientation about this environment and uh scr s how to run some jobs here because I never d did anything so far with this X emissions PhD F : OK . PhD A : So , I think maybe I 'll ask you after the meeting . PhD F : Um . Yeah . Yeah , and {disfmarker} and also uh , Stephane 's a {disfmarker} a really good resource for that if you can't find me . PhD A : Yeah , yeah , yeah . Yep . OK , sure PhD D : Mmm . PhD F : Especially with regard to the Aurora stuff . PhD A : OK . PhD F : He {disfmarker} he knows that stuff better than I do . Professor C : OK . Well , why don't we uh , uh , Sunil since you 're {vocalsound} haven't {disfmarker} haven't been at one of these yet , why don't yo you tell us what 's {disfmarker} what 's up with you ? Wh - what you 've been up to , hopefully . PhD A : Um . Yeah . So , uh , shall I start from {disfmarker} Well I don't know how may I {disfmarker} how {disfmarker} OK . Uh , I think I 'll start from the post uh Aurora submission maybe . Professor C : Yeah . PhD A : Uh , yeah , after the submission the {disfmarker} what I 've been working on mainly was to take {disfmarker} take other s submissions and then over their system , what they submitted , because we didn't have any speech enhancement system in {disfmarker} in ours . So {disfmarker} So I tried uh , And u First I tried just LDA . And then I found that uh , I mean , if {disfmarker} if I combine it with LDA , it gives @ @ improvement over theirs . Uh {disfmarker} PhD F : Are y are you saying LDA ? PhD A : Yeah . Yeah . PhD F : LDA . OK . PhD A : So , just {disfmarker} just the LDA filters . I just plug in {disfmarker} I just take the cepstral coefficients coming from their system and then plug in LDA on top of that . But the LDA filter that I used was different from what we submitted in the proposal . PhD F : Mm - hmm . PhD A : What I did was {vocalsound} I took the LDA filter 's design using clean speech , uh , mainly because the speech is already cleaned up after the enhancement so , instead of using this , uh , narrow {disfmarker} narrow band LDA filter that we submitted uh , I got new filters . So that seems to be giving {disfmarker} uh , improving over their uh , system . Slightly . But , not very significantly . And uh , that was uh , showing any improvement over {disfmarker} final {disfmarker} by plugging in an LDA . And uh , so then after {disfmarker} after that I {disfmarker} I added uh , on - line normalization also on top of that . And that {disfmarker} there {disfmarker} there also I n I found that I have to make some changes to their time constant that I used because th it has a {disfmarker} a mean and variance update time constant and {disfmarker} which is not suitable for the enhanced speech , and whatever we try it on with proposal - one . But um , I didn't {disfmarker} I didn't play with that time constant a lot , I just t g I just found that I have to reduce the value {disfmarker} I mean , I have to increase the time constant , or reduce the value of the update value . That 's all I found So I have to . Uh , Yeah . And uh , uh , the other {disfmarker} other thing what I tried was , I just um , uh , took the baseline and then ran it with the endpoint inf uh th information , just the Aurora baseline , to see that how much the baseline itself improves by just supplying the information of the {disfmarker} I mean the w speech and nonspeech . And uh , I found that the baseline itself improves by twenty - two percent by just giving the wuh . Professor C : Uh , can you back up a second , I {disfmarker} I {disfmarker} I missed something , uh , I guess my mind wandered . Ad - ad When you added the on - line normalization and so forth , uh , uh things got better again ? PhD A : Yeah . No . Professor C : or is it ? PhD A : No . No , things didn't get better with the same time constant that we used . Professor C : Did it not ? No , no . With a different time constant . PhD A : With the different time constant I found that {disfmarker} I mean , I didn't get an improvement over not using on - line normalization , Professor C : Oh . PhD A : because I {disfmarker} I found that I would have change the value of the update factor . Professor C : No you didn't , OK . PhD A : But I didn't play it with play {disfmarker} play quite a bit to make it better than . Professor C : Yeah . PhD A : So , it 's still not {disfmarker} Professor C : OK . PhD A : I mean , the on - line normalization didn't give me any improvement . Professor C : OK . PhD A : And uh , so , Professor C : OK . PhD A : oh yeah So I just stopped there with the uh , speech enhancement . The {disfmarker} the other thing what I tried was the {disfmarker} adding the uh , endpoint information to the baseline and that itself gives like twenty - two percent because the {disfmarker} the second {disfmarker} the new phase is going to be with the endpointed speech . And just to get a feel of how much the baseline itself is going to change by adding this endpoint information , I just , uh , use {disfmarker} Professor C : Hmm . PhD F : So people won't even have to worry about , uh , doing speech - nonspeech then . PhD A : Yeah that 's , that 's what the feeling is like . They 're going to give the endpoint information . PhD F : Mmm . Professor C : G I guess the issue is that people do that anyway , PhD F : I see . Professor C : everybody does that , PhD A : Yeah . Professor C : and they wanted to see , given that you 're doing that , what {disfmarker} what are the best features that you should use . PhD F : Yeah , I see . PhD A : So , Professor C : I mean clearly they 're interact . So I don't know that I entirely agree with it . PhD F : Yeah . Professor C : But {disfmarker} but it might be uh {disfmarker} In some ways it might be better t to {disfmarker} rather than giving the endpoints , to have a standard that everybody uses and then interacts with . PhD F : Mm - hmm . Professor C : But , you know . It 's {disfmarker} it 's still someth reasonable . PhD F : So , are people supposed to assume that there is uh {disfmarker} Are {disfmarker} are people not supposed to use any speech outside of those endpoints ? PhD A : Uh {disfmarker} PhD F : Or can you then use speech outside of it for estimating background noise and things ? PhD A : No . No . That i I {disfmarker} Yeah . Yeah , yeah , exactly . I guess that is {disfmarker} that is where the consensus is . Like y you will {disfmarker} you will {disfmarker} You 'll be given the information about the beginning and the end of speech but the whole speech is available to you . PhD F : OK . PhD A : So . Professor C : So it should make the spectral subtraction style things work even better , PhD A : Yeah . Professor C : because you don't have the mistakes in it . Yeah ? PhD A : Yeah . So {disfmarker} Professor C : OK . PhD A : So that {disfmarker} that {disfmarker} The baseline itself {disfmarker} I mean , it improves by twenty - two percent . I found that in s one of the SpeechDat - Car cases , that like , the Spanish one improves by just fifty percent by just putting the endpoint . w PhD F : Wow . PhD A : I mean you don't need any further speech enhancement with fifty . So , uh , PhD F : So the baseline itself improves by fifty percent . PhD A : Yeah , by fifty percent . Professor C : Yeah . PhD F : Wow . Professor C : So it 's g it 's gonna be harder to {vocalsound} beat that actually . PhD F : Yeah . PhD A : Yeah , so {disfmarker} Professor C : But {disfmarker} but {disfmarker} PhD A : so that is when uh , the {disfmarker} the qualification criteria was reduced from fifty percent to something like twenty - five percent for well - matched . And I think they have {disfmarker} they have actually changed their qualification c criteria now . And uh , Yeah , I guess after that , I just went home f I just had a vacation fo for four weeks . Uh . Professor C : OK . No , that 's {disfmarker} that 's {disfmarker} that 's a good {disfmarker} good update . PhD A : Ye Yeah , and I {disfmarker} I came back and I started working on uh , some other speech enhancement algorithm . I mean , so {disfmarker} I {disfmarker} from the submission what I found that people have tried spectral subtraction and Wiener filtering . These are the main uh , approaches where people have tried , Professor C : Yeah . PhD A : so just to {disfmarker} just to fill the space with some f few more speech enhancement algorithms to see whether it improves a lot , I {disfmarker} I 've been working on this uh , signal subspace approach for speech enhancement where you take the noisy signal and then decomposing the signal s and the noise subspace and then try to estimate the clean speech from the signal plus noise subspace . And {disfmarker} Professor C : Mm - hmm . PhD A : So , I 've been actually running some s So far I 've been trying it only on Matlab . I have to {disfmarker} to {disfmarker} to test whether it works first or not Professor C : Yeah . PhD A : and then I 'll p port it to C and I 'll update it with the repository once I find it it giving any some positive result . So , yeah . Professor C : S So you s you So you said one thing I want to jump on for a second . So {disfmarker} so now you 're {disfmarker} you 're getting tuned into the repository thing that he has here PhD A : Yeah . Professor C : and {disfmarker} so we we 'll have a {vocalsound} single place where the stuff is . PhD A : Yep . Yeah . Professor C : Cool . Um , so maybe uh , just briefly , you could remind us about the related experiments . Cuz you did some stuff that you talked about last week , I guess ? PhD D : Mm - hmm . Professor C : Um , where you were also combining something {disfmarker} both of you I guess were both combining something from the uh , French Telecom system with {vocalsound} the u uh {disfmarker} PhD D : Right . Professor C : I {disfmarker} I don't know whether it was system one or system two , or {disfmarker} ? PhD D : Mm - hmm . It was system one . So Professor C : OK . PhD D : we {disfmarker} The main thing that we did is just to take the spectral subtraction from the France Telecom , which provide us some speech samples that are uh , with noise removed . Professor C : So I let me {disfmarker} let me just stop you there . So then , one distinction is that uh , you were taking the actual France Telecom features and then applying something to {disfmarker} PhD A : Uh , no there is a slight different . Uh I mean , which are extracted at the handset because they had another back - end blind equalization {disfmarker} Professor C : Yeah . PhD A : Yeah . Professor C : Yeah . But that 's what I mean . PhD A : Yeah . Professor C : But u u Sorry , PhD A : Yeah . Professor C : yeah , I 'm not being {disfmarker} I 'm not being clear . PhD A : Yeah . Professor C : What I meant was you had something like cepstra or something , right ? PhD A : Yeah , yeah , yeah , yeah . Professor C : And so one difference is that , I guess you were taking spectra . PhD A : The speech . PhD B : Yeah . PhD D : Yeah . But I guess it 's the s exactly the same thing because on the heads uh , handset they just applied this Wiener filter and then compute cepstral features , PhD A : Yeah , the cepstral f The difference is like {disfmarker} There may be a slight difference in the way {disfmarker} PhD D : right ? or {disfmarker} ? PhD A : because they use exactly the baseline system for converting the cepstrum once you have the speech . I mean , if we are using our own code for th I mean that {disfmarker} that could be the only difference . PhD D : Right . PhD A : I mean , there is no other difference . PhD D : Mm - hmm . PhD A : Yeah . Professor C : But you got some sort of different result . So I 'm trying to understand it . But uh , I th PhD D : Yeah , well I think we should uh , have a table with all the result because I don't know I uh , I don't exactly know what are your results ? But , PhD A : OK . OK . PhD D : Mmm . Yeah , but so we did this , and another difference I guess is that we just applied uh , proposal - one system after this without {disfmarker} well , with our modification to reduce the delay of the {disfmarker} the LDA filters , PhD A : Uh - huh . PhD D : and PhD B : And the filter {disfmarker} PhD D : Well there are slight modifications , but it was the full proposal - one . In your case , if you tried just putting LDA , then maybe on - line normalization {disfmarker} ? PhD A : Only LDA . Yeah . Af - I {disfmarker} after that I added on - line normalization , yeah . PhD D : Mm - hmm . So we just tried directly to {disfmarker} to just , keep the system as it was and , um , when we plug the spectral subtraction it improves uh , signif significantly . Um , but , what seems clear also is that we have to retune the time constants of the on - line normalization . PhD A : Yeah , yeah . Yeah . PhD D : Because if we keep the value that was submitted uh , it doesn't help at all . You can remove on - line normalization , or put it , it doesn't change anything . Uh , uh , as long as you have the spectral subtraction . But , you can still find some kind of optimum somewhere , and we don't know where exactly PhD A : Yeah . PhD D : but , uh . PhD A : Yeah , I assume . Professor C : So it sounds like you should look at some tables of results or something PhD D : Right . PhD A : Yeah . PhD D : Yeah . Professor C : and see where i where the {disfmarker} {vocalsound} where they were different and what we can learn from it . PhD D : Mm - hmm . Mm - hmm . PhD A : without any change . OK . PhD B : But it 's {disfmarker} PhD D : Yeah . Well , PhD B : It 's the new . PhD D : with {disfmarker} with {disfmarker} with changes , PhD A : with PhD B : The new . PhD D : because we change it the system to have {disfmarker} PhD A : Oh yeah , I mean the {disfmarker} the new LDA filters . PhD B : The new . PhD A : I mean {disfmarker} OK . PhD D : Yeah . LDA filters . There are other things that we finally were shown to improve also like , the sixty - four hertz cut - off . PhD A : Mm - hmm . PhD B : Mm - hmm . PhD D : w Uh , it doesn't seem to hurt on TI - digits , finally . PhD A : OK . PhD D : Maybe because of other changes . PhD A : OK . PhD D : Um , well there are some {vocalsound} minor changes , yeah . PhD A : Mm - hmm . PhD D : And , right now if we look at the results , it 's , um , always better than {disfmarker} it seems always better than France Telecom for mismatch and high - mismatch . And it 's still slightly worse for well - matched . PhD B : But PhD D : Um , but this is not significant . But , the problem is that it 's not significant , but if you put this in the , mmm , uh , spreadsheet , it 's still worse . Even with very minor {disfmarker} uh , even if it 's only slightly worse for well - matched . Professor C : Mm - hmm . PhD D : And significantly better for HM . Uh , but , well . I don't think it 's importa important because when they will change their metric , uh , uh , mainly because of uh , when you p you plug the um , frame dropping in the baseline system , it will improve a lot HM , and MM , PhD A : Yeah . PhD D : so , um , I guess what will happen {disfmarker} I don't know what will happen . But , the different contribution , I think , for the different test set will be more even . PhD A : Because the {disfmarker} your improvement on HM and MM will also go down significantly in the spreadsheet so . But the {pause} the well - matched may still {disfmarker} PhD D : Mm - hmm . PhD A : I mean the well - matched may be the one which is least affected by adding the endpoint information . Professor C : Right . PhD A : Yeah . So the {disfmarker} the MM {disfmarker} PhD D : Mm - hmm . PhD A : MM and HM are going to be v hugely affected by it . Yeah . PhD D : Yeah , so um , yeah . PhD A : Yeah . But they d the {disfmarker} everything I mean is like , but there that 's how they reduce {disfmarker} why they reduce the qualification to twenty - five percent or some {disfmarker} something on . PhD D : Mm - hmm . Professor C : But are they changing the weighting ? PhD A : Uh , no , I guess they are going ahead with the same weighting . PhD D : Yeah . PhD A : Yeah . So there 's nothing on {disfmarker} Professor C : I don't understand that . PhD A : Yeah . Professor C : I guess I {disfmarker} I haven't been part of the discussion , so , um , it seems to me that the well - matched condition is gonna be unusual , PhD A : Usual . Professor C : in this case . Unusual . PhD A : Uh - huh . Professor C : Because , um , you don't actually have good matches ordinarily for what any @ @ {disfmarker} particular person 's car is like , or PhD A : Mmm . Professor C : uh , PhD A : Mmm . Professor C : It seems like something like the middle one is {disfmarker} is more natural . PhD A : Hmm . Right . Professor C : So I don't know why the {pause} well - matched is uh {disfmarker} PhD D : Mm - hmm . PhD A : Yeah , but actually the well {disfmarker} well the well - matched um , uh , I mean the {disfmarker} the well - matched condition is not like , uh , the one in TI - digits where uh , you have all the training , uh , conditions exactly like replicated in the testing condition also . It 's like , this is not calibrated by SNR or something . The well - matched has also some {disfmarker} some mismatch in that which is other than the {disfmarker} Professor C : The well wa matched has mismatch ? PhD A : has {disfmarker} has also some slight mismatches , unlike the TI - digits where it 's like prefectly matched PhD F : Perfect to match . PhD A : because it 's artificially added noise . Professor C : Yeah . PhD A : But this is natural recording . Professor C : Yeah . So remind me of what well - matched meant ? PhD A : The {disfmarker} the well - matched is like {disfmarker} Professor C : You 've told me many times . PhD A : the {disfmarker} the well - matched is defined like it 's seventy percent of the whole database is used for training and thirty percent for testing . PhD D : Yeah . Well , so it means that if the database is large enough , it 's matched . PhD A : It 's {disfmarker} it 's {disfmarker} PhD D : Because it PhD A : OK , it 's {disfmarker} Professor C : Yeah . PhD D : in each set you have a range of conditions {disfmarker} Well {disfmarker} Professor \n",
      "Overall Summary:\n",
      "\n",
      "The discussion revolved around the use of wireless headsets and lapel microphones for recording, as well as the use of P-make and Customs for running jobs on multiple machines. The speakers also delved into the use of endpoint information for speech enhancement and the impact on different test sets. Additionally, they discussed the order of new machines for a compute farm and the use of signal subspace approach for speech enhancement. The use of LDA filters and on-line normalization for speech enhancement was also a key point of discussion, along with the addition of endpoint information to the baseline and its impact on overall performance. The speakers also touched on the use of spectral subtraction from France Telecom for speech enhancement and the need to retune the time constants of on-line normalization. The impact of endpoint information on different test sets and the changes in qualification criteria for well-matched conditions were also highlighted, along with the use of the sixty-four hertz cut-off and the results obtained from different test sets.\n"
     ]
    }
   ],
   "source": [
    "print(df_scores['transcript'].iloc[-1])\n",
    "\n",
    "print(df_scores['summary'].iloc[-1])\n",
    "# df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-3.5-turbo-1106\n",
      "Number of tokens: 8437\n",
      "Number of chunks: 1\n",
      "Title: Discussion on Speech Enhancement Algorithms\n",
      "\n",
      "Introduction:\n",
      "In this conversation, PhD students and a professor discuss various speech enhancement algorithms and their results. They explore the use of spectral subtraction and Wiener filtering, as well as the addition of endpoint information to improve the baseline system. The impact of different test conditions on the results is also considered.\n",
      "\n",
      "Key Points:\n",
      "- Discussion of spectral subtraction and Wiener filtering\n",
      "- Addition of endpoint information to improve baseline system\n",
      "- Impact of different test conditions on results\n",
      "- Need for further analysis and comparison of different approaches\n",
      "\n",
      "Conclusion:\n",
      "The conversation between the PhD students and the professor sheds light on the various speech enhancement algorithms and their results. It emphasizes the importance of further analysis and comparison of the different approaches to improve speech enhancement technology.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 333.57it/s]\n",
      "c:\\Users\\Zhang Xiang\\Desktop\\Year 3\\Sem 2\\FYPJ\\Project\\RD_TextSummarizerForWebinar\\Development\\.venv\\lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.84 seconds, 1.19 sentences/sec\n"
     ]
    }
   ],
   "source": [
    "from langchain import FewShotPromptTemplate\n",
    "from langchain.chains import (\n",
    "    LLMChain,\n",
    "    StuffDocumentsChain,\n",
    "    ReduceDocumentsChain,\n",
    "    MapReduceDocumentsChain,\n",
    ")\n",
    "\n",
    "for model_index, model_row in df_openai_models.iterrows():\n",
    "    model_name = model_row[\"models\"]\n",
    "    print(model_name)\n",
    "\n",
    "    temperature = 0\n",
    "    llm = ChatOpenAI(temperature=temperature, model_name=model_name, openai_api_key=openai_api_key)\n",
    "    \n",
    "    map_template = \"\"\"\n",
    "Summarize the following text in a clear and concise way:\n",
    "TEXT:`{text}`\n",
    "Brief Summary:\n",
    "\"\"\"\n",
    "\n",
    "    combine_template = \"\"\"\n",
    "Generate a summary of the following text that includes the following elements:\n",
    "\n",
    "* A title that accurately reflects the content of the text.\n",
    "* An introduction paragraph that provides an overview of the topic.\n",
    "* Bullet points that list the key points of the text.\n",
    "* A conclusion paragraph that summarizes the main points of the text.\n",
    "\n",
    "Text:`{text}`\n",
    "    \"\"\"\n",
    "    \n",
    "    map_prompt = PromptTemplate(template=map_template, input_variables=[\"text\"])\n",
    "    \n",
    "    combine_prompt = PromptTemplate(template=combine_template, input_variables=[\"text\"])\n",
    "\n",
    "\n",
    "    # few_shot_prompt = FewShotPromptTemplate(\n",
    "    #     examples=examples,\n",
    "    #     example_prompt=reduce_prompt,\n",
    "    #     suffix=\"{transcript}\",\n",
    "    #     input_variables = ['transcript'])\n",
    "\n",
    "    for index, row in df_qmsum_test.iterrows():\n",
    "        method = \"MapReduce\"\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # return token of full text\n",
    "        num_tokens = llm.get_num_tokens(row['transcript'])\n",
    "        print(\"Number of tokens:\", num_tokens)\n",
    "\n",
    "\n",
    "        max_tokens = model_row[\"max_tokens\"]\n",
    "\n",
    "        # CHUNKING \"Split documents to shorter length.\"\n",
    "        text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=max_tokens-100, chunk_overlap=100)\n",
    "        docs = text_splitter.create_documents([row['transcript']])\n",
    "        print(\"Number of chunks:\", len(docs))\n",
    "\n",
    "\n",
    "        summary_chain = load_summarize_chain (\n",
    "            llm=llm,\n",
    "            chain_type='map_reduce',\n",
    "            map_prompt = map_prompt,\n",
    "            combine_prompt=combine_prompt,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "                \n",
    "        summary = summary_chain.run(docs)\n",
    "        print(summary)\n",
    "\n",
    "        end_time = time.time()\n",
    "        elapsed_time = end_time - start_time\n",
    "\n",
    "        metrics = SummarizationMetrics(row['summary'], summary)\n",
    "\n",
    "        new_result = {\n",
    "            'model': model_name,\n",
    "            'method': method,\n",
    "            'max_tokens': max_tokens,\n",
    "            'transcript': row['transcript'],\n",
    "            'original summary': row['summary'],\n",
    "            'summary': summary,\n",
    "            'rouge': metrics.rouge_scores(),\n",
    "            'bert_score': metrics.bert_score(),\n",
    "            'bleu': metrics.bleu_score(),\n",
    "            'time_taken': elapsed_time,\n",
    "            'grammar': metrics.grammar_check(),\n",
    "            'readability': metrics.readability_index(),\n",
    "            'num_tokens': num_tokens,\n",
    "            'prompt': combine_template,\n",
    "            'temperature': temperature\n",
    "        }\n",
    "\n",
    "\n",
    "        new_row = pd.DataFrame([new_result])\n",
    "\n",
    "        df_scores = pd.concat([df_scores, new_row], ignore_index=True)\n",
    "        time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_scores.to_excel(\"./result/closed_source_model_openai_api.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
